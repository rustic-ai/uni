{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Uni","text":""},{"location":"#the-embedded-multi-model-graph-database","title":"The Embedded Multi-Model Graph Database","text":"<p>Uni is a high-performance, embedded database that unifies graph, vector, document, and columnar workloads in a single engine. Built in Rust for speed and safety, Uni delivers sub-millisecond graph traversals, semantic vector search, and analytical queries\u2014all without the operational complexity of distributed systems.</p> <p>Installation Quick Start API Reference GitHub</p>"},{"location":"#why-uni","title":"Why Uni?","text":"<p>Modern applications need more than one data model. Knowledge graphs require relationships. AI features need vector similarity. Analytics demand columnar scans. Traditional approaches force you to glue together multiple databases, managing synchronization, consistency, and operational overhead.</p> <p>Uni solves this by design:</p> Capability Description Graph Traversals Navigate billions of edges with O(1) adjacency lookups via CSR-cached topology Vector Search Sub-2ms approximate nearest neighbor queries powered by Lance's HNSW indexes Document Storage Store and query nested JSON with path-based indexing Columnar Analytics DataFusion-powered aggregations with predicate pushdown to storage OpenCypher Queries Familiar graph query syntax with vectorized execution"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#embedded-serverless","title":"Embedded &amp; Serverless","text":"<p>Uni runs as a library in your process\u2014no separate server, no network hops, no operational burden. Import it as a crate and start querying.</p>"},{"location":"#cloud-native-storage","title":"Cloud-Native Storage","text":"<p>Persist directly to S3, GCS, or Azure Blob Storage. Local caching ensures fast reads while object stores provide infinite scale.</p>"},{"location":"#vectorized-execution","title":"Vectorized Execution","text":"<p>Queries process data in columnar batches using Apache Arrow, achieving 100-500x speedup over row-at-a-time execution.</p>"},{"location":"#single-writer-simplicity","title":"Single-Writer Simplicity","text":"<p>No complex distributed consensus. One writer, multiple readers, snapshot isolation. Perfect for embedded scenarios.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>use uni::prelude::*;\n\nlet db = UniDatabase::open(\"./my-graph\")?;\nlet results = db.query(\"\n    MATCH (user:User)-[:PURCHASED]-&gt;(product:Product)\n    WHERE vector_similarity(user.embedding, $query) &gt; 0.85\n    RETURN product.name, COUNT(*) as purchases\n    ORDER BY purchases DESC\n    LIMIT 10\n\")?;\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<p>Uni's layered architecture separates concerns for maximum performance and flexibility:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Your Application                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    Uni (Embedded Library)                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 Query Layer \u2502  \u2502   Runtime   \u2502  \u2502   Storage Layer     \u2502  \u2502\n\u2502  \u2502  (Cypher)   \u2502\u2192 \u2502  (L0 + CSR) \u2502\u2192 \u2502     (Lance)         \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                  \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502                    Object Store                            \u2502\n                    \u2502     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n                    \u2502     \u2502    S3    \u2502    \u2502   GCS    \u2502    \u2502  Local   \u2502          \u2502\n                    \u2502     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Learn more about the architecture \u2192</p>"},{"location":"#performance-at-a-glance","title":"Performance at a Glance","text":"Operation Latency Notes 1-hop traversal ~4.7ms CSR-cached adjacency 3-hop traversal ~9.0ms Linear scaling with depth Vector KNN (k=10) ~1.8ms Lance HNSW index Point lookup ~2.9ms Property by index Batch ingest (1K vertices) ~550\u00b5s L0 memory buffer Flush to storage ~6.3ms L0 \u2192 Lance persistence <p>Benchmarks on standard cloud VM. See Benchmarks for methodology.</p>"},{"location":"#use-cases","title":"Use Cases","text":""},{"location":"#knowledge-graphs-rag","title":"Knowledge Graphs &amp; RAG","text":"<p>Build retrieval-augmented generation systems with graph-structured knowledge and semantic search.</p> <pre><code>// Find contextually relevant documents via graph + vector\nMATCH (query:Query)-[:SIMILAR_TO]-&gt;(doc:Document)\nWHERE vector_similarity(query.embedding, doc.embedding) &gt; 0.8\nMATCH (doc)-[:REFERENCES]-&gt;(source:Source)\nRETURN doc.content, source.citation\nLIMIT 5\n</code></pre>"},{"location":"#recommendation-engines","title":"Recommendation Engines","text":"<p>Traverse user-item-user paths while filtering by embedding similarity for personalized recommendations.</p>"},{"location":"#fraud-detection","title":"Fraud Detection","text":"<p>Walk transaction graphs to identify suspicious patterns with real-time property filtering.</p>"},{"location":"#scientific-graphs","title":"Scientific Graphs","text":"<p>Model citation networks, molecular structures, or biological pathways with vector-enhanced similarity search.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Get up and running in under 5 minutes:</p> <pre><code># Clone and build\ngit clone https://github.com/dragonscale/uni.git\ncd uni &amp;&amp; cargo build --release\n\n# Import sample data\n./target/release/uni import semantic-scholar \\\n  --papers demos/demo01/data/papers.jsonl \\\n  --citations demos/demo01/data/citations.jsonl \\\n  --output ./storage\n\n# Run your first query\n./target/release/uni query \\\n  \"MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\n   WHERE p.year &gt; 2020\n   RETURN cited.title, COUNT(*) as citations\n   ORDER BY citations DESC\n   LIMIT 10\" \\\n  --path ./storage\n</code></pre> <p>Complete Quick Start Guide \u2192</p>"},{"location":"#documentation","title":"Documentation","text":""},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation \u2014 Build from source, prerequisites, verification</li> <li>Quick Start \u2014 Your first graph in 5 minutes</li> <li>CLI Reference \u2014 Complete command documentation</li> </ul>"},{"location":"#core-concepts","title":"Core Concepts","text":"<ul> <li>Architecture \u2014 Layered design and component overview</li> <li>Data Model \u2014 Vertices, edges, properties, and schema</li> <li>Identity Model \u2014 VID, EID, and UniId explained</li> <li>Indexing \u2014 Vector, scalar, and full-text indexes</li> <li>Concurrency \u2014 Single-writer model and snapshots</li> </ul>"},{"location":"#developer-guides","title":"Developer Guides","text":"<ul> <li>Cypher Querying \u2014 Complete OpenCypher reference</li> <li>Vector Search \u2014 Semantic similarity at scale</li> <li>Data Ingestion \u2014 Bulk import and streaming writes</li> <li>Schema Design \u2014 Best practices and patterns</li> <li>Performance Tuning \u2014 Optimization strategies</li> </ul>"},{"location":"#use-cases_1","title":"Use Cases","text":"<ul> <li>RAG &amp; Knowledge Graphs</li> <li>Real-Time Fraud Detection</li> <li>Recommendation Engines</li> <li>Supply Chain &amp; BOM</li> </ul>"},{"location":"#internals","title":"Internals","text":"<ul> <li>Vectorized Execution \u2014 Batch processing deep dive</li> <li>Storage Engine \u2014 Lance integration and LSM design</li> <li>Query Planning \u2014 Planner and optimization</li> <li>Benchmarks \u2014 Performance metrics and methodology</li> </ul>"},{"location":"#reference","title":"Reference","text":"<ul> <li>Rust API \u2014 Programmatic access documentation</li> <li>Configuration \u2014 All configuration options</li> <li>Troubleshooting \u2014 Common issues and solutions</li> <li>Glossary \u2014 Terminology reference</li> </ul>"},{"location":"#technology-stack","title":"Technology Stack","text":"<p>Uni leverages best-in-class Rust ecosystem crates:</p> Component Technology Purpose Storage Lance Columnar format with native vector indexes Columnar Apache Arrow Zero-copy data representation Analytics DataFusion SQL execution and optimization Graph Runtime gryf In-memory graph algorithms Object Store object_store S3/GCS/Azure abstraction Parsing sqlparser SQL/Cypher tokenization Embeddings FastEmbed Local embedding models"},{"location":"#project-status","title":"Project Status","text":"<p>Uni is under active development. Current status:</p> Feature Status Graph storage &amp; traversal Stable Vector search (HNSW, IVF_PQ) Stable Graph Algorithms (36 algorithms) Stable OpenCypher (MATCH, WHERE, RETURN, CREATE) Stable Aggregations &amp; Window Functions Stable Scalar Functions (40+ functions) Stable Predicate pushdown Stable Variable-length paths (<code>*1..3</code>) Stable MERGE / SET / DELETE Stable UNION / UNION ALL Stable WITH RECURSIVE (CTEs) Stable EXPLAIN / PROFILE Stable BACKUP / VACUUM / CHECKPOINT Stable CRDT properties Stable Session Variables (<code>$session.*</code>) Stable Bulk Loading (BulkWriter) Stable Schema DDL Procedures Stable Snapshot Readers Stable Inverted Index (ANY IN) Stable Temporal Queries (validAt) Stable Composite Key Constraints Stable Full-text search Planned Distributed mode Future <p>See Cypher Querying Guide for detailed feature documentation.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions! See the Contributing Guide for details.</p> <pre><code># Run tests\ncargo test\n\n# Run benchmarks\ncargo bench\n\n# Check formatting and lints\ncargo fmt --check &amp;&amp; cargo clippy\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Uni is open source under the Apache 2.0 License.</p>   **Ready to dive in?** Start with the **[Installation Guide](getting-started/installation.md)** or jump straight to the **[Quick Start](getting-started/quickstart.md)**."},{"location":"concepts/","title":"Core Concepts","text":"<p>Understand the fundamental concepts behind Uni's design and architecture.</p>   ### [Architecture](architecture.md) Layered design, component overview, and how the pieces fit together.     ### [Data Model](data-model.md) Vertices, edges, properties, labels, and the property graph model.     ### [Identity Model](identity.md) VID, EID, UniId, and how Uni identifies entities.     ### [Indexing](indexing.md) Vector, scalar, hash, and full-text indexes for fast queries.     ### [Concurrency](concurrency.md) Single-writer model, snapshot isolation, and concurrent readers."},{"location":"concepts/#overview","title":"Overview","text":"<p>Uni is built on three core principles:</p> <ol> <li>Multi-Model Unification \u2014 Graph, vector, document, and columnar workloads in one engine</li> <li>Embedded Simplicity \u2014 No separate server, network hops, or operational overhead</li> <li>Cloud-Native Storage \u2014 Object store persistence with local caching for performance</li> </ol>"},{"location":"concepts/#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Query Layer                   \u2502\n\u2502   Parser \u2192 Planner \u2192 Executor           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            Runtime Layer                 \u2502\n\u2502   L0 Buffer | CSR Cache | Properties    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            Storage Layer                 \u2502\n\u2502   Lance Datasets | WAL | Indexes        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            Object Store                  \u2502\n\u2502      S3 | GCS | Azure | Local           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/#next-steps","title":"Next Steps","text":"<p>Start with Architecture for a comprehensive system overview.</p>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>Uni's architecture is designed for high performance, flexibility, and simplicity. This document provides a comprehensive overview of the system's layers, components, and data flow.</p>"},{"location":"concepts/architecture/#design-principles","title":"Design Principles","text":"<p>Before diving into the architecture, understand the key principles that guided Uni's design:</p> Principle Description Embedded First No separate server process; runs as a library in your application Multi-Model Unity Graph, vector, document, and columnar in one engine, not bolted together Object-Store Native Designed for 100ms latency storage (S3/GCS), minimal round-trips Vectorized Execution Batch processing with Apache Arrow for 100x+ speedups Single-Writer Simplicity No distributed consensus; one writer, many readers, snapshot isolation Late Materialization Load properties only when needed to minimize I/O"},{"location":"concepts/architecture/#system-overview","title":"System Overview","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              APPLICATION                                     \u2502\n\u2502                                                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u2502\n\u2502   \u2502  Rust Crate   \u2502   \u2502    CLI Tool   \u2502   \u2502  HTTP Server  \u2502                \u2502\n\u2502   \u2502   (Library)   \u2502   \u2502               \u2502   \u2502   (Optional)  \u2502                \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2502\n\u2502           \u2502                   \u2502                   \u2502                         \u2502\n\u2502           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502                               \u2502                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                               \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                         QUERY LAYER                                  \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502    Parser    \u2502\u2192 \u2502   Planner    \u2502\u2192 \u2502  Vectorized Executor     \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502   (Cypher)   \u2502  \u2502 (Optimizer)  \u2502  \u2502    (Arrow Batches)       \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                               \u2502                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                               \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                        RUNTIME LAYER                                 \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502  L0 Buffer   \u2502  \u2502  Adjacency   \u2502  \u2502   Property Manager       \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502  (Mutations) \u2502  \u2502    Cache     \u2502  \u2502    (Lazy Loading)        \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502    Writer    \u2502  \u2502     WAL      \u2502  \u2502    Graph Algorithms      \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502 (Coordinator)\u2502  \u2502  (Durability)\u2502  \u2502   (PageRank, WCC...)     \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                               \u2502                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                               \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       STORAGE LAYER                                  \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502   Vertex     \u2502  \u2502    Edge      \u2502  \u2502     Adjacency            \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502  Datasets    \u2502  \u2502  Datasets    \u2502  \u2502     Datasets             \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502   \u2502\n\u2502   \u2502  \u2502   Vector     \u2502  \u2502   Scalar     \u2502  \u2502      Snapshot            \u2502   \u2502   \u2502\n\u2502   \u2502  \u2502   Indexes    \u2502  \u2502   Indexes    \u2502  \u2502      Manifests           \u2502   \u2502   \u2502\n\u2502   \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                               \u2502                                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                               \u25bc                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                       OBJECT STORE                                   \u2502   \u2502\n\u2502   \u2502                                                                      \u2502   \u2502\n\u2502   \u2502      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u2502   \u2502\n\u2502   \u2502      \u2502   Local  \u2502     \u2502    S3    \u2502     \u2502   GCS / Azure    \u2502         \u2502   \u2502\n\u2502   \u2502      \u2502   Disk   \u2502     \u2502          \u2502     \u2502                  \u2502         \u2502   \u2502\n\u2502   \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#data-flow-diagram","title":"Data Flow Diagram","text":"flowchart TB     subgraph Application         A[Rust Crate / CLI / HTTP]     end      subgraph Query[\"Query Layer\"]         B[Parser] --&gt; C[Planner] --&gt; D[Executor]     end      subgraph Runtime[\"Runtime Layer\"]         E[L0 Buffer]         F[Adjacency Cache]         G[Property Manager]     end      subgraph Storage[\"Storage Layer\"]         H[Vertex Datasets]         I[Edge Datasets]         J[Vector Indexes]     end      subgraph ObjectStore[\"Object Store\"]         K[Local / S3 / GCS]     end      Application --&gt; Query     Query --&gt; Runtime     Runtime --&gt; Storage     Storage --&gt; ObjectStore"},{"location":"concepts/architecture/#query-layer","title":"Query Layer","text":"<p>The Query Layer transforms Cypher text into optimized execution plans.</p>"},{"location":"concepts/architecture/#parser","title":"Parser","text":"<p>Converts OpenCypher query strings into an Abstract Syntax Tree (AST).</p> flowchart TB     Input[\"MATCH (n:Person)-[:KNOWS]-&gt;(m)&lt;br/&gt;WHERE n.age &gt; 30 RETURN m.name\"]      subgraph Parser[\"CypherParser\"]         T[Tokenization via sqlparser]         P[Pattern recognition]         E[Expression parsing]     end      Output[\"CypherQuery {&lt;br/&gt;  clauses: [Match {...}],&lt;br/&gt;  return_items: [m.name]&lt;br/&gt;}\"]      Input --&gt; Parser     Parser --&gt; Output <p>Supported Constructs: - Node patterns: <code>(n:Label {prop: value})</code> - Edge patterns: <code>-[:TYPE]-&gt;</code>, <code>&lt;-[:TYPE]-</code>, <code>-[:TYPE]-</code> - WHERE predicates: comparison, boolean logic, IN, IS NULL - Aggregations: COUNT, SUM, AVG, MIN, MAX, COLLECT - Procedures: <code>CALL db.idx.vector.query(...)</code></p>"},{"location":"concepts/architecture/#planner","title":"Planner","text":"<p>Transforms the AST into a Logical Plan with optimizations.</p> flowchart TB     AST[CypherQuery AST]      subgraph Planner[\"QueryPlanner\"]         S1[\"1. Pattern \u2192 Scan/Traverse operators\"]         S2[\"2. WHERE \u2192 Filter operators\"]         S3[\"3. RETURN \u2192 Project operators\"]         S4[\"4. Aggregations \u2192 Aggregate operators\"]         S5[\"5. ORDER BY/LIMIT \u2192 Sort/Limit operators\"]     end      LP[LogicalPlan]      AST --&gt; Planner --&gt; LP <p>Key Optimizations: - Predicate Pushdown: Push filters to storage layer (Lance) - Projection Pruning: Only load required columns - Index Selection: Choose optimal indexes for scans - Join Ordering: Optimize multi-pattern queries</p>"},{"location":"concepts/architecture/#vectorized-executor","title":"Vectorized Executor","text":"<p>Executes logical plans using columnar batch processing.</p> <pre><code>// Conceptual execution flow\nlet batch = scan_operator.execute()?;        // Load VIDs in batch\nlet batch = filter_operator.execute(batch)?; // Apply selection mask\nlet batch = traverse_operator.execute(batch)?; // Batch neighbor lookup\nlet batch = project_operator.execute(batch)?; // Select columns\n</code></pre> <p>Execution Model: - VectorizedBatch: Arrow RecordBatch + selection mask - Morsel-Driven: 1024-4096 rows per batch for cache efficiency - Pipeline Execution: Chain operators without materialization - SIMD Acceleration: Arrow compute kernels for filters/projections</p> <p>Learn more about Vectorized Execution \u2192</p>"},{"location":"concepts/architecture/#runtime-layer","title":"Runtime Layer","text":"<p>The Runtime Layer manages in-memory state, caching, and write coordination.</p>"},{"location":"concepts/architecture/#l0-buffer","title":"L0 Buffer","text":"<p>In-memory buffer for uncommitted mutations. All writes land here first.</p> flowchart TB     M[\"Mutations (INSERT/DELETE)\"]      subgraph L0[\"L0 Buffer\"]         DG[\"DeltaGraph&lt;br/&gt;(gryf-backed)\"]         PM[\"Property Maps&lt;br/&gt;vertex_props, edge_props\"]         TS[\"Tombstones&lt;br/&gt;(Deletes)\"]         VT[\"Version Tracking&lt;br/&gt;current_version: u64\"]     end      Lance[\"Lance Datasets\"]      M --&gt; L0     L0 --&gt;|on flush| Lance <p>Characteristics: - Row-oriented for fast single-record inserts - Backed by Write-Ahead Log for durability - Flushed to L1 (Lance) when size threshold reached - Read-your-writes semantics for queries</p>"},{"location":"concepts/architecture/#adjacency-cache","title":"Adjacency Cache","text":"<p>In-memory CSR (Compressed Sparse Row) cache for O(1) neighbor lookups.</p> <pre><code>       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                   Adjacency Cache                           \u2502\n       \u2502                                                             \u2502\n       \u2502  EdgeType: CITES                                            \u2502\n       \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n       \u2502  \u2502  Vertex 0:  neighbors=[1, 5, 12]   edges=[e0, e1, e2]\u2502   \u2502\n       \u2502  \u2502  Vertex 1:  neighbors=[0, 3]       edges=[e3, e4]    \u2502   \u2502\n       \u2502  \u2502  Vertex 2:  neighbors=[0, 1, 3, 7] edges=[e5,e6,e7,e8]\u2502   \u2502\n       \u2502  \u2502  ...                                                  \u2502   \u2502\n       \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n       \u2502                                                             \u2502\n       \u2502  Storage: DashMap&lt;(EdgeType, Direction), CsrIndex&gt;         \u2502\n       \u2502  Eviction: LRU-based, configurable max size                \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - Eliminates storage round-trips for traversals - Batch neighbor lookups for entire VectorizedBatch - Automatic cache invalidation on L0 flush - Concurrent read access via DashMap</p>"},{"location":"concepts/architecture/#property-manager","title":"Property Manager","text":"<p>Lazy-loads vertex/edge properties from storage on demand.</p> <pre><code>         Query needs n.title, n.year\n              \u2502\n              \u25bc\n       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n       \u2502                   Property Manager                          \u2502\n       \u2502                                                             \u2502\n       \u2502  1. Check LRU cache for (vid, property)                     \u2502\n       \u2502  2. If miss: batch load from Lance                          \u2502\n       \u2502  3. Columnar loading for vectorized access                  \u2502\n       \u2502                                                             \u2502\n       \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n       \u2502  \u2502  Cache: LruCache&lt;(Vid, String), Value&gt;              \u2502   \u2502\n       \u2502  \u2502  Capacity: configurable (default: 10,000 entries)   \u2502   \u2502\n       \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Loading Strategies: - Single Property: <code>get_vertex_prop(vid, \"name\")</code> - Batch Load: <code>get_batch_vertex_props(vids, [\"name\", \"age\"])</code> - Columnar Load: <code>load_properties_columnar(vids, props)</code> \u2192 Arrow arrays</p>"},{"location":"concepts/architecture/#writer","title":"Writer","text":"<p>Coordinates mutations with L0 buffer and WAL.</p> <pre><code>// Writer coordination flow\npub struct Writer {\n    l0_manager: Arc&lt;L0Manager&gt;,      // L0 buffer access\n    storage: Arc&lt;StorageManager&gt;,    // Storage layer\n    allocator: Arc&lt;IdAllocator&gt;,     // VID/EID allocation\n    cache: Option&lt;Arc&lt;AdjacencyCache&gt;&gt;, // Cache invalidation\n}\n\n// Insert vertex\nwriter.insert_vertex(vid, properties)?; // \u2192 L0 + WAL\nwriter.check_flush()?;                   // \u2192 Maybe L0 \u2192 Lance\n</code></pre> <p>Write Flow: 1. Allocate VID via <code>IdAllocator</code> 2. Write to WAL for durability 3. Insert into L0 buffer 4. Return immediately (async durability) 5. Background flush when L0 full</p>"},{"location":"concepts/architecture/#storage-layer","title":"Storage Layer","text":"<p>The Storage Layer provides durable, versioned, columnar storage via Lance.</p>"},{"location":"concepts/architecture/#lance-integration","title":"Lance Integration","text":"<p>Lance is the core storage format, providing:</p> Feature Benefit Columnar Storage Efficient analytical scans Vector Indexes Native HNSW/IVF for ANN search Versioning Time-travel, snapshot isolation Object Store S3/GCS native support Random Access Fast point lookups by row ID"},{"location":"concepts/architecture/#dataset-layout","title":"Dataset Layout","text":"<pre><code>storage/\n\u251c\u2500\u2500 schema.json                    # Schema definition\n\u251c\u2500\u2500 snapshots/\n\u2502   \u2514\u2500\u2500 manifest_v42.json         # Point-in-time snapshot\n\u251c\u2500\u2500 vertices_Paper/               # Per-label vertex dataset\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u251c\u2500\u2500 0000.lance\n\u2502   \u2502   \u2514\u2500\u2500 0001.lance\n\u2502   \u2514\u2500\u2500 _versions/\n\u2502       \u2514\u2500\u2500 42.manifest\n\u251c\u2500\u2500 vertices_Author/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 edges_CITES/                  # Per-type edge dataset\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 adj_out_CITES_Paper/          # Adjacency (outgoing, CITES, from Paper)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 adj_in_CITES_Paper/           # Adjacency (incoming, CITES, to Paper)\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 indexes/\n\u2502   \u251c\u2500\u2500 vector_paper_embedding/   # Vector index\n\u2502   \u2514\u2500\u2500 scalar_author_name/       # Scalar index\n\u2514\u2500\u2500 delta_CITES_out/              # LSM-style delta (L1)\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"concepts/architecture/#vertex-dataset-schema","title":"Vertex Dataset Schema","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        VertexDataset (per label)                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2502\n\u2502 Column       \u2502 Description                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 _vid         \u2502 u64 - Internal vertex ID (label_id &lt;&lt; 48 | offset)           \u2502\n\u2502 _uid         \u2502 [u8; 32] - UniId (SHA3-256 content hash)                     \u2502\n\u2502 _deleted     \u2502 bool - Soft delete flag                                      \u2502\n\u2502 _version     \u2502 u64 - Last modification version                              \u2502\n\u2502 ext_id       \u2502 String - External ID (user-provided)                         \u2502\n\u2502 &lt;properties&gt; \u2502 User-defined columns per schema                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#edge-dataset-schema","title":"Edge Dataset Schema","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         EdgeDataset (per type)                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Column       \u2502 Description                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 eid          \u2502 u64 - Internal edge ID (type_id &lt;&lt; 48 | offset)              \u2502\n\u2502 src_vid      \u2502 u64 - Source vertex VID                                      \u2502\n\u2502 dst_vid      \u2502 u64 - Destination vertex VID                                 \u2502\n\u2502 _deleted     \u2502 bool - Soft delete flag                                      \u2502\n\u2502 _version     \u2502 u64 - Last modification version                              \u2502\n\u2502 &lt;properties&gt; \u2502 User-defined columns per schema                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#adjacency-dataset","title":"Adjacency Dataset","text":"<p>Optimized for O(1) neighbor lookups:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    AdjacencyDataset (per edge type + direction)             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Column       \u2502 Description                                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 src_vid      \u2502 u64 - Source vertex VID                                      \u2502\n\u2502 neighbors    \u2502 List&lt;u64&gt; - All neighbor VIDs                                \u2502\n\u2502 edge_ids     \u2502 List&lt;u64&gt; - Corresponding edge IDs                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nExample row:\n  src_vid=42, neighbors=[1, 7, 23, 99], edge_ids=[e1, e2, e3, e4]\n</code></pre>"},{"location":"concepts/architecture/#data-flow-examples","title":"Data Flow Examples","text":""},{"location":"concepts/architecture/#query-execution-flow","title":"Query Execution Flow","text":"flowchart TB     Q[\"MATCH (p:Paper)-[:CITES]-&gt;(c)&lt;br/&gt;WHERE p.year &gt; 2020&lt;br/&gt;RETURN c.title\"]      subgraph Parse[\"1. PARSE\"]         P1[\"CypherParser tokenizes and builds AST\"]     end      subgraph Plan[\"2. PLAN\"]         P2[\"Project(c.title)&lt;br/&gt;\u2514\u2500\u2500 Traverse(CITES, p \u2192 c)&lt;br/&gt;    \u2514\u2500\u2500 Filter(p.year &gt; 2020)&lt;br/&gt;        \u2514\u2500\u2500 Scan(Paper, p)\"]     end      subgraph Execute[\"3. EXECUTE (Vectorized)\"]         E1[\"a) Scan Paper with filter pushdown\"]         E2[\"b) Traverse CITES via Adjacency Cache\"]         E3[\"c) Late materialize c.title\"]         E4[\"d) Project final columns\"]         E1 --&gt; E2 --&gt; E3 --&gt; E4     end      subgraph Return[\"4. RETURN\"]         R1[\"Convert to output format\"]     end      Q --&gt; Parse --&gt; Plan --&gt; Execute --&gt; Return"},{"location":"concepts/architecture/#write-flow","title":"Write Flow","text":"flowchart TB     C[\"CREATE (n:Paper {title: 'New Paper', year: 2024})\"]      subgraph Allocate[\"1. ALLOCATE ID\"]         A1[\"IdAllocator.allocate_vid(label_id=1)\"]     end      subgraph WAL[\"2. WRITE TO WAL\"]         W1[\"WriteAheadLog.append({op: INSERT_VERTEX, ...})\"]     end      subgraph L0[\"3. INSERT TO L0\"]         L1[\"L0Buffer.insert_vertex(vid, props)\"]         L2[\"Graph structure updated in-memory\"]         L3[\"Properties stored in HashMap\"]     end      subgraph Flush[\"4. CHECK FLUSH\"]         F1{\"mutation_count &gt; max?\"}         F2[\"Flush to Lance\"]         F3[\"Invalidate cache\"]         F4[\"Create snapshot\"]         F1 --&gt;|Yes| F2 --&gt; F3 --&gt; F4     end      C --&gt; Allocate --&gt; WAL --&gt; L0 --&gt; Flush"},{"location":"concepts/architecture/#key-technologies","title":"Key Technologies","text":"Component Technology Purpose Storage Format Lance Columnar, versioned, vector-native Columnar Runtime Apache Arrow Zero-copy data representation Query Processing DataFusion Relational operators, predicate pushdown Graph Runtime gryf In-memory graph algorithms Object Store object_store S3/GCS/Azure abstraction Parsing sqlparser SQL/Cypher tokenization Concurrency DashMap, tokio Thread-safe caching, async I/O"},{"location":"concepts/architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Data Model \u2014 Understand vertices, edges, and properties</li> <li>Identity Model \u2014 VID, EID, and UniId explained</li> <li>Vectorized Execution \u2014 Deep dive into batch processing</li> <li>Storage Engine \u2014 Lance integration and LSM design</li> </ul>"},{"location":"concepts/concurrency/","title":"Concurrency Model","text":"<p>Uni uses a single-writer, multi-reader concurrency model with snapshot-based isolation. This design provides simplicity, consistency, and predictable performance without the complexity of distributed consensus.</p>"},{"location":"concepts/concurrency/#design-philosophy","title":"Design Philosophy","text":"<p>Traditional distributed databases require complex consensus protocols (Raft, Paxos) to maintain consistency across replicas. Uni takes a different approach:</p> Traditional Distributed Uni's Approach Multiple writers Single writer Network consensus Local coordination Eventual consistency Snapshot isolation Complex conflict resolution No conflicts by design Operational complexity Embedded simplicity <p>This model is ideal for: - Embedded databases in applications - Batch processing pipelines - Single-node analytics workloads - Development and testing environments</p>"},{"location":"concepts/concurrency/#architecture","title":"Architecture","text":"flowchart TB     subgraph Writer[\"WRITER (Single)\"]         L0[\"L0 Buffer&lt;br/&gt;(Exclusive)\"]         WAL[\"WAL&lt;br/&gt;(Append-only)\"]         Lance[\"Lance Datasets&lt;br/&gt;(Versioned)\"]         L0 --&gt; WAL --&gt; Lance     end      subgraph Snapshots[\"SNAPSHOT MANIFESTS\"]         V1[v1] --&gt; V2[v2] --&gt; V3[v3] --&gt; V4[\"v4 (current)\"]     end      subgraph Readers[\"READERS (Multiple)\"]         R1[\"Reader 1&lt;br/&gt;(v4)\"]         R2[\"Reader 2&lt;br/&gt;(v4)\"]         R3[\"Reader 3&lt;br/&gt;(v3)\"]         RN[\"Reader N&lt;br/&gt;(v4)\"]     end      Writer --&gt;|Creates snapshots| Snapshots     Snapshots --&gt;|Readers bind to| Readers"},{"location":"concepts/concurrency/#single-writer","title":"Single Writer","text":""},{"location":"concepts/concurrency/#exclusive-write-access","title":"Exclusive Write Access","text":"<p>Only one writer can modify the database at a time:</p> <pre><code>pub struct Writer {\n    l0_manager: Arc&lt;L0Manager&gt;,      // Exclusive L0 access\n    storage: Arc&lt;StorageManager&gt;,     // Storage coordination\n    allocator: Arc&lt;IdAllocator&gt;,      // ID allocation\n    // ...\n}\n</code></pre>"},{"location":"concepts/concurrency/#write-flow","title":"Write Flow","text":"flowchart TB     A[\"1. Application calls&lt;br/&gt;writer.insert_vertex(vid, props)\"]     B[\"2. Acquire write lock&lt;br/&gt;on L0 buffer (Mutex)\"]     C[\"3. Append to WAL&lt;br/&gt;(durability)\"]     D[\"4. Insert into L0 buffer&lt;br/&gt;(in-memory graph + properties)\"]     E[\"5. Increment version counter\"]     F[\"6. Release lock,&lt;br/&gt;return to application\"]      A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F"},{"location":"concepts/concurrency/#why-single-writer","title":"Why Single Writer?","text":"Benefit Explanation No conflicts Writes are serialized, no concurrent modification issues Simple recovery WAL replay is deterministic Predictable latency No lock contention or retry loops Easier reasoning No need to reason about interleaved operations Efficient batching Buffer many writes before flush"},{"location":"concepts/concurrency/#multiple-readers","title":"Multiple Readers","text":""},{"location":"concepts/concurrency/#snapshot-isolation","title":"Snapshot Isolation","text":"<p>Readers operate on consistent snapshots of the database. Each snapshot represents a point-in-time view:</p> <pre><code>pub struct SnapshotManifest {\n    snapshot_id: String,\n    version: u64,\n    timestamp: DateTime&lt;Utc&gt;,\n    labels: HashMap&lt;String, LabelSnapshot&gt;,      // Lance version per label\n    edge_types: HashMap&lt;String, EdgeSnapshot&gt;,   // Lance version per type\n    adjacencies: HashMap&lt;String, Vec&lt;String&gt;&gt;,   // Adjacency chunks\n}\n</code></pre>"},{"location":"concepts/concurrency/#reader-independence","title":"Reader Independence","text":"sequenceDiagram     participant W as Writer     participant S as Snapshots     participant R1 as Reader 1     participant R2 as Reader 2     participant R3 as Reader 3      Note over S: v1 exists     R1-&gt;&gt;S: Start (binds to v1)     W-&gt;&gt;W: Write A     W-&gt;&gt;W: Write B     R1-&gt;&gt;S: Query (sees A, B in L0)     W-&gt;&gt;S: Flush \u2192 creates v2     R2-&gt;&gt;S: Start (binds to v2)     W-&gt;&gt;W: Write C     R2-&gt;&gt;S: Query (sees A, B flushed)     R1-&gt;&gt;R1: End (still v1)     W-&gt;&gt;S: Flush \u2192 creates v3     R3-&gt;&gt;S: Start (binds to v3)     R2-&gt;&gt;R2: End"},{"location":"concepts/concurrency/#read-your-writes","title":"Read-Your-Writes","text":"<p>Readers can optionally include uncommitted L0 buffer data:</p> <pre><code>pub struct ExecutionContext {\n    storage: Arc&lt;StorageManager&gt;,\n    l0_buffer: Option&lt;Arc&lt;RwLock&lt;L0Buffer&gt;&gt;&gt;,  // Optional L0 access\n    snapshot: SnapshotManifest,\n}\n</code></pre> <p>With L0 access: <pre><code>-- Sees both committed (Lance) and uncommitted (L0) data\nCREATE (n:Paper {title: \"New Paper\"})\nMATCH (p:Paper) WHERE p.title = \"New Paper\"  -- Finds it immediately\nRETURN p\n</code></pre></p> <p>Without L0 access (snapshot-only): <pre><code>-- Reader bound to v2, sees only committed data at v2\nMATCH (p:Paper) RETURN COUNT(p)  -- Consistent count at v2\n</code></pre></p>"},{"location":"concepts/concurrency/#snapshot-management","title":"Snapshot Management","text":""},{"location":"concepts/concurrency/#snapshot-creation","title":"Snapshot Creation","text":"<p>Snapshots are created when L0 buffer is flushed to Lance:</p> flowchart TB     Trigger[\"L0 Buffer Full&lt;br/&gt;(or manual flush)\"]     S1[\"1. Write L0 vertices to Lance datasets&lt;br/&gt;vertices_Paper.lance \u2192 new version\"]     S2[\"2. Write L0 edges to Lance datasets&lt;br/&gt;edges_CITES.lance \u2192 new version\"]     S3[\"3. Update adjacency datasets&lt;br/&gt;adj_out_CITES_Paper.lance \u2192 new version\"]     S4[\"4. Create snapshot manifest (atomic write)&lt;br/&gt;snapshots/manifest_v42.json\"]     S5[\"5. Clear L0 buffer,&lt;br/&gt;invalidate adjacency cache\"]      Trigger --&gt; S1 --&gt; S2 --&gt; S3 --&gt; S4 --&gt; S5"},{"location":"concepts/concurrency/#snapshot-manifest-structure","title":"Snapshot Manifest Structure","text":"<pre><code>{\n  \"snapshot_id\": \"snap_20240115_103045_abc123\",\n  \"version\": 42,\n  \"timestamp\": \"2024-01-15T10:30:45.123Z\",\n  \"labels\": {\n    \"Paper\": {\n      \"dataset_version\": 15,\n      \"vertex_count\": 1000000\n    },\n    \"Author\": {\n      \"dataset_version\": 8,\n      \"vertex_count\": 250000\n    }\n  },\n  \"edge_types\": {\n    \"CITES\": {\n      \"dataset_version\": 12,\n      \"edge_count\": 5000000\n    }\n  },\n  \"adjacencies\": {\n    \"CITES_out\": [\"chunk_0.lance\", \"chunk_1.lance\"],\n    \"CITES_in\": [\"chunk_0.lance\", \"chunk_1.lance\"]\n  }\n}\n</code></pre>"},{"location":"concepts/concurrency/#snapshot-lifecycle","title":"Snapshot Lifecycle","text":"State Description Active Current snapshot, new readers bind to this Referenced Old snapshot still in use by active readers Unreferenced No readers, candidate for garbage collection Deleted Removed, storage reclaimed"},{"location":"concepts/concurrency/#consistency-guarantees","title":"Consistency Guarantees","text":""},{"location":"concepts/concurrency/#acid-properties","title":"ACID Properties","text":"Property Guarantee Atomicity Flush is all-or-nothing (manifest written last) Consistency Schema validated on write, constraints enforced Isolation Snapshot isolation for readers Durability WAL ensures writes survive crashes"},{"location":"concepts/concurrency/#isolation-level-comparison","title":"Isolation Level Comparison","text":"Level Uni Equivalent Anomalies Prevented Read Uncommitted With L0 access None Read Committed N/A Dirty reads Repeatable Read Snapshot isolation Dirty reads, non-repeatable reads Serializable Single writer All anomalies"},{"location":"concepts/concurrency/#write-ahead-log-wal","title":"Write-Ahead Log (WAL)","text":"<p>The WAL ensures durability for uncommitted writes:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              WAL STRUCTURE                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   wal/                                                                      \u2502\n\u2502   \u251c\u2500\u2500 segment_000001.log                                                    \u2502\n\u2502   \u251c\u2500\u2500 segment_000002.log                                                    \u2502\n\u2502   \u2514\u2500\u2500 segment_000003.log (current)                                          \u2502\n\u2502                                                                             \u2502\n\u2502   Segment Format:                                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502   \u2502  Length  \u2502   CRC    \u2502   Type   \u2502            Payload               \u2502    \u2502\n\u2502   \u2502 (4 bytes)\u2502 (4 bytes)\u2502 (1 byte) \u2502         (variable)               \u2502    \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2502                                                                             \u2502\n\u2502   Record Types:                                                             \u2502\n\u2502   \u251c\u2500\u2500 INSERT_VERTEX { vid, label_id, properties }                          \u2502\n\u2502   \u251c\u2500\u2500 DELETE_VERTEX { vid }                                                \u2502\n\u2502   \u251c\u2500\u2500 INSERT_EDGE { eid, src_vid, dst_vid, type_id, properties }           \u2502\n\u2502   \u251c\u2500\u2500 DELETE_EDGE { eid }                                                  \u2502\n\u2502   \u2514\u2500\u2500 CHECKPOINT { snapshot_version }                                       \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/concurrency/#recovery-process","title":"Recovery Process","text":"flowchart TB     R1[\"1. Find latest snapshot manifest&lt;br/&gt;\u2192 manifest_v42.json\"]     R2[\"2. Load snapshot state&lt;br/&gt;\u2192 Lance datasets at recorded versions\"]     R3[\"3. Replay WAL from last checkpoint&lt;br/&gt;\u2192 Apply INSERT_VERTEX, DELETE_EDGE, etc.&lt;br/&gt;\u2192 Rebuild L0 buffer\"]     R4[\"4. Resume normal operation&lt;br/&gt;\u2192 Writer ready&lt;br/&gt;\u2192 Readers can bind to snapshot\"]      R1 --&gt; R2 --&gt; R3 --&gt; R4"},{"location":"concepts/concurrency/#concurrency-primitives","title":"Concurrency Primitives","text":""},{"location":"concepts/concurrency/#thread-safe-components","title":"Thread-Safe Components","text":"Component Primitive Pattern L0 Buffer <code>Mutex&lt;L0Buffer&gt;</code> Exclusive write access Adjacency Cache <code>DashMap&lt;K, V&gt;</code> Concurrent read, partitioned write Property Cache <code>Mutex&lt;LruCache&gt;</code> Exclusive access with LRU eviction ID Allocator <code>AtomicU64</code> Lock-free increment Snapshot Manager <code>RwLock&lt;SnapshotManager&gt;</code> Read-heavy access pattern"},{"location":"concepts/concurrency/#example-concurrent-reads","title":"Example: Concurrent Reads","text":"<pre><code>// Multiple readers can execute concurrently\nlet snapshot = snapshot_manager.current().await;\n\n// Reader 1 (thread A)\ntokio::spawn(async move {\n    let results = executor.execute(query1, &amp;snapshot).await?;\n});\n\n// Reader 2 (thread B)\ntokio::spawn(async move {\n    let results = executor.execute(query2, &amp;snapshot).await?;\n});\n\n// Both run concurrently, both see same consistent snapshot\n</code></pre>"},{"location":"concepts/concurrency/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"concepts/concurrency/#single-writer-throughput","title":"Single-Writer Throughput","text":"Operation Latency Throughput L0 insert ~550\u00b5s / 1K vertices ~1.8M vertices/sec WAL append ~10\u00b5s per record ~100K records/sec Flush ~6.3ms / 1K vertices Batched"},{"location":"concepts/concurrency/#scaling-strategies","title":"Scaling Strategies","text":"<ol> <li>Batch Writes: Group many operations before commit</li> <li>Async Flush: Flush in background while accepting new writes</li> <li>Multiple Databases: Shard data across independent Uni instances</li> <li>Read Replicas: Sync snapshots to read-only replicas</li> </ol>"},{"location":"concepts/concurrency/#best-practices","title":"Best Practices","text":""},{"location":"concepts/concurrency/#write-optimization","title":"Write Optimization","text":"<pre><code>// Good: Batch many writes\nlet mut batch = Vec::with_capacity(1000);\nfor item in items {\n    batch.push(create_vertex(item));\n}\nwriter.insert_batch(batch).await?;\n\n// Bad: Many small writes\nfor item in items {\n    writer.insert_vertex(item).await?;  // Overhead per call\n}\n</code></pre>"},{"location":"concepts/concurrency/#reader-management","title":"Reader Management","text":"<pre><code>// Good: Bind to snapshot once, reuse\nlet snapshot = snapshot_manager.current().await;\nfor query in queries {\n    executor.execute(query, &amp;snapshot).await?;  // Same snapshot\n}\n\n// Bad: New snapshot per query (may see inconsistent data)\nfor query in queries {\n    let snapshot = snapshot_manager.current().await;  // Might change\n    executor.execute(query, &amp;snapshot).await?;\n}\n</code></pre>"},{"location":"concepts/concurrency/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture \u2014 System overview</li> <li>Storage Engine \u2014 Lance integration and LSM design</li> <li>Performance Tuning \u2014 Optimization strategies</li> </ul>"},{"location":"concepts/crdt-types/","title":"CRDT Types","text":"<p>Uni includes a comprehensive library of Conflict-free Replicated Data Types (CRDTs) for distributed, eventually-consistent data synchronization.</p>"},{"location":"concepts/crdt-types/#overview","title":"Overview","text":"<p>CRDTs are data structures that can be replicated across multiple nodes, updated independently, and merged without conflicts. They guarantee eventual consistency without coordination.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            CRDT TYPES IN UNI                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    COUNTERS      \u2502      SETS        \u2502           REGISTERS &amp; MAPS            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 GCounter       \u2502 \u2022 GSet           \u2502 \u2022 LWWRegister                         \u2502\n\u2502   (Grow-only)    \u2502   (Grow-only)    \u2502   (Last-Writer-Wins)                  \u2502\n\u2502                  \u2502 \u2022 ORSet          \u2502 \u2022 LWWMap                              \u2502\n\u2502                  \u2502   (Add-wins)     \u2502   (Per-key LWW)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                          SEQUENCES                                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Rga (Replicated Growable Array) - Ordered sequences with insert/delete    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/crdt-types/#crdtmerge-trait","title":"CrdtMerge Trait","text":"<p>All CRDT types implement the <code>CrdtMerge</code> trait:</p> <pre><code>pub trait CrdtMerge {\n    /// Merge another instance into self.\n    /// Must satisfy: commutativity, associativity, idempotency.\n    fn merge(&amp;mut self, other: &amp;Self);\n}\n</code></pre> <p>Properties Guaranteed: - Commutativity: <code>a.merge(b) == b.merge(a)</code> - Associativity: <code>(a.merge(b)).merge(c) == a.merge(b.merge(c))</code> - Idempotency: <code>a.merge(a) == a</code></p>"},{"location":"concepts/crdt-types/#gcounter-grow-only-counter","title":"GCounter (Grow-only Counter)","text":"<p>A counter that can only be incremented. Each node maintains its own count, and the total is the sum across all nodes.</p>"},{"location":"concepts/crdt-types/#use-cases","title":"Use Cases","text":"<ul> <li>View counts</li> <li>Like counters</li> <li>Event tallies</li> <li>Any monotonically increasing metric</li> </ul>"},{"location":"concepts/crdt-types/#api","title":"API","text":"<pre><code>use uni_crdt::GCounter;\n\nlet mut counter = GCounter::new();\n\n// Increment for a specific actor/node\ncounter.increment(\"node_a\", 5);\ncounter.increment(\"node_b\", 3);\ncounter.increment(\"node_a\", 2);\n\n// Get total value\nassert_eq!(counter.value(), 10);\n\n// Get per-actor count\nassert_eq!(counter.actor_count(\"node_a\"), 7);\nassert_eq!(counter.actor_count(\"node_b\"), 3);\n</code></pre>"},{"location":"concepts/crdt-types/#merge-behavior","title":"Merge Behavior","text":"<pre><code>let mut a = GCounter::new();\na.increment(\"A\", 5);\na.increment(\"B\", 2);\n\nlet mut b = GCounter::new();\nb.increment(\"B\", 7);  // B has higher count here\nb.increment(\"C\", 3);\n\na.merge(&amp;b);\n\n// Takes maximum for each actor\nassert_eq!(a.actor_count(\"A\"), 5);\nassert_eq!(a.actor_count(\"B\"), 7);  // max(2, 7)\nassert_eq!(a.actor_count(\"C\"), 3);\nassert_eq!(a.value(), 15);\n</code></pre>"},{"location":"concepts/crdt-types/#gset-grow-only-set","title":"GSet (Grow-only Set)","text":"<p>A set that only supports additions. Elements can never be removed.</p>"},{"location":"concepts/crdt-types/#use-cases_1","title":"Use Cases","text":"<ul> <li>Append-only logs</li> <li>Immutable tag collections</li> <li>User IDs that have seen content</li> <li>One-time events</li> </ul>"},{"location":"concepts/crdt-types/#api_1","title":"API","text":"<pre><code>use uni_crdt::GSet;\n\nlet mut set: GSet&lt;String&gt; = GSet::new();\n\n// Add elements\nset.add(\"apple\".to_string());\nset.add(\"banana\".to_string());\n\n// Check membership\nassert!(set.contains(&amp;\"apple\".to_string()));\nassert!(!set.contains(&amp;\"cherry\".to_string()));\n\n// Iterate elements\nfor elem in set.elements() {\n    println!(\"{}\", elem);\n}\n\nassert_eq!(set.len(), 2);\n</code></pre>"},{"location":"concepts/crdt-types/#merge-behavior_1","title":"Merge Behavior","text":"<pre><code>let mut a: GSet&lt;i32&gt; = GSet::new();\na.add(1);\na.add(2);\n\nlet mut b: GSet&lt;i32&gt; = GSet::new();\nb.add(2);\nb.add(3);\n\na.merge(&amp;b);\n\n// Union of both sets\nassert!(a.contains(&amp;1));\nassert!(a.contains(&amp;2));\nassert!(a.contains(&amp;3));\nassert_eq!(a.len(), 3);\n</code></pre>"},{"location":"concepts/crdt-types/#orset-observed-remove-set","title":"ORSet (Observed-Remove Set)","text":"<p>A set that supports both add and remove operations. Uses unique tags to track element provenance. Concurrent add + remove results in the element being present (add-wins semantics).</p>"},{"location":"concepts/crdt-types/#use-cases_2","title":"Use Cases","text":"<ul> <li>Collaborative editing (selected items)</li> <li>User preferences</li> <li>Shopping carts</li> <li>Any set with deletion support</li> </ul>"},{"location":"concepts/crdt-types/#api_2","title":"API","text":"<pre><code>use uni_crdt::ORSet;\n\nlet mut set: ORSet&lt;String&gt; = ORSet::new();\n\n// Add elements (returns a unique tag)\nlet tag = set.add(\"apple\".to_string());\nset.add(\"banana\".to_string());\n\n// Remove elements\nset.remove(&amp;\"apple\".to_string());\n\n// Check membership\nassert!(!set.contains(&amp;\"apple\".to_string()));\nassert!(set.contains(&amp;\"banana\".to_string()));\n\n// Get visible elements\nlet elements = set.elements();\n</code></pre>"},{"location":"concepts/crdt-types/#add-wins-semantics","title":"Add-Wins Semantics","text":"<pre><code>let mut a: ORSet&lt;String&gt; = ORSet::new();\na.add(\"apple\".to_string());\n\nlet mut b = a.clone();\nb.remove(&amp;\"apple\".to_string());  // Remove on replica B\n\n// Concurrent add on replica A\na.add(\"apple\".to_string());  // New tag created\n\na.merge(&amp;b);\n\n// Add wins! The new tag in 'a' wasn't tombstoned in 'b'\nassert!(a.contains(&amp;\"apple\".to_string()));\n</code></pre>"},{"location":"concepts/crdt-types/#lwwregister-last-writer-wins-register","title":"LWWRegister (Last-Writer-Wins Register)","text":"<p>A single-value register where conflicts are resolved by timestamp. The value with the highest timestamp wins.</p>"},{"location":"concepts/crdt-types/#use-cases_3","title":"Use Cases","text":"<ul> <li>User profile fields</li> <li>Document titles</li> <li>Configuration values</li> <li>Any single-value property</li> </ul>"},{"location":"concepts/crdt-types/#api_3","title":"API","text":"<pre><code>use uni_crdt::LWWRegister;\n\nlet mut reg = LWWRegister::new(\"initial\".to_string(), 100);\n\n// Set with timestamp\nreg.set(\"newer\".to_string(), 110);\nassert_eq!(reg.get(), \"newer\");\n\n// Older timestamp is ignored\nreg.set(\"older\".to_string(), 105);\nassert_eq!(reg.get(), \"newer\");  // Still \"newer\"\n\n// Get current timestamp\nassert_eq!(reg.timestamp(), 110);\n</code></pre>"},{"location":"concepts/crdt-types/#merge-behavior_2","title":"Merge Behavior","text":"<pre><code>let a = LWWRegister::new(\"A\".to_string(), 100);\nlet b = LWWRegister::new(\"B\".to_string(), 110);\n\nlet mut merged = a.clone();\nmerged.merge(&amp;b);\n\n// B wins (higher timestamp)\nassert_eq!(merged.get(), \"B\");\n</code></pre>"},{"location":"concepts/crdt-types/#lwwmap-last-writer-wins-map","title":"LWWMap (Last-Writer-Wins Map)","text":"<p>A map where each key is managed by an independent LWWRegister. Supports put and remove operations.</p>"},{"location":"concepts/crdt-types/#use-cases_4","title":"Use Cases","text":"<ul> <li>User preferences (key-value)</li> <li>Entity properties</li> <li>Configuration maps</li> <li>JSON-like documents</li> </ul>"},{"location":"concepts/crdt-types/#api_4","title":"API","text":"<pre><code>use uni_crdt::LWWMap;\n\nlet mut map: LWWMap&lt;String, i32&gt; = LWWMap::new();\n\n// Put key-value pairs with timestamp\nmap.put(\"a\".to_string(), 1, 100);\nmap.put(\"b\".to_string(), 2, 110);\n\n// Get values\nassert_eq!(map.get(&amp;\"a\".to_string()), Some(&amp;1));\nassert_eq!(map.get(&amp;\"b\".to_string()), Some(&amp;2));\n\n// Remove with timestamp (tombstone)\nmap.remove(&amp;\"a\".to_string(), 120);\nassert_eq!(map.get(&amp;\"a\".to_string()), None);\n\n// Iterate keys\nfor key in map.keys() {\n    println!(\"{}\", key);\n}\n</code></pre>"},{"location":"concepts/crdt-types/#merge-behavior_3","title":"Merge Behavior","text":"<pre><code>let mut a: LWWMap&lt;String, i32&gt; = LWWMap::new();\na.put(\"a\".to_string(), 1, 100);\n\nlet mut b: LWWMap&lt;String, i32&gt; = LWWMap::new();\nb.put(\"a\".to_string(), 2, 110);  // Higher timestamp\nb.put(\"b\".to_string(), 3, 100);\n\na.merge(&amp;b);\n\n// Per-key LWW resolution\nassert_eq!(a.get(&amp;\"a\".to_string()), Some(&amp;2));  // b's value wins\nassert_eq!(a.get(&amp;\"b\".to_string()), Some(&amp;3));\n</code></pre>"},{"location":"concepts/crdt-types/#rga-replicated-growable-array","title":"Rga (Replicated Growable Array)","text":"<p>An ordered sequence supporting insertion and deletion at any position. Used for collaborative text editing and ordered collections.</p>"},{"location":"concepts/crdt-types/#use-cases_5","title":"Use Cases","text":"<ul> <li>Collaborative text editing</li> <li>Ordered lists</li> <li>Comment threads</li> <li>Version histories</li> </ul>"},{"location":"concepts/crdt-types/#api_5","title":"API","text":"<pre><code>use uni_crdt::Rga;\n\nlet mut rga: Rga&lt;char&gt; = Rga::new();\n\n// Insert elements (returns ID for future reference)\nlet id1 = rga.insert(None, 'H', 1);           // Insert at beginning\nlet id2 = rga.insert(Some(id1), 'e', 2);      // Insert after id1\nlet id3 = rga.insert(Some(id2), 'l', 3);\nlet id4 = rga.insert(Some(id3), 'l', 4);\nrga.insert(Some(id4), 'o', 5);\n\n// Convert to vector\nlet text: String = rga.to_vec().into_iter().collect();\nassert_eq!(text, \"Hello\");\n\n// Delete element (tombstone)\nrga.delete(id2);  // Remove 'e'\nlet text: String = rga.to_vec().into_iter().collect();\nassert_eq!(text, \"Hllo\");\n</code></pre>"},{"location":"concepts/crdt-types/#concurrent-insert-resolution","title":"Concurrent Insert Resolution","text":"<pre><code>let mut a: Rga&lt;char&gt; = Rga::new();\nlet id0 = a.insert(None, 'A', 1);\n\nlet mut b = a.clone();\n\n// Concurrent inserts after id0\na.insert(Some(id0), 'B', 2);  // timestamp 2\nb.insert(Some(id0), 'C', 3);  // timestamp 3\n\na.merge(&amp;b);\n\nlet result: String = a.to_vec().into_iter().collect();\n// C comes before B (higher timestamp)\nassert_eq!(result, \"ACB\");\n</code></pre>"},{"location":"concepts/crdt-types/#dynamic-crdt-wrapper","title":"Dynamic CRDT Wrapper","text":"<p>For storage and serialization, Uni provides a dynamic <code>Crdt</code> enum:</p> <pre><code>use uni_crdt::{Crdt, GCounter, CrdtMerge};\n\n// Wrap any CRDT type\nlet mut gc = GCounter::new();\ngc.increment(\"actor1\", 42);\nlet crdt = Crdt::GCounter(gc);\n\n// Serialize to MessagePack\nlet bytes = crdt.to_msgpack().unwrap();\n\n// Deserialize\nlet decoded = Crdt::from_msgpack(&amp;bytes).unwrap();\n\n// Merge works on wrapped types\nlet mut a = Crdt::GCounter(GCounter::new());\nlet b = Crdt::GCounter(GCounter::new());\na.merge(&amp;b);\n</code></pre>"},{"location":"concepts/crdt-types/#supported-variants","title":"Supported Variants","text":"Variant Type Description <code>Crdt::GCounter</code> <code>GCounter</code> Grow-only counter <code>Crdt::GSet</code> <code>GSet&lt;String&gt;</code> Grow-only set <code>Crdt::ORSet</code> <code>ORSet&lt;String&gt;</code> Observed-remove set <code>Crdt::LWWRegister</code> <code>LWWRegister&lt;serde_json::Value&gt;</code> Last-writer-wins register <code>Crdt::LWWMap</code> <code>LWWMap&lt;String, serde_json::Value&gt;</code> Last-writer-wins map <code>Crdt::Rga</code> <code>Rga&lt;String&gt;</code> Replicated growable array"},{"location":"concepts/crdt-types/#choosing-the-right-crdt","title":"Choosing the Right CRDT","text":"Use Case CRDT Type Why Page views, likes GCounter Only increments, no conflict Tags (append-only) GSet Never need removal User selections ORSet Need add/remove with add-wins Single property value LWWRegister Simple conflict resolution Key-value properties LWWMap Per-key conflict resolution Collaborative text Rga Ordered with concurrent edits"},{"location":"concepts/crdt-types/#best-practices","title":"Best Practices","text":""},{"location":"concepts/crdt-types/#1-choose-appropriate-granularity","title":"1. Choose Appropriate Granularity","text":"<pre><code>// Bad: Single LWWRegister for entire document\nlet doc = LWWRegister::new(large_json, timestamp);\n\n// Good: LWWMap with fine-grained keys\nlet mut props = LWWMap::new();\nprops.put(\"title\".to_string(), title_value, ts);\nprops.put(\"author\".to_string(), author_value, ts);\n</code></pre>"},{"location":"concepts/crdt-types/#2-use-logical-timestamps","title":"2. Use Logical Timestamps","text":"<pre><code>// Use hybrid logical clocks or Lamport timestamps\n// Not wall-clock time alone (clock skew issues)\nlet hlc_timestamp = hlc.now();\nregister.set(value, hlc_timestamp);\n</code></pre>"},{"location":"concepts/crdt-types/#3-consider-tombstone-growth","title":"3. Consider Tombstone Growth","text":"<pre><code>// ORSet and LWWMap accumulate tombstones\n// Periodically compact if history not needed\n// Or use garbage collection with causal stability\n</code></pre>"},{"location":"concepts/crdt-types/#4-match-semantics-to-requirements","title":"4. Match Semantics to Requirements","text":"<pre><code>// Need \"add wins\"? Use ORSet\n// Need \"remove wins\"? Use 2P-Set or LWW with remove timestamp\n// Need both? Consider custom CRDT composition\n</code></pre>"},{"location":"concepts/crdt-types/#next-steps","title":"Next Steps","text":"<ul> <li>Identity Model \u2014 UniId for content-addressed CRDT operations</li> <li>Architecture \u2014 How CRDTs integrate with Uni storage</li> <li>Data Model \u2014 Property types and schema definition</li> </ul>"},{"location":"concepts/data-model/","title":"Data Model","text":"<p>Uni combines Property Graph, Document, and Vector concepts into a unified data model. This document explains the core entities, their relationships, and how to define schemas.</p>"},{"location":"concepts/data-model/#core-concepts","title":"Core Concepts","text":"<p>Uni's data model has three primary entity types:</p> flowchart LR     subgraph Source[\"Source\"]         V1[\"VERTEX&lt;br/&gt;(Node)\"]         P1[\"Properties&lt;br/&gt;+ Label\"]     end      subgraph Relationship[\"Relationship\"]         E[\"EDGE&lt;br/&gt;(Relationship)\"]         PE[\"Properties&lt;br/&gt;+ Type\"]     end      subgraph Target[\"Target\"]         V2[\"VERTEX&lt;br/&gt;(Node)\"]         P2[\"Properties&lt;br/&gt;+ Label\"]     end      V1 --&gt; E --&gt; V2     V1 --&gt;|has| P1     E --&gt;|has| PE     V2 --&gt;|has| P2"},{"location":"concepts/data-model/#vertices-nodes","title":"Vertices (Nodes)","text":"<p>Vertices represent entities in your domain. Each vertex has:</p> Component Description Example VID Internal 64-bit identifier <code>0x0001_0000_0000_002A</code> Label(s) Type classification <code>:Paper</code>, <code>:Author</code>, <code>:Venue</code> Properties Key-value attributes <code>{title: \"...\", year: 2023}</code> External ID User-provided identifier <code>\"paper_abc123\"</code>"},{"location":"concepts/data-model/#labels","title":"Labels","text":"<p>Labels categorize vertices and determine their schema. A vertex has exactly one primary label (stored in VID encoding).</p> <pre><code>// Create vertices with labels\nCREATE (p:Paper {title: \"Attention Is All You Need\"})\nCREATE (a:Author {name: \"Ashish Vaswani\"})\nCREATE (v:Venue {name: \"NeurIPS\", year: 2017})\n</code></pre> <p>Label Best Practices: - Use singular nouns: <code>:Paper</code> not <code>:Papers</code> - Use PascalCase: <code>:ResearchPaper</code> not <code>:research_paper</code> - Be specific: <code>:AcademicPaper</code> vs generic <code>:Document</code></p>"},{"location":"concepts/data-model/#properties","title":"Properties","text":"<p>Properties are strongly-typed key-value pairs defined in the schema.</p> <pre><code>{\n  \"Paper\": {\n    \"title\": { \"type\": \"String\", \"nullable\": false },\n    \"year\": { \"type\": \"Int32\", \"nullable\": true },\n    \"abstract\": { \"type\": \"String\", \"nullable\": true },\n    \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 },\n    \"metadata\": { \"type\": \"Json\", \"nullable\": true }\n  }\n}\n</code></pre>"},{"location":"concepts/data-model/#edges-relationships","title":"Edges (Relationships)","text":"<p>Edges connect vertices with typed, directed relationships.</p> Component Description Example EID Internal 64-bit identifier <code>0x0002_0000_0000_0015</code> Type Relationship classification <code>:CITES</code>, <code>:AUTHORED_BY</code> Source Origin vertex (VID) Paper vertex Destination Target vertex (VID) Author vertex Properties Edge attributes <code>{position: 1, role: \"lead\"}</code>"},{"location":"concepts/data-model/#edge-direction","title":"Edge Direction","text":"<p>Edges are always directed (source \u2192 destination):</p> <pre><code>// Paper cites another Paper\n(paper1:Paper)-[:CITES]-&gt;(paper2:Paper)\n\n// Paper is authored by Author\n(paper:Paper)-[:AUTHORED_BY]-&gt;(author:Author)\n\n// Query in either direction\nMATCH (a:Author)&lt;-[:AUTHORED_BY]-(p:Paper)  // Incoming to Author\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)  // Outgoing from Paper\n</code></pre>"},{"location":"concepts/data-model/#edge-type-constraints","title":"Edge Type Constraints","text":"<p>Edge types can constrain which label combinations are valid:</p> <pre><code>{\n  \"edge_types\": {\n    \"CITES\": {\n      \"id\": 1,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Paper\"]\n    },\n    \"AUTHORED_BY\": {\n      \"id\": 2,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Author\"]\n    }\n  }\n}\n</code></pre>"},{"location":"concepts/data-model/#edge-properties","title":"Edge Properties","text":"<p>Edges can carry their own properties:</p> <pre><code>CREATE (p:Paper)-[:AUTHORED_BY {position: 1, contribution: \"lead\"}]-&gt;(a:Author)\n\nMATCH (p:Paper)-[e:AUTHORED_BY]-&gt;(a:Author)\nWHERE e.position = 1\nRETURN p.title, a.name\n</code></pre>"},{"location":"concepts/data-model/#data-types","title":"Data Types","text":"<p>Uni supports a rich set of data types for properties:</p>"},{"location":"concepts/data-model/#primitive-types","title":"Primitive Types","text":"Type Size Range / Description Example <code>String</code> Variable UTF-8 text <code>\"Hello, World\"</code> <code>Int32</code> 4 bytes -2\u00b3\u00b9 to 2\u00b3\u00b9-1 <code>42</code> <code>Int64</code> 8 bytes -2\u2076\u00b3 to 2\u2076\u00b3-1 <code>9223372036854775807</code> <code>Float32</code> 4 bytes IEEE 754 single precision <code>3.14159</code> <code>Float64</code> 8 bytes IEEE 754 double precision <code>3.141592653589793</code> <code>Bool</code> 1 byte true / false <code>true</code> <code>Timestamp</code> 8 bytes Microsecond precision UTC <code>\"2024-01-15T10:30:00Z\"</code>"},{"location":"concepts/data-model/#complex-types","title":"Complex Types","text":"Type Description Example <code>Json</code> Structured JSON document <code>{\"nested\": {\"key\": [1, 2, 3]}}</code> <code>Vector</code> Fixed-dimension float32 array <code>[0.1, -0.2, 0.3, ...]</code> <code>List&lt;T&gt;</code> Variable-length array <code>[\"a\", \"b\", \"c\"]</code>"},{"location":"concepts/data-model/#vector-type","title":"Vector Type","text":"<p>Vectors are first-class citizens for embedding-based search:</p> <pre><code>{\n  \"embedding\": {\n    \"type\": \"Vector\",\n    \"dimensions\": 768,\n    \"nullable\": false\n  }\n}\n</code></pre> <p>Vector Characteristics: - Fixed dimension (immutable after schema creation) - Float32 elements (for storage efficiency) - Indexable with HNSW, IVF_PQ algorithms - Searchable via Cypher procedures</p>"},{"location":"concepts/data-model/#json-type","title":"JSON Type","text":"<p>For semi-structured data with flexible schema:</p> <pre><code>{\n  \"metadata\": {\n    \"type\": \"Json\",\n    \"nullable\": true\n  }\n}\n</code></pre> <p>JSON Capabilities: - Store arbitrary nested structures - Query with JSON path expressions - Index specific paths for performance</p> <pre><code>// Access JSON fields\nMATCH (p:Paper)\nWHERE p.metadata.venue.location = 'Vancouver'\nRETURN p.title\n</code></pre>"},{"location":"concepts/data-model/#schema-definition","title":"Schema Definition","text":"<p>Uni uses a strict schema for performance and storage efficiency. Schemas are defined in JSON.</p>"},{"location":"concepts/data-model/#complete-schema-example","title":"Complete Schema Example","text":"<pre><code>{\n  \"schema_version\": 1,\n\n  \"labels\": {\n    \"Paper\": {\n      \"id\": 1,\n      \"is_document\": true,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    },\n    \"Author\": {\n      \"id\": 2,\n      \"is_document\": false,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    },\n    \"Venue\": {\n      \"id\": 3,\n      \"is_document\": false,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    }\n  },\n\n  \"edge_types\": {\n    \"CITES\": {\n      \"id\": 1,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Paper\"],\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    },\n    \"AUTHORED_BY\": {\n      \"id\": 2,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Author\"],\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    },\n    \"PUBLISHED_IN\": {\n      \"id\": 3,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Venue\"],\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"active\"\n    }\n  },\n\n  \"properties\": {\n    \"Paper\": {\n      \"title\": { \"type\": \"String\", \"nullable\": false },\n      \"abstract\": { \"type\": \"String\", \"nullable\": true },\n      \"year\": { \"type\": \"Int32\", \"nullable\": true },\n      \"doi\": { \"type\": \"String\", \"nullable\": true },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 },\n      \"metadata\": { \"type\": \"Json\", \"nullable\": true }\n    },\n    \"Author\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"email\": { \"type\": \"String\", \"nullable\": true },\n      \"affiliation\": { \"type\": \"String\", \"nullable\": true },\n      \"h_index\": { \"type\": \"Int32\", \"nullable\": true }\n    },\n    \"Venue\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"type\": { \"type\": \"String\", \"nullable\": true },\n      \"location\": { \"type\": \"String\", \"nullable\": true }\n    },\n    \"AUTHORED_BY\": {\n      \"position\": { \"type\": \"Int32\", \"nullable\": true },\n      \"contribution\": { \"type\": \"String\", \"nullable\": true }\n    }\n  },\n\n  \"indexes\": {\n    \"paper_embeddings\": {\n      \"type\": \"vector\",\n      \"label\": \"Paper\",\n      \"property\": \"embedding\",\n      \"config\": {\n        \"index_type\": \"hnsw\",\n        \"metric\": \"cosine\"\n      }\n    },\n    \"author_email\": {\n      \"type\": \"scalar\",\n      \"label\": \"Author\",\n      \"property\": \"email\",\n      \"config\": {\n        \"index_type\": \"btree\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"concepts/data-model/#schema-element-states","title":"Schema Element States","text":"<p>Labels and edge types can be in different lifecycle states:</p> State Description Queryable Writable <code>active</code> Normal operation Yes Yes <code>deprecated</code> Marked for removal Yes Yes <code>hidden</code> No longer queryable No No <code>tombstone</code> Deleted No No"},{"location":"concepts/data-model/#document-mode","title":"Document Mode","text":"<p>Labels marked as <code>is_document: true</code> enable document-specific features:</p>"},{"location":"concepts/data-model/#json-storage","title":"JSON Storage","text":"<p>Store complex nested data beyond the property schema:</p> <pre><code>{\n  \"Paper\": {\n    \"id\": 1,\n    \"is_document\": true\n  }\n}\n</code></pre> <pre><code>CREATE (p:Paper {\n  title: \"Research Paper\",\n  _doc: {\n    figures: [\n      { id: \"fig1\", caption: \"Architecture diagram\" },\n      { id: \"fig2\", caption: \"Results chart\" }\n    ],\n    supplementary: {\n      code_url: \"https://github.com/...\",\n      datasets: [\"imagenet\", \"coco\"]\n    }\n  }\n})\n</code></pre>"},{"location":"concepts/data-model/#json-path-indexing","title":"JSON Path Indexing","text":"<p>Index specific paths within JSON documents:</p> <pre><code>{\n  \"json_indexes\": {\n    \"Paper\": [\n      \"$.supplementary.datasets[*]\",\n      \"$.figures[*].id\"\n    ]\n  }\n}\n</code></pre>"},{"location":"concepts/data-model/#identity-model-summary","title":"Identity Model Summary","text":"ID Type Bits Purpose Example VID 64 Internal vertex identifier <code>0x0001_0000_0000_002A</code> EID 64 Internal edge identifier <code>0x0002_0000_0000_0015</code> ext_id String User-provided external ID <code>\"paper_abc123\"</code> UniId 256 Content-addressed hash <code>bafkrei...</code> <p>Learn more about Identity Model \u2192</p>"},{"location":"concepts/data-model/#querying-the-data-model","title":"Querying the Data Model","text":""},{"location":"concepts/data-model/#pattern-matching","title":"Pattern Matching","text":"<pre><code>// Simple node match\nMATCH (p:Paper)\n\n// Node with properties\nMATCH (p:Paper {year: 2023})\n\n// Relationships\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)\n\n// Multi-hop\nMATCH (p1:Paper)-[:CITES]-&gt;(p2:Paper)-[:CITES]-&gt;(p3:Paper)\n</code></pre>"},{"location":"concepts/data-model/#filtering","title":"Filtering","text":"<pre><code>// Property comparisons\nWHERE p.year &gt; 2020 AND p.year &lt; 2025\n\n// String operations\nWHERE p.title CONTAINS 'Transformer'\n\n// Null checks\nWHERE a.email IS NOT NULL\n\n// List membership\nWHERE p.venue IN ['NeurIPS', 'ICML', 'ICLR']\n</code></pre>"},{"location":"concepts/data-model/#projections","title":"Projections","text":"<pre><code>// Select properties\nRETURN p.title, p.year\n\n// Aliases\nRETURN p.title AS paper_title\n\n// Aggregations\nRETURN COUNT(p) AS total, AVG(p.year) AS avg_year\n</code></pre>"},{"location":"concepts/data-model/#best-practices","title":"Best Practices","text":""},{"location":"concepts/data-model/#schema-design","title":"Schema Design","text":"<ol> <li>Choose labels carefully \u2014 They're encoded in VIDs and can't change</li> <li>Keep properties typed \u2014 Avoid overusing JSON for queryable data</li> <li>Use edge types \u2014 Don't store relationships as vertex properties</li> <li>Plan for vectors \u2014 Dimension can't change after creation</li> </ol>"},{"location":"concepts/data-model/#performance-considerations","title":"Performance Considerations","text":"<ol> <li>Index frequently queried properties \u2014 Especially for WHERE clauses</li> <li>Use vector indexes for embeddings \u2014 HNSW for quality, IVF_PQ for scale</li> <li>Avoid wide vertices \u2014 Many properties = larger Lance rows</li> <li>Leverage label partitioning \u2014 Queries on single label are faster</li> </ol>"},{"location":"concepts/data-model/#next-steps","title":"Next Steps","text":"<ul> <li>Identity Model \u2014 Deep dive into VID/EID encoding</li> <li>Indexing \u2014 Vector, scalar, and full-text indexes</li> <li>Schema Design Guide \u2014 Best practices and patterns</li> </ul>"},{"location":"concepts/identity/","title":"Identity Model","text":"<p>Uni uses a sophisticated identity system to balance performance, flexibility, and distributed computing requirements. This document explains the three identity types and their roles.</p>"},{"location":"concepts/identity/#overview","title":"Overview","text":"<p>Every entity in Uni has multiple identifiers serving different purposes:</p> Identity Bits Purpose Locality VID/EID 64 Internal array indexing Local to database ext_id Variable User-provided external ID User-defined UniId 256 Content-addressed provenance Global / distributed <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         VERTEX IDENTITY STACK                               \u2502\n\u2502                                                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                    User-Facing (ext_id)                              \u2502   \u2502\n\u2502  \u2502                    \"paper_abc123\"                                    \u2502   \u2502\n\u2502  \u2502                    Human-readable, stable across imports             \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                  \u2502 resolves to                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                    Internal (VID)                                    \u2502   \u2502\n\u2502  \u2502                    0x0001_0000_0000_002A                             \u2502   \u2502\n\u2502  \u2502                    Fast array indexing, label-encoded                \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                  \u2502 content-hashes to                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502                    Provenance (UniId)                             \u2502   \u2502\n\u2502  \u2502                    bafkreihdwdcefgh4dqkjv67uzcmw7o...               \u2502   \u2502\n\u2502  \u2502                    Content-addressed, CRDT-compatible                \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/identity/#vertex-id-vid","title":"Vertex ID (VID)","text":"<p>The Vertex ID is a 64-bit packed integer optimized for O(1) array indexing.</p>"},{"location":"concepts/identity/#encoding","title":"Encoding","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              VID (64 bits)                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   label_id (16)  \u2502                  local_offset (48)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   Example: 0x0001_0000_0000_002A                                           \u2502\n\u2502            \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                           \u2502\n\u2502            label    offset                                                 \u2502\n\u2502            (Paper)  (42)                                                   \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Component Bits Range Purpose <code>label_id</code> 16 0 - 65,535 Identifies vertex type (label) <code>local_offset</code> 48 0 - 281 trillion Per-label sequential offset"},{"location":"concepts/identity/#usage-in-code","title":"Usage in Code","text":"<pre><code>use uni::core::Vid;\n\n// Create a VID\nlet vid = Vid::new(1, 42);  // label_id=1 (Paper), offset=42\n\n// Access components\nassert_eq!(vid.label_id(), 1);\nassert_eq!(vid.local_offset(), 42);\nassert_eq!(vid.as_u64(), 0x0001_0000_0000_002A);\n\n// Parse from u64\nlet vid = Vid::from_u64(0x0001_0000_0000_002A);\n</code></pre>"},{"location":"concepts/identity/#why-this-design","title":"Why This Design?","text":"<ol> <li>O(1) Array Indexing: The offset directly indexes into per-label property arrays</li> <li>Label Partitioning: Queries on a single label only scan that label's data</li> <li>Dense Storage: Offsets are sequential, enabling compact columnar storage</li> <li>Type Safety: Label ID embedded in VID prevents cross-label confusion</li> </ol>"},{"location":"concepts/identity/#capacity","title":"Capacity","text":"Component Maximum Practical Limit Labels 65,535 Typically 10-100 Vertices per label 281 trillion Limited by storage Total vertices 18 quintillion Theoretical max"},{"location":"concepts/identity/#edge-id-eid","title":"Edge ID (EID)","text":"<p>Edge IDs follow the same packed 64-bit structure as VIDs.</p>"},{"location":"concepts/identity/#encoding_1","title":"Encoding","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              EID (64 bits)                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   type_id (16)   \u2502                  local_offset (48)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   Example: 0x0002_0000_0000_0015                                           \u2502\n\u2502            \u2500\u2500\u2500\u2500\u2500\u2500 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                           \u2502\n\u2502            type     offset                                                 \u2502\n\u2502            (CITES)  (21)                                                   \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/identity/#usage","title":"Usage","text":"<pre><code>use uni::core::Eid;\n\nlet eid = Eid::new(2, 21);  // type_id=2 (CITES), offset=21\n\nassert_eq!(eid.type_id(), 2);\nassert_eq!(eid.local_offset(), 21);\n</code></pre>"},{"location":"concepts/identity/#external-id-ext_id","title":"External ID (ext_id)","text":"<p>The external ID is a user-provided string identifier for human readability.</p>"},{"location":"concepts/identity/#characteristics","title":"Characteristics","text":"Property Description Type UTF-8 String Uniqueness Unique within a label Mutability Immutable after creation Indexing Automatically indexed for lookups"},{"location":"concepts/identity/#usage_1","title":"Usage","text":"<pre><code>// Create with external ID\nCREATE (p:Paper {id: \"arxiv:2106.09685\", title: \"LoRA\"})\n\n// Query by external ID\nMATCH (p:Paper {id: \"arxiv:2106.09685\"})\nRETURN p.title\n</code></pre>"},{"location":"concepts/identity/#resolution","title":"Resolution","text":"<p>External IDs are resolved to VIDs at query time:</p> <pre><code>ext_id \"arxiv:2106.09685\"\n         \u2502\n         \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  ext_id Index   \u2502  (BTree index on ext_id column)\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502\n             \u25bc\n    VID 0x0001_0000_0000_002A\n</code></pre>"},{"location":"concepts/identity/#uniid","title":"UniId","text":"<p>The UniId is a content-addressed identifier for distributed systems and provenance tracking.</p>"},{"location":"concepts/identity/#characteristics_1","title":"Characteristics","text":"Property Description Algorithm SHA3-256 Encoding Multibase (base32) Length 44 characters Determinism Same content \u2192 same UID"},{"location":"concepts/identity/#format","title":"Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           UniId Structure                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                            \u2502\n\u2502   Multibase prefix: 'b' (base32 lowercase)                                 \u2502\n\u2502                                                                            \u2502\n\u2502   Example: bafkreihdwdcefgh4dqkjv67uzcmw7ojee6xedzdetojuzjevtenxquvyku     \u2502\n\u2502            \u2500                                                               \u2502\n\u2502            \u2514\u2500\u2500 multibase prefix                                            \u2502\n\u2502             \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500       \u2502\n\u2502             \u2514\u2500\u2500 base32 encoded SHA3-256 hash (43 chars)                    \u2502\n\u2502                                                                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/identity/#generation","title":"Generation","text":"<p>UniId is computed from vertex content:</p> <pre><code>use uni::core::UniId;\nuse sha3::{Sha3_256, Digest};\n\n// Content to hash\nlet content = serde_json::json!({\n    \"label\": \"Paper\",\n    \"properties\": {\n        \"title\": \"Attention Is All You Need\",\n        \"year\": 2017\n    }\n});\n\n// Compute SHA3-256\nlet mut hasher = Sha3_256::new();\nhasher.update(content.to_string().as_bytes());\nlet hash = hasher.finalize();\n\n// Create UniId\nlet uid = UniId::from_bytes(&amp;hash);\nprintln!(\"{}\", uid.to_multibase());  // bafkrei...\n</code></pre>"},{"location":"concepts/identity/#use-cases","title":"Use Cases","text":"<ol> <li>Content Deduplication: Same content always produces same UID</li> <li>Distributed Sync: UIDs are globally unique without coordination</li> <li>Audit Trail: Track data provenance across systems</li> <li>CRDT Integration: UIDs enable conflict-free replication across distributed nodes</li> </ol>"},{"location":"concepts/identity/#id-resolution","title":"ID Resolution","text":""},{"location":"concepts/identity/#vid-lookup-by-ext_id","title":"VID Lookup by ext_id","text":"<pre><code>MATCH (p:Paper {id: \"arxiv:2106.09685\"})\n</code></pre> <p>Resolution path: 1. Parse pattern \u2192 extract ext_id value 2. Query ext_id index \u2192 get VID 3. Load vertex data using VID offset</p>"},{"location":"concepts/identity/#vid-lookup-by-uniid","title":"VID Lookup by UniId","text":"<pre><code>MATCH (p:Paper)\nWHERE p._uid = \"bafkreihdwdcefgh4dqkjv67uzcmw7ojee6xedzdetojuzjevtenxquvyku\"\n</code></pre> <p>Resolution path: 1. Query UID index (separate Lance dataset) 2. Get VID from index 3. Load vertex data using VID</p>"},{"location":"concepts/identity/#direction-enum","title":"Direction Enum","text":"<p>For edge traversal, Uni uses a Direction enum:</p> <pre><code>pub enum Direction {\n    Outgoing,  // Source \u2192 Destination\n    Incoming,  // Destination \u2190 Source\n    Both,      // Either direction\n}\n</code></pre>"},{"location":"concepts/identity/#cypher-syntax-mapping","title":"Cypher Syntax Mapping","text":"Cypher Pattern Direction <code>(a)-[:TYPE]-&gt;(b)</code> Outgoing from a <code>(a)&lt;-[:TYPE]-(b)</code> Incoming to a <code>(a)-[:TYPE]-(b)</code> Both"},{"location":"concepts/identity/#id-allocation","title":"ID Allocation","text":"<p>IDs are allocated by the <code>IdAllocator</code>:</p> <pre><code>pub struct IdAllocator {\n    label_counters: DashMap&lt;u16, AtomicU64&gt;,\n    edge_type_counters: DashMap&lt;u16, AtomicU64&gt;,\n}\n\nimpl IdAllocator {\n    pub fn allocate_vid(&amp;self, label_id: u16) -&gt; Vid {\n        let offset = self.label_counters\n            .entry(label_id)\n            .or_insert(AtomicU64::new(0))\n            .fetch_add(1, Ordering::SeqCst);\n        Vid::new(label_id, offset)\n    }\n\n    pub fn allocate_eid(&amp;self, type_id: u16) -&gt; Eid {\n        // Similar for edges\n    }\n}\n</code></pre> <p>Allocation Properties: - Thread-safe via atomic operations - Sequential within each label/type - Persisted on flush for recovery - Never reuses IDs (even after deletes)</p>"},{"location":"concepts/identity/#storage-layout","title":"Storage Layout","text":""},{"location":"concepts/identity/#uid-index-structure","title":"UID Index Structure","text":"<pre><code>indexes/uid_to_vid/{label}/index.lance\n\u251c\u2500\u2500 _uid: FixedSizeBinary(32)  // SHA3-256 hash bytes\n\u2514\u2500\u2500 _vid: UInt64               // Corresponding VID\n</code></pre>"},{"location":"concepts/identity/#resolution-performance","title":"Resolution Performance","text":"Lookup Type Index Complexity Typical Latency VID direct None O(1) ~10\u00b5s ext_id BTree O(log n) ~100\u00b5s UniId BTree O(log n) ~100\u00b5s Full scan None O(n) Varies"},{"location":"concepts/identity/#best-practices","title":"Best Practices","text":""},{"location":"concepts/identity/#choosing-external-ids","title":"Choosing External IDs","text":"<pre><code>\u2713 Good: \"user_12345\", \"arxiv:2106.09685\", \"isbn:978-0134685991\"\n\u2717 Bad: Sequential integers (use VID instead), UUIDs (use UniId)\n</code></pre>"},{"location":"concepts/identity/#when-to-use-each-id","title":"When to Use Each ID","text":"Use Case Recommended ID Internal operations VID API responses ext_id Cross-system sync UniId Human debugging ext_id Array indexing VID offset"},{"location":"concepts/identity/#next-steps","title":"Next Steps","text":"<ul> <li>Data Model \u2014 Vertices, edges, and properties</li> <li>Indexing \u2014 Index types and configuration</li> <li>Architecture \u2014 System overview</li> </ul>"},{"location":"concepts/indexing/","title":"Indexing","text":"<p>Indexes are critical for query performance in Uni. This guide covers all index types, their use cases, and configuration options.</p>"},{"location":"concepts/indexing/#index-types-overview","title":"Index Types Overview","text":"<p>Uni supports five categories of indexes:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              INDEX TYPES                                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    VECTOR INDEXES   \u2502   SCALAR INDEXES    \u2502   FULL-TEXT INDEXES  \u2502   JSON FTS INDEXES   \u2502  INVERTED INDEXES  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 HNSW              \u2502 \u2022 BTree             \u2502 \u2022 Inverted Index     \u2502 \u2022 Lance Inverted     \u2502 \u2022 Set Membership   \u2502\n\u2502 \u2022 IVF_PQ            \u2502 \u2022 Hash              \u2502 \u2022 Tokenizers         \u2502 \u2022 BM25 Ranking       \u2502 \u2022 ANY IN patterns  \u2502\n\u2502 \u2022 Flat (exact)      \u2502 \u2022 Bitmap            \u2502 \u2022 Scoring            \u2502 \u2022 Path-Specific      \u2502 \u2022 Tag filtering    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Similarity search   \u2502 Exact/range queries \u2502 Keyword search       \u2502 JSON document search \u2502 List membership    \u2502\n\u2502 Nearest neighbors   \u2502 Equality checks     \u2502 Text matching        \u2502 CONTAINS operator    \u2502 Multi-value props  \u2502\n\u2502 Embeddings          \u2502 Sorting             \u2502 Relevance ranking    \u2502 Phrase search        \u2502 Security filtering \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/indexing/#vector-indexes","title":"Vector Indexes","text":"<p>Vector indexes enable fast approximate nearest neighbor (ANN) search on embedding columns.</p>"},{"location":"concepts/indexing/#supported-algorithms","title":"Supported Algorithms","text":"Algorithm Description Trade-offs HNSW Hierarchical Navigable Small World Best recall, higher memory IVF_PQ Inverted File + Product Quantization Lower memory, good recall Flat Exact brute-force search Perfect recall, O(n) speed"},{"location":"concepts/indexing/#distance-metrics","title":"Distance Metrics","text":"Metric Formula Use Case Cosine 1 - (A\u00b7B)/(\u2016A\u2016\u2016B\u2016) Normalized embeddings L2 \u221a\u03a3(a\u1d62-b\u1d62)\u00b2 Euclidean distance Dot -A\u00b7B Inner product (unnormalized)"},{"location":"concepts/indexing/#creating-vector-indexes","title":"Creating Vector Indexes","text":"<p>Via Cypher:</p> <pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper)\nON p.embedding\nOPTIONS {\n  index_type: \"hnsw\",\n  metric: \"cosine\",\n  m: 16,\n  ef_construction: 200\n}\n</code></pre> <p>Via CLI:</p> <pre><code>uni index create vector \\\n    --name paper_embeddings \\\n    --label Paper \\\n    --property embedding \\\n    --type hnsw \\\n    --metric cosine \\\n    --m 16 \\\n    --ef-construction 200 \\\n    --path ./storage\n</code></pre>"},{"location":"concepts/indexing/#hnsw-configuration","title":"HNSW Configuration","text":"Parameter Default Description <code>m</code> 16 Max connections per layer (higher = better recall, more memory) <code>ef_construction</code> 200 Build-time search width (higher = better index, slower build) <code>ef_search</code> 100 Query-time search width (higher = better recall, slower query) <p>Tuning Guidelines:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           HNSW Tuning Guide                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Recall vs Speed:                                                          \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                          \u2502\n\u2502   Higher ef_search \u2192 Better recall, slower queries                          \u2502\n\u2502   Lower ef_search  \u2192 Faster queries, may miss results                       \u2502\n\u2502                                                                             \u2502\n\u2502   Memory vs Recall:                                                         \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                                         \u2502\n\u2502   Higher m \u2192 More connections, better recall, more memory                   \u2502\n\u2502   Lower m  \u2192 Less memory, potentially lower recall                          \u2502\n\u2502                                                                             \u2502\n\u2502   Recommended Starting Points:                                              \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                                              \u2502\n\u2502   Small dataset (&lt;100K):  m=16, ef_construction=100, ef_search=50           \u2502\n\u2502   Medium (100K-1M):       m=32, ef_construction=200, ef_search=100          \u2502\n\u2502   Large (&gt;1M):            m=48, ef_construction=400, ef_search=150          \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/indexing/#ivf_pq-configuration","title":"IVF_PQ Configuration","text":"Parameter Default Description <code>num_partitions</code> 256 Number of IVF clusters (\u221an is a good starting point) <code>num_sub_vectors</code> 8 PQ compression factor (dimension / sub_vectors = bytes per vector) <code>num_probes</code> 20 Clusters to search at query time <p>Example:</p> <pre><code>CREATE VECTOR INDEX product_embeddings\nFOR (p:Product)\nON p.embedding\nOPTIONS {\n  index_type: \"ivf_pq\",\n  metric: \"cosine\",\n  num_partitions: 1024,\n  num_sub_vectors: 32,\n  num_probes: 50\n}\n</code></pre>"},{"location":"concepts/indexing/#querying-vector-indexes","title":"Querying Vector Indexes","text":"<p>Procedure Call:</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node, distance\nRETURN node.title, distance\nORDER BY distance\n</code></pre> <p>With Threshold:</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 100, 0.2)\nYIELD node, distance\nWHERE distance &lt; 0.15\nRETURN node.title, distance\n</code></pre> <p>Hybrid (Vector + Graph):</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node as paper, distance\nMATCH (paper)-[:AUTHORED_BY]-&gt;(author:Author)\nRETURN paper.title, author.name, distance\n</code></pre>"},{"location":"concepts/indexing/#scalar-indexes","title":"Scalar Indexes","text":"<p>Scalar indexes optimize exact match and range queries on primitive properties.</p>"},{"location":"concepts/indexing/#index-types","title":"Index Types","text":"Type Operations Best For BTree <code>=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>BETWEEN</code> General purpose, range queries Hash <code>=</code> only High-cardinality exact match Bitmap <code>=</code>, <code>IN</code> Low-cardinality categorical"},{"location":"concepts/indexing/#creating-scalar-indexes","title":"Creating Scalar Indexes","text":"<p>BTree Index (default):</p> <pre><code>CREATE INDEX author_email FOR (a:Author) ON a.email\n</code></pre> <p>Explicit Type:</p> <pre><code>CREATE INDEX paper_year FOR (p:Paper) ON p.year OPTIONS { type: \"btree\" }\nCREATE INDEX user_country FOR (u:User) ON u.country OPTIONS { type: \"bitmap\" }\n</code></pre> <p>Via CLI:</p> <pre><code>uni index create scalar \\\n    --name paper_year \\\n    --label Paper \\\n    --property year \\\n    --type btree \\\n    --path ./storage\n</code></pre>"},{"location":"concepts/indexing/#composite-indexes","title":"Composite Indexes","text":"<p>Index multiple properties together:</p> <pre><code>CREATE INDEX paper_venue_year FOR (p:Paper) ON (p.venue, p.year)\n</code></pre> <p>Query utilization:</p> <pre><code>// Uses index (prefix match)\nMATCH (p:Paper) WHERE p.venue = 'NeurIPS' AND p.year &gt; 2020\n\n// Uses index (first column only)\nMATCH (p:Paper) WHERE p.venue = 'NeurIPS'\n\n// Does NOT use index (missing prefix)\nMATCH (p:Paper) WHERE p.year &gt; 2020\n</code></pre>"},{"location":"concepts/indexing/#index-selection","title":"Index Selection","text":"<p>Uni's query planner automatically selects indexes:</p> <pre><code>Query: MATCH (p:Paper) WHERE p.year &gt; 2020 AND p.venue = 'NeurIPS'\n\nPlan:\n\u251c\u2500\u2500 Project [p.title]\n\u2502   \u2514\u2500\u2500 Scan [:Paper]\n\u2502         \u21b3 Index: paper_venue_year (venue='NeurIPS', year&gt;2020)\n\u2502         \u21b3 Predicate Pushdown: venue = 'NeurIPS' AND year &gt; 2020\n</code></pre>"},{"location":"concepts/indexing/#full-text-indexes","title":"Full-Text Indexes","text":"<p>Full-text indexes enable keyword search within text properties.</p>"},{"location":"concepts/indexing/#creating-full-text-indexes","title":"Creating Full-Text Indexes","text":"<pre><code>CREATE FULLTEXT INDEX paper_search\nFOR (p:Paper)\nON EACH [p.title, p.abstract]\nOPTIONS {\n  tokenizer: \"standard\",\n  min_token_length: 2\n}\n</code></pre>"},{"location":"concepts/indexing/#tokenizers","title":"Tokenizers","text":"Tokenizer Description Example <code>standard</code> Unicode word boundaries \"Hello, World!\" \u2192 [\"hello\", \"world\"] <code>whitespace</code> Split on whitespace only \"Hello, World!\" \u2192 [\"hello,\", \"world!\"] <code>ngram</code> Character n-grams \"cat\" \u2192 [\"ca\", \"at\"] (bigrams) <code>keyword</code> No tokenization \"Hello World\" \u2192 [\"hello world\"]"},{"location":"concepts/indexing/#querying-full-text-indexes","title":"Querying Full-Text Indexes","text":"<pre><code>CALL db.index.fulltext.queryNodes('paper_search', 'transformer attention')\nYIELD node, score\nRETURN node.title, score\nORDER BY score DESC\nLIMIT 10\n</code></pre> <p>Boolean Operators:</p> <pre><code>// AND (default)\n'transformer attention'  // Both terms required\n\n// OR\n'transformer OR attention'\n\n// NOT\n'transformer NOT vision'\n\n// Phrase\n'\"attention mechanism\"'\n\n// Wildcard\n'transform*'\n</code></pre>"},{"location":"concepts/indexing/#json-full-text-indexes","title":"JSON Full-Text Indexes","text":"<p>JSON Full-Text indexes enable BM25-based full-text search on JSON document columns, leveraging Lance's native inverted index.</p>"},{"location":"concepts/indexing/#when-to-use-json-fts","title":"When to Use JSON FTS","text":"Use Case Index Type Search within JSON documents JSON Full-Text Index Keyword/phrase search in text fields JSON Full-Text Index Exact JSON path matching JsonPath Index Equality filters on scalar fields Scalar Index"},{"location":"concepts/indexing/#creating-json-full-text-indexes","title":"Creating JSON Full-Text Indexes","text":"<p>Via Cypher:</p> <pre><code>CREATE JSON FULLTEXT INDEX article_fts\nFOR (a:Article) ON _doc\n</code></pre> <p>With Options:</p> <pre><code>CREATE JSON FULLTEXT INDEX article_fts\nFOR (a:Article) ON _doc\nOPTIONS { with_positions: true }\n</code></pre> <p>The <code>with_positions</code> option enables phrase search by storing term positions.</p> <p>If Not Exists:</p> <pre><code>CREATE JSON FULLTEXT INDEX article_fts IF NOT EXISTS\nFOR (a:Article) ON _doc\n</code></pre>"},{"location":"concepts/indexing/#querying-with-contains","title":"Querying with CONTAINS","text":"<p>Use the <code>CONTAINS</code> operator to perform full-text search on FTS-indexed columns:</p> <pre><code>// Basic full-text search\nMATCH (a:Article)\nWHERE a._doc CONTAINS 'graph database'\nRETURN a.title\n\n// Path-specific search (searches within a JSON path)\nMATCH (a:Article)\nWHERE a._doc.title CONTAINS 'graph'\nRETURN a.title\n\n// Combined with exact matching\nMATCH (a:Article)\nWHERE a._doc.title CONTAINS 'graph' AND a.status = 'published'\nRETURN a.title\n</code></pre>"},{"location":"concepts/indexing/#query-routing-priority","title":"Query Routing Priority","text":"<p>The query planner routes predicates to the most efficient index:</p> <pre><code>1. _uid = 'xxx'           \u2192 UidIndex (O(1) lookup)\n2. column CONTAINS 'term' \u2192 Lance FTS (BM25 ranking)\n3. path = 'exact'         \u2192 JsonPathIndex (exact match)\n4. Pushable predicates    \u2192 Lance scan filter\n5. Else                   \u2192 Residual (post-load filter)\n</code></pre>"},{"location":"concepts/indexing/#json-fts-configuration","title":"JSON FTS Configuration","text":"Parameter Default Description <code>with_positions</code> false Enable phrase search (stores term positions)"},{"location":"concepts/indexing/#how-it-works","title":"How It Works","text":"<p>JSON Full-Text indexes use Lance's inverted index with triplet tokenization:</p> <pre><code>Document: { \"title\": \"Graph Databases\", \"year\": 2024 }\n         \u2193\nTokens:  (title, string, \"graph\"), (title, string, \"databases\"), (year, int, 2024)\n         \u2193\nQuery:   title:graph \u2192 Matches documents with \"graph\" in title path\n</code></pre>"},{"location":"concepts/indexing/#inverted-indexes","title":"Inverted Indexes","text":"<p>Inverted indexes enable efficient filtering on <code>List&lt;String&gt;</code> properties, ideal for tag-based access control and multi-value attribute queries.</p>"},{"location":"concepts/indexing/#use-cases","title":"Use Cases","text":"Use Case Query Pattern Benefit Tag filtering <code>ANY(tag IN d.tags WHERE tag IN $allowed)</code> O(k) vs O(n) scan Security labels Filter by granted access tags Multi-tenant filtering Categories Documents in multiple categories Efficient set intersection Skills matching Users with any required skill Fast membership checks"},{"location":"concepts/indexing/#creating-inverted-indexes","title":"Creating Inverted Indexes","text":"<p>Via Schema:</p> <pre><code>{\n  \"indexes\": {\n    \"document_tags\": {\n      \"type\": \"inverted\",\n      \"label\": \"Document\",\n      \"property\": \"tags\",\n      \"config\": {\n        \"normalize\": true,\n        \"max_terms_per_doc\": 10000\n      }\n    }\n  }\n}\n</code></pre> <p>Via Cypher:</p> <pre><code>CREATE INVERTED INDEX document_tags\nFOR (d:Document)\nON d.tags\nOPTIONS { normalize: true, max_terms_per_doc: 10000 }\n</code></pre> <p>Via Rust API:</p> <pre><code>db.schema()\n    .label(\"Document\")\n        .property(\"tags\", DataType::List(Box::new(DataType::String)))\n        .index(\"tags\", IndexType::Inverted(InvertedIndexConfig {\n            normalize: true,\n            max_terms_per_doc: 10_000,\n        }))\n    .apply()\n    .await?;\n</code></pre>"},{"location":"concepts/indexing/#inverted-index-configuration","title":"Inverted Index Configuration","text":"Parameter Default Description <code>normalize</code> <code>true</code> Lowercase and trim whitespace on terms <code>max_terms_per_doc</code> <code>10_000</code> Maximum terms per document (DoS protection)"},{"location":"concepts/indexing/#query-patterns","title":"Query Patterns","text":"<p>ANY IN pattern (optimized):</p> <pre><code>// Finds documents with ANY of the specified tags\nMATCH (d:Document)\nWHERE ANY(tag IN d.tags WHERE tag IN ['public', 'team:eng'])\nRETURN d.title\n</code></pre> <p>With session variables (multi-tenant):</p> <pre><code>// Security filtering with session-based permissions\nMATCH (d:Document)\nWHERE d.tenant_id = $session.tenant_id\n  AND ANY(tag IN d.tags WHERE tag IN $session.granted_tags)\nRETURN d\n</code></pre>"},{"location":"concepts/indexing/#how-inverted-indexes-work","title":"How Inverted Indexes Work","text":"<pre><code>Document 1: tags = ['rust', 'database']\nDocument 2: tags = ['python', 'ml']\nDocument 3: tags = ['rust', 'ml']\n         \u2193\nInverted Index (term \u2192 VID list):\n  'rust'     \u2192 [vid_1, vid_3]\n  'database' \u2192 [vid_1]\n  'python'   \u2192 [vid_2]\n  'ml'       \u2192 [vid_2, vid_3]\n         \u2193\nQuery: ANY(tag IN d.tags WHERE tag IN ['rust', 'python'])\nResult: Union of 'rust' and 'python' \u2192 [vid_1, vid_2, vid_3]\n</code></pre>"},{"location":"concepts/indexing/#query-planner-integration","title":"Query Planner Integration","text":"<p>When an inverted index exists on a <code>List&lt;String&gt;</code> property, the query planner automatically rewrites <code>ANY IN</code> patterns to use index lookups:</p> <pre><code>Query: MATCH (d:Document) WHERE ANY(tag IN d.tags WHERE tag IN $allowed) RETURN d\n\nWithout Index:\n\u251c\u2500 Full Scan: Document\n\u2514\u2500 Filter: ANY(tag IN d.tags WHERE tag IN $allowed)  // O(n \u00d7 m)\n\nWith Inverted Index:\n\u251c\u2500 Inverted Index Lookup: tags IN $allowed           // O(k)\n\u2514\u2500 Fetch: Document properties\n</code></pre>"},{"location":"concepts/indexing/#performance-comparison","title":"Performance Comparison","text":"Scenario Without Index With Index Speedup 1M docs, 10 tags each, query 3 tags ~5s scan ~10ms 500x 100K docs, security filter ~500ms ~5ms 100x Multi-value category filter ~1s ~15ms 67x"},{"location":"concepts/indexing/#index-management","title":"Index Management","text":""},{"location":"concepts/indexing/#list-indexes","title":"List Indexes","text":"<p>Cypher:</p> <pre><code>SHOW INDEXES\n</code></pre> <p>CLI:</p> <pre><code>uni index list --path ./storage\n</code></pre> <p>Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Name                \u2502 Type   \u2502 Label   \u2502 Property \u2502 Status    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 paper_embeddings    \u2502 Vector \u2502 Paper   \u2502 embedding\u2502 READY     \u2502\n\u2502 paper_year          \u2502 BTree  \u2502 Paper   \u2502 year     \u2502 READY     \u2502\n\u2502 author_email        \u2502 BTree  \u2502 Author  \u2502 email    \u2502 BUILDING  \u2502\n\u2502 paper_search        \u2502 FTS    \u2502 Paper   \u2502 [title,  \u2502 READY     \u2502\n\u2502                     \u2502        \u2502         \u2502 abstract]\u2502           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"concepts/indexing/#drop-indexes","title":"Drop Indexes","text":"<pre><code>DROP INDEX paper_year\n</code></pre> <pre><code>uni index drop paper_year --path ./storage\n</code></pre>"},{"location":"concepts/indexing/#rebuild-indexes","title":"Rebuild Indexes","text":"<pre><code>uni index rebuild paper_embeddings --path ./storage\n</code></pre>"},{"location":"concepts/indexing/#index-storage","title":"Index Storage","text":"<p>Indexes are stored within the Lance dataset structure:</p> <pre><code>storage/\n\u251c\u2500\u2500 vertices_Paper/\n\u2502   \u251c\u2500\u2500 data/\n\u2502   \u2502   \u2514\u2500\u2500 *.lance\n\u2502   \u251c\u2500\u2500 _indices/                    # Lance native indexes\n\u2502   \u2502   \u2514\u2500\u2500 embedding_idx-uuid/      # Vector index\n\u2502   \u2502       \u251c\u2500\u2500 index.idx\n\u2502   \u2502       \u2514\u2500\u2500 aux/\n\u2502   \u2514\u2500\u2500 _versions/\n\u2514\u2500\u2500 indexes/\n    \u251c\u2500\u2500 scalar_paper_year/           # Separate scalar index\n    \u2502   \u2514\u2500\u2500 index.lance\n    \u2514\u2500\u2500 fulltext_paper_search/       # Full-text index\n        \u2514\u2500\u2500 index/\n</code></pre>"},{"location":"concepts/indexing/#predicate-pushdown","title":"Predicate Pushdown","text":"<p>Indexes integrate with Uni's predicate pushdown optimization:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                        PREDICATE PUSHDOWN FLOW                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper) WHERE p.year &gt; 2020 AND p.title CONTAINS 'AI'     \u2502\n\u2502                                                                             \u2502\n\u2502   1. Predicate Analysis                                                     \u2502\n\u2502      \u251c\u2500\u2500 p.year &gt; 2020      \u2192 Pushable (scalar index or Lance filter)      \u2502\n\u2502      \u2514\u2500\u2500 p.title CONTAINS   \u2192 Residual (post-load filter)                  \u2502\n\u2502                                                                             \u2502\n\u2502   2. Index Selection                                                        \u2502\n\u2502      \u2514\u2500\u2500 paper_year index available? Yes \u2192 Use index scan                  \u2502\n\u2502                                                                             \u2502\n\u2502   3. Execution                                                              \u2502\n\u2502      \u251c\u2500\u2500 Index Scan: year &gt; 2020 \u2192 VIDs [v1, v2, v3, ...]                  \u2502\n\u2502      \u251c\u2500\u2500 Load Properties: title for filtered VIDs                          \u2502\n\u2502      \u2514\u2500\u2500 Residual Filter: title CONTAINS 'AI'                              \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/indexing/#pushable-predicates","title":"Pushable Predicates","text":"Predicate Index Type Pushed? <code>p.x = 5</code> BTree, Hash Yes <code>p.x &gt; 5</code> BTree Yes <code>p.x IN [1,2,3]</code> BTree, Bitmap Yes <code>p.x IS NULL</code> BTree Yes <code>p._doc CONTAINS 'foo'</code> JSON FTS Yes (if FTS-indexed) <code>p.x CONTAINS 'foo'</code> None No (residual, if not FTS-indexed) <code>p.x STARTS WITH 'foo'</code> BTree Partial <code>func(p.x) = 5</code> None No (residual)"},{"location":"concepts/indexing/#best-practices","title":"Best Practices","text":""},{"location":"concepts/indexing/#when-to-create-indexes","title":"When to Create Indexes","text":"<pre><code>\u2713 CREATE INDEX when:\n  \u2022 Property appears in WHERE clauses frequently\n  \u2022 Property is used for JOIN conditions\n  \u2022 Property is used in ORDER BY\n  \u2022 High-cardinality exact match queries (Hash)\n  \u2022 Range queries on numeric/date properties (BTree)\n  \u2022 Low-cardinality categorical filters (Bitmap)\n\n\u2717 AVOID INDEX when:\n  \u2022 Property rarely queried\n  \u2022 Very small dataset (&lt;1000 rows)\n  \u2022 Property updated frequently\n  \u2022 Very low selectivity (e.g., boolean with 50/50 split)\n</code></pre>"},{"location":"concepts/indexing/#index-sizing","title":"Index Sizing","text":"Index Type Memory Formula Example (1M vectors, 768d) HNSW ~1.5x vectors \u00d7 (4 + m\u00d78) bytes ~120 MB IVF_PQ vectors \u00d7 (d/sub_vectors) bytes ~24 MB BTree ~40 bytes per key ~40 MB Bitmap ~n_distinct \u00d7 rows / 8 bytes Varies"},{"location":"concepts/indexing/#index-maintenance","title":"Index Maintenance","text":"<pre><code># Check index health\nuni index stats --path ./storage\n\n# Rebuild fragmented index\nuni index rebuild paper_embeddings --path ./storage\n\n# Optimize after bulk load\nuni index optimize --path ./storage\n</code></pre>"},{"location":"concepts/indexing/#performance-comparison_1","title":"Performance Comparison","text":"Query Type Without Index With Index Speedup Point lookup O(n) scan O(log n) BTree 1000x+ Range query O(n) scan O(log n + k) 100x+ Vector KNN O(n\u00d7d) brute O(log n) HNSW 1000x+ Full-text O(n\u00d7len) scan O(log n) inverted 100x+"},{"location":"concepts/indexing/#next-steps","title":"Next Steps","text":"<ul> <li>Vector Search Guide \u2014 Deep dive into similarity search</li> <li>Performance Tuning \u2014 Optimization strategies</li> <li>Query Planning \u2014 How indexes are selected</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Get up and running with Uni in minutes.</p>   ### [Installation](installation.md) Build Uni from source, install prerequisites, and verify your setup.     ### [Quick Start](quickstart.md) Create your first graph, import data, and run queries in 5 minutes.     ### [CLI Reference](cli-reference.md) Complete documentation for all Uni command-line tools."},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before installing Uni, ensure you have:</p> <ul> <li>Rust 1.75+ \u2014 Install via rustup</li> <li>8GB+ RAM \u2014 Recommended for development</li> <li>Git \u2014 For cloning the repository</li> </ul>"},{"location":"getting-started/#quick-install","title":"Quick Install","text":"<pre><code># Clone and build\ngit clone https://github.com/dragonscale/uni.git\ncd uni\ncargo build --release\n\n# Verify installation\n./target/release/uni --version\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Once installed, follow the Quick Start guide to create your first graph database.</p>"},{"location":"getting-started/cli-reference/","title":"CLI Reference","text":"<p>Complete reference for the <code>uni</code> command-line interface. The CLI provides tools for data import, query execution, and server management.</p>"},{"location":"getting-started/cli-reference/#synopsis","title":"Synopsis","text":"<pre><code>uni [OPTIONS] &lt;COMMAND&gt;\n</code></pre>"},{"location":"getting-started/cli-reference/#global-options","title":"Global Options","text":"Option Description <code>-h, --help</code> Print help information <code>-V, --version</code> Print version information <code>-v, --verbose</code> Enable verbose logging (can be repeated: -vv, -vvv) <code>--quiet</code> Suppress non-essential output <code>--log-format &lt;FORMAT&gt;</code> Log format: <code>text</code> (default), <code>json</code>"},{"location":"getting-started/cli-reference/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>RUST_LOG</code> Log level filter (e.g., <code>info</code>, <code>debug</code>, <code>uni=debug</code>) <code>warn</code> <code>UNI_STORAGE_PATH</code> Default storage path <code>./storage</code> <code>UNI_CONFIG</code> Path to configuration file <code>./uni.toml</code> <code>AWS_REGION</code> AWS region for S3 storage \u2014 <code>AWS_ACCESS_KEY_ID</code> AWS access key \u2014 <code>AWS_SECRET_ACCESS_KEY</code> AWS secret key \u2014"},{"location":"getting-started/cli-reference/#commands","title":"Commands","text":""},{"location":"getting-started/cli-reference/#import-import-data","title":"<code>import</code> \u2014 Import Data","text":"<p>Import vertices and edges from JSONL files into a new or existing database.</p>"},{"location":"getting-started/cli-reference/#synopsis_1","title":"Synopsis","text":"<pre><code>uni import &lt;NAME&gt; [OPTIONS]\n</code></pre>"},{"location":"getting-started/cli-reference/#arguments","title":"Arguments","text":"Argument Description <code>&lt;NAME&gt;</code> Dataset name identifier (e.g., <code>semantic-scholar</code>, <code>products</code>)"},{"location":"getting-started/cli-reference/#options","title":"Options","text":"Option Description Required <code>--papers &lt;PATH&gt;</code> Path to vertices JSONL file Yes <code>--citations &lt;PATH&gt;</code> Path to edges JSONL file Yes <code>--output &lt;PATH&gt;</code> Output directory for storage No (default: <code>./storage</code>) <code>--schema &lt;PATH&gt;</code> Path to schema JSON file No (auto-inferred) <code>--batch-size &lt;N&gt;</code> Records per batch during import No (default: 10000) <code>--skip-validation</code> Skip schema validation (faster but risky) No <code>--force</code> Overwrite existing storage No"},{"location":"getting-started/cli-reference/#examples","title":"Examples","text":"<p>Basic import: <pre><code>uni import products \\\n    --papers ./data/products.jsonl \\\n    --citations ./data/purchases.jsonl \\\n    --output ./product-graph\n</code></pre></p> <p>Import with custom schema: <pre><code>uni import research \\\n    --papers ./papers.jsonl \\\n    --citations ./citations.jsonl \\\n    --schema ./schema.json \\\n    --output ./research-graph\n</code></pre></p> <p>Large dataset with tuned batch size: <pre><code>uni import wikipedia \\\n    --papers ./articles.jsonl \\\n    --citations ./links.jsonl \\\n    --batch-size 50000 \\\n    --output s3://my-bucket/wiki-graph\n</code></pre></p>"},{"location":"getting-started/cli-reference/#input-file-format","title":"Input File Format","text":"<p>Vertices JSONL: <pre><code>{\"id\": \"node_123\", \"label\": \"Product\", \"name\": \"Widget\", \"price\": 29.99, \"embedding\": [0.1, 0.2, ...]}\n</code></pre></p> <ul> <li><code>id</code> (required): Unique string identifier</li> <li><code>label</code> (optional): Vertex label (default: inferred from import name)</li> <li>Additional fields: Property key-value pairs</li> </ul> <p>Edges JSONL: <pre><code>{\"src\": \"user_456\", \"dst\": \"node_123\", \"type\": \"PURCHASED\", \"timestamp\": \"2024-01-15T10:30:00Z\"}\n</code></pre></p> <ul> <li><code>src</code> (required): Source vertex ID</li> <li><code>dst</code> (required): Destination vertex ID</li> <li><code>type</code> (optional): Edge type (default: <code>RELATES_TO</code>)</li> <li>Additional fields: Edge properties</li> </ul>"},{"location":"getting-started/cli-reference/#query-execute-queries","title":"<code>query</code> \u2014 Execute Queries","text":"<p>Run OpenCypher queries against a database.</p>"},{"location":"getting-started/cli-reference/#synopsis_2","title":"Synopsis","text":"<pre><code>uni query &lt;STATEMENT&gt; [OPTIONS]\n</code></pre>"},{"location":"getting-started/cli-reference/#arguments_1","title":"Arguments","text":"Argument Description <code>&lt;STATEMENT&gt;</code> Cypher query string"},{"location":"getting-started/cli-reference/#options_1","title":"Options","text":"Option Description Default <code>--path &lt;PATH&gt;</code> Storage directory path <code>./storage</code>"},{"location":"getting-started/cli-reference/#examples_1","title":"Examples","text":"<p>Basic query with table output: <pre><code>uni query \"MATCH (n:Person) RETURN n.name LIMIT 10\" --path ./social-graph\n</code></pre></p> <p>Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 n.name   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Alice    \u2502\n\u2502 Bob      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"getting-started/cli-reference/#repl-interactive-shell","title":"<code>repl</code> \u2014 Interactive Shell","text":"<p>Start the interactive UniDB shell for running Cypher queries.</p>"},{"location":"getting-started/cli-reference/#synopsis_3","title":"Synopsis","text":"<pre><code>uni repl [OPTIONS]\n# or simply\nuni\n</code></pre>"},{"location":"getting-started/cli-reference/#options_2","title":"Options","text":"Option Description Default <code>--path &lt;PATH&gt;</code> Storage directory path <code>./storage</code>"},{"location":"getting-started/cli-reference/#shell-commands","title":"Shell Commands","text":"<p>Within the REPL, you can use the following commands:</p> Command Description <code>help</code> Show available commands <code>clear</code> Clear the screen <code>exit</code>, <code>quit</code> Exit the REPL <code>&lt;cypher&gt;</code> Execute a Cypher query"},{"location":"getting-started/cli-reference/#snapshot-manage-snapshots","title":"<code>snapshot</code> \u2014 Manage Snapshots","text":"<p>Create, list, and restore database snapshots for point-in-time recovery and history tracking.</p>"},{"location":"getting-started/cli-reference/#synopsis_4","title":"Synopsis","text":"<pre><code>uni snapshot &lt;SUBCOMMAND&gt; [OPTIONS]\n</code></pre>"},{"location":"getting-started/cli-reference/#subcommands","title":"Subcommands","text":"<p><code>list</code> \u2014 List all available snapshots. <pre><code>uni snapshot list --path ./storage\n</code></pre></p> <p><code>create</code> \u2014 Create a new named snapshot. <pre><code>uni snapshot create [--name &lt;NAME&gt;] --path ./storage\n</code></pre></p> <p><code>restore</code> \u2014 Restore the database to a specific snapshot ID. <pre><code>uni snapshot restore &lt;ID&gt; --path ./storage\n</code></pre></p>"},{"location":"getting-started/cli-reference/#start-start-server","title":"<code>start</code> \u2014 Start Server","text":"<p>Start the Uni HTTP API server for remote access.</p>"},{"location":"getting-started/cli-reference/#synopsis_5","title":"Synopsis","text":"<pre><code>uni start [OPTIONS]\n</code></pre>"},{"location":"getting-started/cli-reference/#options_3","title":"Options","text":"Option Description Default <code>--port &lt;PORT&gt;</code> HTTP port to listen on 8080 <code>--host &lt;HOST&gt;</code> Host address to bind <code>127.0.0.1</code> <code>--path &lt;PATH&gt;</code> Storage directory path <code>./storage</code> <code>--workers &lt;N&gt;</code> Number of worker threads CPU count <code>--read-only</code> Disable write operations false <code>--cors</code> Enable CORS for all origins false"},{"location":"getting-started/cli-reference/#examples_2","title":"Examples","text":"<p>Start on default port: <pre><code>uni start --path ./my-graph\n</code></pre></p> <p>Production configuration: <pre><code>uni start \\\n    --host 0.0.0.0 \\\n    --port 9000 \\\n    --path s3://bucket/graph \\\n    --workers 8 \\\n    --read-only\n</code></pre></p>"},{"location":"getting-started/cli-reference/#api-endpoints","title":"API Endpoints","text":"<p>When the server is running:</p> Endpoint Method Description <code>/health</code> GET Health check <code>/query</code> POST Execute Cypher query <code>/schema</code> GET Get schema definition <code>/stats</code> GET Database statistics <p>Query API example: <pre><code>curl -X POST http://localhost:8080/query \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"query\": \"MATCH (n) RETURN COUNT(n)\"}'\n</code></pre></p> <p>Response: <pre><code>{\n  \"results\": [{\"COUNT(n)\": 10000}],\n  \"stats\": {\n    \"rows\": 1,\n    \"execution_time_ms\": 12.5\n  }\n}\n</code></pre></p>"},{"location":"getting-started/cli-reference/#schema-stats-and-index-management","title":"Schema, Stats, and Index Management","text":"<p>Schema inspection, database statistics, and index management are available through Cypher queries in the REPL or via the query command:</p> <p>Schema inspection: <pre><code># View labels\nuni query \"CALL db.labels() YIELD label RETURN label\" --path ./graph\n\n# View relationship types\nuni query \"CALL db.relationshipTypes() YIELD relationshipType RETURN relationshipType\" --path ./graph\n\n# View indexes\nuni query \"SHOW INDEXES\" --path ./graph\n</code></pre></p> <p>Database statistics: <pre><code># Count vertices and edges\nuni query \"MATCH (n) RETURN labels(n)[0] AS label, count(*) AS count\" --path ./graph\n\n# Count by edge type\nuni query \"MATCH ()-[r]-&gt;() RETURN type(r) AS type, count(*) AS count\" --path ./graph\n</code></pre></p> <p>Index management: <pre><code># Create a vector index\nuni query \"CREATE VECTOR INDEX paper_emb FOR (p:Paper) ON p.embedding OPTIONS {type: 'hnsw', metric: 'cosine'}\" --path ./graph\n\n# Create a scalar index\nuni query \"CREATE INDEX author_name FOR (a:Author) ON a.name\" --path ./graph\n\n# Drop an index\nuni query \"DROP INDEX paper_emb\" --path ./graph\n</code></pre></p>"},{"location":"getting-started/cli-reference/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Success 1 General error 2 Invalid arguments 3 Storage error (file not found, permission denied) 4 Query error (parse error, execution failure) 5 Timeout exceeded"},{"location":"getting-started/cli-reference/#shell-completion","title":"Shell Completion","text":"<p>Generate shell completions for faster CLI usage:</p> <p>Bash: <pre><code>uni completions bash &gt; /etc/bash_completion.d/uni\n</code></pre></p> <p>Zsh: <pre><code>uni completions zsh &gt; ~/.zsh/completions/_uni\n</code></pre></p> <p>Fish: <pre><code>uni completions fish &gt; ~/.config/fish/completions/uni.fish\n</code></pre></p>"},{"location":"getting-started/cli-reference/#see-also","title":"See Also","text":"<ul> <li>Quick Start \u2014 Tutorial introduction</li> <li>Cypher Querying \u2014 Query language reference</li> <li>Configuration \u2014 Configuration file options</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This guide covers all methods for installing Uni, from building from source to using pre-built binaries.</p>"},{"location":"getting-started/installation/#system-requirements","title":"System Requirements","text":""},{"location":"getting-started/installation/#minimum-requirements","title":"Minimum Requirements","text":"Component Requirement OS Linux (x86_64, aarch64), macOS (x86_64, Apple Silicon) Memory 4 GB RAM minimum, 16 GB recommended for large graphs Disk SSD recommended for optimal performance Rust 1.75+ (if building from source)"},{"location":"getting-started/installation/#build-dependencies","title":"Build Dependencies","text":"<p>Building Uni requires several system dependencies:</p> Dependency Purpose Installation Rust toolchain Compilation rustup.rs Clang/LLVM Lance native dependencies System package manager Protocol Buffers Lance serialization System package manager pkg-config Build configuration System package manager OpenSSL TLS for object store access System package manager"},{"location":"getting-started/installation/#installation-methods","title":"Installation Methods","text":""},{"location":"getting-started/installation/#method-1-build-from-source-recommended","title":"Method 1: Build from Source (Recommended)","text":"<p>Building from source provides the latest features and allows customization.</p>"},{"location":"getting-started/installation/#step-1-install-rust","title":"Step 1: Install Rust","text":"<pre><code># Install rustup (Rust toolchain manager)\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n\n# Reload your shell configuration\nsource $HOME/.cargo/env\n\n# Verify installation\nrustc --version\ncargo --version\n</code></pre>"},{"location":"getting-started/installation/#step-2-install-system-dependencies","title":"Step 2: Install System Dependencies","text":"<p>Ubuntu / Debian: <pre><code>sudo apt update\nsudo apt install -y \\\n    build-essential \\\n    pkg-config \\\n    libssl-dev \\\n    protobuf-compiler \\\n    clang \\\n    llvm\n</code></pre></p> <p>Fedora / RHEL: <pre><code>sudo dnf install -y \\\n    gcc \\\n    gcc-c++ \\\n    pkg-config \\\n    openssl-devel \\\n    protobuf-compiler \\\n    clang \\\n    llvm\n</code></pre></p> <p>macOS: <pre><code># Install Homebrew if not present\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install dependencies\nbrew install protobuf llvm pkg-config openssl@3\n\n# Add LLVM to PATH (for Apple Silicon)\necho 'export PATH=\"/opt/homebrew/opt/llvm/bin:$PATH\"' &gt;&gt; ~/.zshrc\nsource ~/.zshrc\n</code></pre></p> <p>Arch Linux: <pre><code>sudo pacman -S base-devel pkg-config openssl protobuf clang llvm\n</code></pre></p>"},{"location":"getting-started/installation/#step-3-clone-and-build","title":"Step 3: Clone and Build","text":"<pre><code># Clone the repository\ngit clone https://github.com/dragonscale/uni.git\ncd uni\n\n# Build in release mode (optimized)\ncargo build --release\n\n# The binary is now at target/release/uni\nls -la target/release/uni\n</code></pre>"},{"location":"getting-started/installation/#step-4-install-to-path-optional","title":"Step 4: Install to PATH (Optional)","text":"<pre><code># Option A: Copy to /usr/local/bin\nsudo cp target/release/uni /usr/local/bin/\n\n# Option B: Add cargo bin to PATH\necho 'export PATH=\"$HOME/.cargo/bin:$PATH\"' &gt;&gt; ~/.bashrc\ncargo install --path .\n</code></pre>"},{"location":"getting-started/installation/#method-2-using-cargo-install","title":"Method 2: Using Cargo Install","text":"<p>If you only need the CLI and don't require source modifications:</p> <pre><code># Install directly from the repository\ncargo install --git https://github.com/dragonscale/uni.git\n\n# Or from crates.io (when published)\ncargo install uni\n</code></pre>"},{"location":"getting-started/installation/#method-3-docker","title":"Method 3: Docker","text":"<p>Run Uni in a containerized environment:</p> <pre><code># Build the Docker image\ndocker build -t uni:latest .\n\n# Run with local storage mounted\ndocker run -v $(pwd)/storage:/data uni:latest \\\n    query \"MATCH (n) RETURN n LIMIT 10\" --path /data\n</code></pre> <p>Docker Compose example:</p> <pre><code>version: '3.8'\nservices:\n  uni:\n    build: .\n    volumes:\n      - ./storage:/data\n      - ./schema.json:/app/schema.json\n    environment:\n      - UNI_STORAGE_PATH=/data\n      - RUST_LOG=info\n</code></pre>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>After installation, verify Uni is working correctly:</p>"},{"location":"getting-started/installation/#check-version","title":"Check Version","text":"<pre><code>uni --version\n# Output: uni 0.1.0\n</code></pre>"},{"location":"getting-started/installation/#display-help","title":"Display Help","text":"<pre><code>uni --help\n</code></pre> <p>Expected output: <pre><code>Uni - The Embedded Multi-Model Graph Database\n\nUsage: uni &lt;COMMAND&gt;\n\nCommands:\n  import  Import data from JSONL files\n  query   Execute a Cypher query\n  start   Start the HTTP server\n  help    Print this message or the help of the given subcommand(s)\n\nOptions:\n  -h, --help     Print help\n  -V, --version  Print version\n</code></pre></p>"},{"location":"getting-started/installation/#run-a-simple-query","title":"Run a Simple Query","text":"<pre><code># Create a test directory\nmkdir -p /tmp/uni-test\n\n# Run a query (will create empty storage)\nuni query \"RETURN 1 + 1 AS result\" --path /tmp/uni-test\n\n# Expected output:\n# \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n# \u2502 result \u2502\n# \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n# \u2502 2      \u2502\n# \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting-installation","title":"Troubleshooting Installation","text":""},{"location":"getting-started/installation/#common-issues","title":"Common Issues","text":""},{"location":"getting-started/installation/#protoc-not-found","title":"\"protoc not found\"","text":"<pre><code># Ubuntu/Debian\nsudo apt install protobuf-compiler\n\n# macOS\nbrew install protobuf\n\n# Verify\nprotoc --version\n</code></pre>"},{"location":"getting-started/installation/#failed-to-run-custom-build-command-for-ring","title":"\"failed to run custom build command for <code>ring</code>\"","text":"<p>This usually indicates missing C compiler or LLVM:</p> <pre><code># Ubuntu/Debian\nsudo apt install build-essential clang\n\n# macOS\nxcode-select --install\n</code></pre>"},{"location":"getting-started/installation/#openssl-not-found","title":"\"openssl not found\"","text":"<pre><code># Ubuntu/Debian\nsudo apt install libssl-dev pkg-config\n\n# macOS\nbrew install openssl@3\nexport OPENSSL_DIR=$(brew --prefix openssl@3)\n</code></pre>"},{"location":"getting-started/installation/#slow-compilation","title":"Slow Compilation","text":"<p>Enable parallel compilation and use the <code>mold</code> linker:</p> <pre><code># Install mold (Linux)\nsudo apt install mold\n\n# Configure Cargo to use mold\ncat &gt;&gt; ~/.cargo/config.toml &lt;&lt; EOF\n[target.x86_64-unknown-linux-gnu]\nlinker = \"clang\"\nrustflags = [\"-C\", \"link-arg=-fuse-ld=mold\"]\nEOF\n\n# Rebuild\ncargo build --release\n</code></pre>"},{"location":"getting-started/installation/#feature-flags","title":"Feature Flags","text":"<p>Uni supports optional features that can be enabled during compilation:</p> Feature Description Default <code>fastembed</code> Local embedding model support Enabled <code>s3</code> Amazon S3 object store Enabled <code>gcs</code> Google Cloud Storage Disabled <code>azure</code> Azure Blob Storage Disabled"},{"location":"getting-started/installation/#custom-build-example","title":"Custom Build Example","text":"<pre><code># Minimal build (local filesystem only)\ncargo build --release --no-default-features\n\n# Build with all cloud providers\ncargo build --release --features \"s3,gcs,azure\"\n\n# Build without embedding support (smaller binary)\ncargo build --release --no-default-features --features \"s3\"\n</code></pre>"},{"location":"getting-started/installation/#development-setup","title":"Development Setup","text":"<p>For contributing to Uni, set up the full development environment:</p> <pre><code># Clone with submodules\ngit clone --recursive https://github.com/dragonscale/uni.git\ncd uni\n\n# Install development tools\ncargo install cargo-watch cargo-nextest\n\n# Run tests\ncargo nextest run\n\n# Run with hot-reload during development\ncargo watch -x \"run -- query 'RETURN 1'\"\n\n# Check code quality\ncargo fmt --check\ncargo clippy -- -D warnings\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that Uni is installed:</p> <ol> <li>Quick Start \u2014 Import data and run your first queries</li> <li>CLI Reference \u2014 Learn all available commands</li> <li>Data Model \u2014 Understand vertices, edges, and properties</li> </ol>"},{"location":"getting-started/programming-guide/","title":"Programming Guide","text":"<p>This guide walks you through building applications with Uni using the Rust or Python API. Select your preferred language - all code examples will switch to match your choice.</p>"},{"location":"getting-started/programming-guide/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have Uni installed for your language:</p> RustPython <p>Add Uni to your <code>Cargo.toml</code>:</p> <pre><code>[dependencies]\nuni = \"0.1\"\ntokio = { version = \"1\", features = [\"full\"] }\n</code></pre> <p>Install from PyPI or build from source:</p> <pre><code>pip install uni\n\n# Or build from source\ncd bindings/python\npip install maturin\nmaturin develop --release\n</code></pre>"},{"location":"getting-started/programming-guide/#opening-a-database","title":"Opening a Database","text":"<p>The first step is opening or creating a database. Uni uses a builder pattern for configuration.</p> RustPython <pre><code>use uni::prelude::*;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Open or create a database (creates if doesn't exist)\n    let db = Uni::open(\"./my-graph\").build().await?;\n\n    // Open existing database (fails if doesn't exist)\n    let db = Uni::open_existing(\"./my-graph\").build().await?;\n\n    // Create new database (fails if already exists)\n    let db = Uni::create(\"./my-graph\").build().await?;\n\n    // In-memory database (for testing)\n    let db = Uni::in_memory().build().await?;\n\n    Ok(())\n}\n</code></pre> <pre><code>import uni\n\n# Open or create a database (creates if doesn't exist)\ndb = uni.DatabaseBuilder.open(\"./my-graph\").build()\n\n# Open existing database (fails if doesn't exist)\ndb = uni.DatabaseBuilder.open_existing(\"./my-graph\").build()\n\n# Create new database (fails if already exists)\ndb = uni.DatabaseBuilder.create(\"./my-graph\").build()\n\n# Temporary in-memory database\ndb = uni.DatabaseBuilder.temporary().build()\n\n# Simple shorthand (open or create)\ndb = uni.Database(\"./my-graph\")\n</code></pre>"},{"location":"getting-started/programming-guide/#configuration-options","title":"Configuration Options","text":"<p>Configure cache size, parallelism, and other options:</p> RustPython <pre><code>let db = Uni::open(\"./my-graph\")\n    .cache_size(2 * 1024 * 1024 * 1024)  // 2 GB cache\n    .parallelism(8)                       // 8 worker threads\n    .build()\n    .await?;\n</code></pre> <pre><code>db = (\n    uni.DatabaseBuilder.open(\"./my-graph\")\n    .cache_size(2 * 1024 * 1024 * 1024)  # 2 GB cache\n    .parallelism(8)                       # 8 worker threads\n    .build()\n)\n</code></pre>"},{"location":"getting-started/programming-guide/#defining-schema","title":"Defining Schema","text":"<p>Before inserting data, define your graph schema with vertex labels, edge types, and properties.</p>"},{"location":"getting-started/programming-guide/#using-the-schema-builder","title":"Using the Schema Builder","text":"RustPython <pre><code>db.schema()\n    // Define Person vertex type\n    .label(\"Person\")\n        .property(\"name\", DataType::String)\n        .property(\"age\", DataType::Int32)\n        .property_nullable(\"email\", DataType::String)\n        .index(\"name\", IndexType::Scalar(ScalarType::Hash))\n    // Define Company vertex type\n    .label(\"Company\")\n        .property(\"name\", DataType::String)\n        .property(\"founded\", DataType::Int32)\n    // Define WORKS_AT edge type (Person -&gt; Company)\n    .edge_type(\"WORKS_AT\", &amp;[\"Person\"], &amp;[\"Company\"])\n        .property(\"since\", DataType::Int32)\n        .property_nullable(\"role\", DataType::String)\n    // Define KNOWS edge type (Person -&gt; Person)\n    .edge_type(\"KNOWS\", &amp;[\"Person\"], &amp;[\"Person\"])\n    .apply()\n    .await?;\n</code></pre> <pre><code>schema = db.schema()\n\n# Define Person vertex type\nschema = (\n    schema.label(\"Person\")\n    .property(\"name\", \"string\")\n    .property(\"age\", \"int\")\n    .property_nullable(\"email\", \"string\")\n    .index(\"name\", \"hash\")\n    .done()\n)\n\n# Define Company vertex type\nschema = (\n    schema.label(\"Company\")\n    .property(\"name\", \"string\")\n    .property(\"founded\", \"int\")\n    .done()\n)\n\n# Define edge types\nschema = (\n    schema.edge_type(\"WORKS_AT\", [\"Person\"], [\"Company\"])\n    .property(\"since\", \"int\")\n    .property_nullable(\"role\", \"string\")\n    .done()\n)\n\nschema = (\n    schema.edge_type(\"KNOWS\", [\"Person\"], [\"Person\"])\n    .done()\n)\n\n# Apply all schema changes\nschema.apply()\n</code></pre>"},{"location":"getting-started/programming-guide/#quick-schema-methods","title":"Quick Schema Methods","text":"<p>For simple cases, use the direct methods:</p> RustPython <pre><code>// Create label\ndb.create_label(\"Person\").await?;\n\n// Add property (label, name, type)\ndb.add_property(\"Person\", \"name\", DataType::String, false).await?;  // required\ndb.add_property(\"Person\", \"email\", DataType::String, true).await?;  // nullable\n\n// Create index\ndb.create_scalar_index(\"Person\", \"name\", ScalarType::Hash).await?;\n</code></pre> <pre><code># Create label\ndb.create_label(\"Person\")\n\n# Add property (label, name, type, nullable)\ndb.add_property(\"Person\", \"name\", \"string\", False)  # required\ndb.add_property(\"Person\", \"email\", \"string\", True)  # nullable\n\n# Create index\ndb.create_scalar_index(\"Person\", \"name\", \"hash\")\n</code></pre>"},{"location":"getting-started/programming-guide/#basic-queries","title":"Basic Queries","text":"<p>Execute Cypher queries to read and write data.</p>"},{"location":"getting-started/programming-guide/#creating-data","title":"Creating Data","text":"RustPython <pre><code>// Create a single vertex\ndb.execute(\"CREATE (p:Person {name: 'Alice', age: 30})\").await?;\n\n// Create multiple vertices and an edge\ndb.execute(r#\"\n    CREATE (alice:Person {name: 'Alice', age: 30})\n    CREATE (bob:Person {name: 'Bob', age: 25})\n    CREATE (alice)-[:KNOWS {since: 2020}]-&gt;(bob)\n\"#).await?;\n\n// Create edge between existing vertices\ndb.execute(r#\"\n    MATCH (a:Person {name: 'Alice'}), (c:Company {name: 'TechCorp'})\n    CREATE (a)-[:WORKS_AT {since: 2022, role: 'Engineer'}]-&gt;(c)\n\"#).await?;\n</code></pre> <pre><code># Create a single vertex\ndb.execute(\"CREATE (p:Person {name: 'Alice', age: 30})\")\n\n# Create multiple vertices and an edge\ndb.execute(\"\"\"\n    CREATE (alice:Person {name: 'Alice', age: 30})\n    CREATE (bob:Person {name: 'Bob', age: 25})\n    CREATE (alice)-[:KNOWS {since: 2020}]-&gt;(bob)\n\"\"\")\n\n# Create edge between existing vertices\ndb.execute(\"\"\"\n    MATCH (a:Person {name: 'Alice'}), (c:Company {name: 'TechCorp'})\n    CREATE (a)-[:WORKS_AT {since: 2022, role: 'Engineer'}]-&gt;(c)\n\"\"\")\n</code></pre>"},{"location":"getting-started/programming-guide/#reading-data","title":"Reading Data","text":"RustPython <pre><code>// Simple query\nlet results = db.query(\"MATCH (p:Person) RETURN p.name, p.age\").await?;\n\nfor row in &amp;results {\n    let name: String = row.get(\"p.name\")?;\n    let age: i32 = row.get(\"p.age\")?;\n    println!(\"{} is {} years old\", name, age);\n}\n\n// Query with filtering and ordering\nlet results = db.query(r#\"\n    MATCH (p:Person)\n    WHERE p.age &gt;= 25\n    RETURN p.name AS name, p.age AS age\n    ORDER BY p.age DESC\n    LIMIT 10\n\"#).await?;\n\nfor row in &amp;results {\n    println!(\"{}: {}\", row.get::&lt;String&gt;(\"name\")?, row.get::&lt;i32&gt;(\"age\")?);\n}\n</code></pre> <pre><code># Simple query\nresults = db.query(\"MATCH (p:Person) RETURN p.name AS name, p.age AS age\")\n\nfor row in results:\n    print(f\"{row['name']} is {row['age']} years old\")\n\n# Query with filtering and ordering\nresults = db.query(\"\"\"\n    MATCH (p:Person)\n    WHERE p.age &gt;= 25\n    RETURN p.name AS name, p.age AS age\n    ORDER BY p.age DESC\n    LIMIT 10\n\"\"\")\n\nfor row in results:\n    print(f\"{row['name']}: {row['age']}\")\n</code></pre>"},{"location":"getting-started/programming-guide/#parameterized-queries","title":"Parameterized Queries","text":"<p>Always use parameters for user-provided values to prevent injection attacks:</p> RustPython <pre><code>// Single parameter\nlet results = db.query_with(\"MATCH (p:Person) WHERE p.name = $name RETURN p\")\n    .param(\"name\", \"Alice\")\n    .fetch_all()\n    .await?;\n\n// Multiple parameters\nlet results = db.query_with(r#\"\n    MATCH (p:Person)\n    WHERE p.age &gt;= $min_age AND p.age &lt;= $max_age\n    RETURN p.name AS name, p.age AS age\n\"#)\n    .param(\"min_age\", 20)\n    .param(\"max_age\", 40)\n    .fetch_all()\n    .await?;\n\n// Parameters from HashMap\nlet params = hashmap! {\n    \"name\" =&gt; \"Alice\".into(),\n    \"company\" =&gt; \"TechCorp\".into(),\n};\nlet results = db.query_with(\n    \"MATCH (p:Person {name: $name})-[:WORKS_AT]-&gt;(c:Company {name: $company}) RETURN p, c\"\n)\n    .params(params)\n    .fetch_all()\n    .await?;\n</code></pre> <pre><code># Single parameter\nresults = (\n    db.query_with(\"MATCH (p:Person) WHERE p.name = $name RETURN p.name AS name\")\n    .param(\"name\", \"Alice\")\n    .fetch_all()\n)\n\n# Multiple parameters\nresults = (\n    db.query_with(\"\"\"\n        MATCH (p:Person)\n        WHERE p.age &gt;= $min_age AND p.age &lt;= $max_age\n        RETURN p.name AS name, p.age AS age\n    \"\"\")\n    .param(\"min_age\", 20)\n    .param(\"max_age\", 40)\n    .fetch_all()\n)\n\n# Parameters from dict\nparams = {\"name\": \"Alice\", \"company\": \"TechCorp\"}\nresults = (\n    db.query_with(\"\"\"\n        MATCH (p:Person {name: $name})-[:WORKS_AT]-&gt;(c:Company {name: $company})\n        RETURN p.name AS person, c.name AS company\n    \"\"\")\n    .params(params)\n    .fetch_all()\n)\n</code></pre>"},{"location":"getting-started/programming-guide/#graph-traversals","title":"Graph Traversals","text":"<p>Traverse relationships to explore connected data.</p>"},{"location":"getting-started/programming-guide/#basic-traversal","title":"Basic Traversal","text":"RustPython <pre><code>// Find all people that Alice knows\nlet results = db.query(r#\"\n    MATCH (alice:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend:Person)\n    RETURN friend.name AS name\n\"#).await?;\n\n// Find friends of friends\nlet results = db.query(r#\"\n    MATCH (alice:Person {name: 'Alice'})-[:KNOWS*2]-&gt;(fof:Person)\n    WHERE fof.name &lt;&gt; 'Alice'\n    RETURN DISTINCT fof.name AS name\n\"#).await?;\n\n// Variable-length paths (1 to 3 hops)\nlet results = db.query(r#\"\n    MATCH path = (alice:Person {name: 'Alice'})-[:KNOWS*1..3]-&gt;(other:Person)\n    RETURN other.name AS name, length(path) AS distance\n\"#).await?;\n</code></pre> <pre><code># Find all people that Alice knows\nresults = db.query(\"\"\"\n    MATCH (alice:Person {name: 'Alice'})-[:KNOWS]-&gt;(friend:Person)\n    RETURN friend.name AS name\n\"\"\")\n\n# Find friends of friends\nresults = db.query(\"\"\"\n    MATCH (alice:Person {name: 'Alice'})-[:KNOWS*2]-&gt;(fof:Person)\n    WHERE fof.name &lt;&gt; 'Alice'\n    RETURN DISTINCT fof.name AS name\n\"\"\")\n\n# Variable-length paths (1 to 3 hops)\nresults = db.query(\"\"\"\n    MATCH path = (alice:Person {name: 'Alice'})-[:KNOWS*1..3]-&gt;(other:Person)\n    RETURN other.name AS name, length(path) AS distance\n\"\"\")\n</code></pre>"},{"location":"getting-started/programming-guide/#aggregations","title":"Aggregations","text":"RustPython <pre><code>// Count friends per person\nlet results = db.query(r#\"\n    MATCH (p:Person)-[:KNOWS]-&gt;(friend:Person)\n    RETURN p.name AS person, COUNT(friend) AS friend_count\n    ORDER BY friend_count DESC\n\"#).await?;\n\n// Average age by company\nlet results = db.query(r#\"\n    MATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\n    RETURN c.name AS company, AVG(p.age) AS avg_age, COUNT(p) AS employees\n\"#).await?;\n</code></pre> <pre><code># Count friends per person\nresults = db.query(\"\"\"\n    MATCH (p:Person)-[:KNOWS]-&gt;(friend:Person)\n    RETURN p.name AS person, COUNT(friend) AS friend_count\n    ORDER BY friend_count DESC\n\"\"\")\n\n# Average age by company\nresults = db.query(\"\"\"\n    MATCH (p:Person)-[:WORKS_AT]-&gt;(c:Company)\n    RETURN c.name AS company, AVG(p.age) AS avg_age, COUNT(p) AS employees\n\"\"\")\n</code></pre>"},{"location":"getting-started/programming-guide/#transactions","title":"Transactions","text":"<p>Group multiple operations into atomic transactions.</p>"},{"location":"getting-started/programming-guide/#explicit-transactions","title":"Explicit Transactions","text":"RustPython <pre><code>// Begin transaction\nlet tx = db.begin().await?;\n\n// Execute operations\ntx.execute(\"CREATE (p:Person {name: 'Carol', age: 28})\").await?;\ntx.execute(\"CREATE (p:Person {name: 'Dave', age: 32})\").await?;\ntx.execute(r#\"\n    MATCH (c:Person {name: 'Carol'}), (d:Person {name: 'Dave'})\n    CREATE (c)-[:KNOWS]-&gt;(d)\n\"#).await?;\n\n// Commit (or rollback on error)\ntx.commit().await?;\n</code></pre> <pre><code># Begin transaction\ntx = db.begin()\n\ntry:\n    # Execute operations\n    tx.query(\"CREATE (p:Person {name: 'Carol', age: 28})\")\n    tx.query(\"CREATE (p:Person {name: 'Dave', age: 32})\")\n    tx.query(\"\"\"\n        MATCH (c:Person {name: 'Carol'}), (d:Person {name: 'Dave'})\n        CREATE (c)-[:KNOWS]-&gt;(d)\n    \"\"\")\n\n    # Commit\n    tx.commit()\nexcept Exception as e:\n    # Rollback on error\n    tx.rollback()\n    raise e\n</code></pre>"},{"location":"getting-started/programming-guide/#transaction-closure-rust","title":"Transaction Closure (Rust)","text":"RustPython <pre><code>// Auto-commit on success, auto-rollback on error\ndb.transaction(|tx| async move {\n    tx.execute(\"CREATE (a:Person {name: 'Eve', age: 26})\").await?;\n    tx.execute(\"CREATE (b:Person {name: 'Frank', age: 29})\").await?;\n    tx.execute(r#\"\n        MATCH (e:Person {name: 'Eve'}), (f:Person {name: 'Frank'})\n        CREATE (e)-[:KNOWS]-&gt;(f)\n    \"#).await?;\n    Ok(())\n}).await?;\n</code></pre> <pre><code># Python uses explicit try/except pattern shown above\n# No closure-based API available\n</code></pre>"},{"location":"getting-started/programming-guide/#vector-search","title":"Vector Search","text":"<p>Store and search vector embeddings for semantic similarity.</p>"},{"location":"getting-started/programming-guide/#setting-up-vector-properties","title":"Setting Up Vector Properties","text":"RustPython <pre><code>// Add vector property to schema\ndb.schema()\n    .label(\"Document\")\n        .property(\"title\", DataType::String)\n        .property(\"content\", DataType::String)\n        .vector(\"embedding\", 384)  // 384 dimensions\n        .index(\"embedding\", IndexType::Vector(VectorIndexCfg {\n            algorithm: VectorAlgo::Hnsw { m: 16, ef_construction: 200 },\n            metric: VectorMetric::Cosine,\n        }))\n    .apply()\n    .await?;\n</code></pre> <pre><code># Add vector property (vector:N syntax for N dimensions)\ndb.add_property(\"Document\", \"embedding\", \"vector:384\", False)\n\n# Create vector index (label, property, metric)\ndb.create_vector_index(\"Document\", \"embedding\", \"cosine\")\n</code></pre>"},{"location":"getting-started/programming-guide/#inserting-vectors","title":"Inserting Vectors","text":"RustPython <pre><code>// Insert document with embedding\nlet embedding: Vec&lt;f32&gt; = compute_embedding(\"Machine learning fundamentals\");\n\ndb.query_with(r#\"\n    CREATE (d:Document {\n        title: $title,\n        content: $content,\n        embedding: $embedding\n    })\n\"#)\n    .param(\"title\", \"ML Basics\")\n    .param(\"content\", \"Machine learning fundamentals...\")\n    .param(\"embedding\", embedding)\n    .fetch_all()\n    .await?;\n</code></pre> <pre><code># Insert document with embedding\nembedding = compute_embedding(\"Machine learning fundamentals\")\n\ndb.query_with(\"\"\"\n    CREATE (d:Document {\n        title: $title,\n        content: $content,\n        embedding: $embedding\n    })\n\"\"\").param(\"title\", \"ML Basics\") \\\n   .param(\"content\", \"Machine learning fundamentals...\") \\\n   .param(\"embedding\", embedding) \\\n   .fetch_all()\n</code></pre>"},{"location":"getting-started/programming-guide/#searching-vectors","title":"Searching Vectors","text":"RustPython <pre><code>// Simple vector search\nlet query_vec = compute_embedding(\"deep learning neural networks\");\nlet matches = db.vector_search(\"Document\", \"embedding\", query_vec.clone(), 10).await?;\n\nfor m in &amp;matches {\n    println!(\"VID: {}, Distance: {:.4}\", m.vid, m.distance);\n}\n\n// Vector search with builder (filters and options)\nlet results = db.vector_search_with(\"Document\", \"embedding\", query_vec)\n    .k(20)\n    .threshold(0.5)  // Only results with distance &lt; 0.5\n    .filter(\"node.category = 'tutorial'\")\n    .fetch_nodes()\n    .await?;\n\nfor (node, distance) in results {\n    println!(\"{} ({:.4})\", node.get::&lt;String&gt;(\"title\")?, distance);\n}\n\n// Vector search via Cypher\nlet results = db.query_with(r#\"\n    CALL db.idx.vector.query('Document', 'embedding', $vec, 10)\n    YIELD node, distance\n    RETURN node.title AS title, distance\n    ORDER BY distance\n\"#)\n    .param(\"vec\", query_vec)\n    .fetch_all()\n    .await?;\n</code></pre> <pre><code># Simple vector search\nquery_vec = compute_embedding(\"deep learning neural networks\")\nmatches = db.vector_search(\"Document\", \"embedding\", query_vec, k=10)\n\nfor m in matches:\n    print(f\"VID: {m.vid}, Distance: {m.distance:.4f}\")\n\n# Vector search with builder (filters and options)\nresults = (\n    db.vector_search_with(\"Document\", \"embedding\", query_vec)\n    .k(20)\n    .threshold(0.5)  # Only results with distance &lt; 0.5\n    .search()\n)\n\nfor m in results:\n    print(f\"VID: {m.vid}, Distance: {m.distance:.4f}\")\n\n# Vector search via Cypher\nresults = db.query_with(\"\"\"\n    CALL db.idx.vector.query('Document', 'embedding', $vec, 10)\n    YIELD node, distance\n    RETURN node.title AS title, distance\n    ORDER BY distance\n\"\"\").param(\"vec\", query_vec).fetch_all()\n\nfor row in results:\n    print(f\"{row['title']}: {row['distance']:.4f}\")\n</code></pre>"},{"location":"getting-started/programming-guide/#bulk-loading","title":"Bulk Loading","text":"<p>For large datasets, use the bulk writer for efficient loading.</p> RustPython <pre><code>// Create bulk writer with deferred indexing\nlet mut bulk = db.bulk_writer()\n    .defer_vector_indexes(true)\n    .defer_scalar_indexes(true)\n    .batch_size(50_000)\n    .on_progress(|p| {\n        println!(\"{:?}: {} rows processed\", p.phase, p.rows_processed);\n    })\n    .build()?;\n\n// Insert vertices in bulk\nlet people: Vec&lt;HashMap&lt;String, Value&gt;&gt; = (0..100_000)\n    .map(|i| hashmap! {\n        \"name\" =&gt; format!(\"Person-{}\", i).into(),\n        \"age\" =&gt; (20 + i % 50).into(),\n    })\n    .collect();\n\nlet vids = bulk.insert_vertices(\"Person\", people).await?;\n\n// Insert edges in bulk (src_vid, dst_vid, properties)\nlet edges: Vec&lt;EdgeData&gt; = vids.windows(2)\n    .map(|pair| EdgeData {\n        src: pair[0],\n        dst: pair[1],\n        properties: hashmap! { \"since\" =&gt; 2024.into() },\n    })\n    .collect();\n\nbulk.insert_edges(\"KNOWS\", edges).await?;\n\n// Commit and rebuild indexes\nlet stats = bulk.commit().await?;\nprintln!(\n    \"Loaded {} vertices, {} edges in {:?}\",\n    stats.vertices_inserted, stats.edges_inserted, stats.duration\n);\n</code></pre> <pre><code># Create bulk writer with configuration\nwriter = (\n    db.bulk_writer()\n    .batch_size(50_000)\n    .build()\n)\n\n# Insert vertices in bulk\npeople = [\n    {\"name\": f\"Person-{i}\", \"age\": 20 + i % 50}\n    for i in range(100_000)\n]\n\nvids = writer.insert_vertices(\"Person\", people)\n\n# Insert edges in bulk (src_vid, dst_vid, properties)\nedges = [\n    (vids[i], vids[i + 1], {\"since\": 2024})\n    for i in range(len(vids) - 1)\n]\n\nwriter.insert_edges(\"KNOWS\", edges)\n\n# Commit and rebuild indexes\nstats = writer.commit()\nprint(f\"Loaded {stats.vertices_inserted} vertices, {stats.edges_inserted} edges\")\n</code></pre>"},{"location":"getting-started/programming-guide/#sessions","title":"Sessions","text":"<p>Sessions provide scoped context for multi-tenant queries.</p> RustPython <pre><code>// Create session with tenant context\nlet session = db.session()\n    .set(\"tenant_id\", \"acme-corp\")\n    .set(\"user_id\", \"user-123\")\n    .build();\n\n// All queries have access to $session.* variables\nlet results = session.query(r#\"\n    MATCH (d:Document)\n    WHERE d.tenant_id = $session.tenant_id\n    RETURN d.title AS title\n\"#).await?;\n\n// Query with additional parameters\nlet results = session.query_with(r#\"\n    MATCH (d:Document)\n    WHERE d.tenant_id = $session.tenant_id\n      AND d.status = $status\n    RETURN d.title AS title\n\"#)\n    .param(\"status\", \"published\")\n    .fetch_all()\n    .await?;\n\n// Read session variable\nlet tenant: &amp;str = session.get(\"tenant_id\").unwrap().as_str().unwrap();\n</code></pre> <pre><code># Create session with tenant context\nsession = (\n    db.session()\n    .set(\"tenant_id\", \"acme-corp\")\n    .set(\"user_id\", \"user-123\")\n    .build()\n)\n\n# Execute queries with session context\nresults = session.query(\"\"\"\n    MATCH (d:Document)\n    WHERE d.tenant_id = $session.tenant_id\n    RETURN d.title AS title\n\"\"\")\n\n# Read session variable\ntenant = session.get(\"tenant_id\")\nprint(f\"Tenant: {tenant}\")\n</code></pre>"},{"location":"getting-started/programming-guide/#explain-and-profile","title":"EXPLAIN and PROFILE","text":"<p>Analyze query execution plans.</p> RustPython <pre><code>// Get query plan without executing\nlet plan = db.explain(\"MATCH (p:Person) WHERE p.age &gt; 25 RETURN p.name\").await?;\nprintln!(\"Plan:\\n{}\", plan.plan_text);\nprintln!(\"Estimated cost: {}\", plan.estimated_cost);\n\n// Execute with profiling\nlet (results, profile) = db.profile(\"MATCH (p:Person) WHERE p.age &gt; 25 RETURN p.name\").await?;\nprintln!(\"Total time: {}ms\", profile.total_time_ms);\nprintln!(\"Rows scanned: {}\", profile.rows_scanned);\nprintln!(\"Peak memory: {} bytes\", profile.peak_memory_bytes);\n</code></pre> <pre><code># Get query plan without executing\nplan = db.explain(\"MATCH (p:Person) WHERE p.age &gt; 25 RETURN p.name AS name\")\nprint(f\"Plan:\\n{plan['plan_text']}\")\nprint(f\"Estimated cost: {plan['cost_estimates']}\")\n\n# Execute with profiling\nresults, profile = db.profile(\"MATCH (p:Person) WHERE p.age &gt; 25 RETURN p.name AS name\")\nprint(f\"Total time: {profile['total_time_ms']}ms\")\nprint(f\"Peak memory: {profile['peak_memory_bytes']} bytes\")\n</code></pre>"},{"location":"getting-started/programming-guide/#snapshots","title":"Snapshots","text":"<p>Access historical database states.</p> RustPython <pre><code>// Create a named snapshot\nlet snapshot_id = db.create_snapshot(Some(\"before_migration\")).await?;\n\n// List all snapshots\nfor snap in db.list_snapshots().await? {\n    println!(\"{}: {} ({})\",\n        snap.id,\n        snap.name.as_deref().unwrap_or(\"-\"),\n        snap.created_at\n    );\n}\n\n// Open read-only view at snapshot\nlet historical = db.at_snapshot(&amp;snapshot_id).await?;\nlet old_count = historical.query(\"MATCH (n) RETURN count(n) AS c\").await?;\nprintln!(\"Count at snapshot: {}\", old_count[0].get::&lt;i64&gt;(\"c\")?);\n\n// Restore to snapshot\ndb.restore_snapshot(&amp;snapshot_id).await?;\n</code></pre> <pre><code># Create a named snapshot\nsnapshot_id = db.create_snapshot(\"before_migration\")\n\n# List all snapshots\nfor snap in db.list_snapshots():\n    print(f\"{snap.snapshot_id}: {snap.name or '-'} ({snap.vertex_count} vertices)\")\n\n# Open read-only view at snapshot\nhistorical = db.at_snapshot(snapshot_id)\nold_results = historical.query(\"MATCH (n) RETURN count(n) AS c\")\nprint(f\"Count at snapshot: {old_results[0]['c']}\")\n\n# Restore to snapshot\ndb.restore_snapshot(snapshot_id)\n</code></pre>"},{"location":"getting-started/programming-guide/#graph-algorithms","title":"Graph Algorithms","text":"<p>Run built-in graph algorithms.</p>"},{"location":"getting-started/programming-guide/#pagerank","title":"PageRank","text":"RustPython <pre><code>// Using the algorithm builder\nlet rankings = db.algo()\n    .pagerank()\n    .labels(&amp;[\"Person\"])\n    .edge_types(&amp;[\"KNOWS\"])\n    .damping(0.85)\n    .max_iterations(50)\n    .run()\n    .await?;\n\nfor (vid, score) in rankings.iter().take(10) {\n    println!(\"VID: {}, Score: {:.6}\", vid, score);\n}\n\n// Via Cypher\nlet results = db.query(r#\"\n    CALL algo.pageRank(['Person'], ['KNOWS'])\n    YIELD nodeId, score\n    RETURN nodeId, score\n    ORDER BY score DESC\n    LIMIT 10\n\"#).await?;\n</code></pre> <pre><code># PageRank via Cypher\nresults = db.query(\"\"\"\n    CALL algo.pageRank(['Person'], ['KNOWS'])\n    YIELD nodeId, score\n    RETURN nodeId, score\n    ORDER BY score DESC\n    LIMIT 10\n\"\"\")\n\nfor row in results:\n    print(f\"Node: {row['nodeId']}, Score: {row['score']:.6f}\")\n</code></pre>"},{"location":"getting-started/programming-guide/#weakly-connected-components","title":"Weakly Connected Components","text":"RustPython <pre><code>// Find connected components\nlet components = db.algo()\n    .wcc()\n    .labels(&amp;[\"Person\"])\n    .edge_types(&amp;[\"KNOWS\"])\n    .run()\n    .await?;\n\n// Count component sizes\nlet mut sizes: HashMap&lt;i64, usize&gt; = HashMap::new();\nfor (_, component_id) in &amp;components {\n    *sizes.entry(*component_id).or_default() += 1;\n}\nprintln!(\"Found {} components\", sizes.len());\n</code></pre> <pre><code># WCC via Cypher\nresults = db.query(\"\"\"\n    CALL algo.wcc(['Person'], ['KNOWS'])\n    YIELD nodeId, componentId\n    RETURN componentId, COUNT(*) AS size\n    ORDER BY size DESC\n\"\"\")\n\nprint(f\"Found {len(results)} components\")\nfor row in results[:5]:\n    print(f\"Component {row['componentId']}: {row['size']} nodes\")\n</code></pre>"},{"location":"getting-started/programming-guide/#community-detection","title":"Community Detection","text":"RustPython <pre><code>// Louvain community detection via Cypher\nlet results = db.query(r#\"\n    CALL algo.louvain(['Person'], ['KNOWS'])\n    YIELD nodeId, communityId\n    RETURN communityId, COUNT(*) AS size\n    ORDER BY size DESC\n    LIMIT 10\n\"#).await?;\n</code></pre> <pre><code># Louvain community detection\nresults = db.query(\"\"\"\n    CALL algo.louvain(['Person'], ['KNOWS'])\n    YIELD nodeId, communityId\n    RETURN communityId, COUNT(*) AS size\n    ORDER BY size DESC\n    LIMIT 10\n\"\"\")\n\nfor row in results:\n    print(f\"Community {row['communityId']}: {row['size']} members\")\n</code></pre>"},{"location":"getting-started/programming-guide/#error-handling","title":"Error Handling","text":"<p>Handle errors appropriately in your application.</p> RustPython <pre><code>use uni::prelude::*;\n\nmatch db.query(\"INVALID CYPHER\").await {\n    Ok(results) =&gt; {\n        // Process results\n    }\n    Err(UniError::Parse { message, line, column, .. }) =&gt; {\n        eprintln!(\n            \"Syntax error at {}:{}: {}\",\n            line.unwrap_or(0),\n            column.unwrap_or(0),\n            message\n        );\n    }\n    Err(UniError::Query { message, .. }) =&gt; {\n        eprintln!(\"Query execution error: {}\", message);\n    }\n    Err(UniError::Timeout { timeout_ms }) =&gt; {\n        eprintln!(\"Query timed out after {}ms\", timeout_ms);\n    }\n    Err(e) =&gt; {\n        eprintln!(\"Error: {}\", e);\n    }\n}\n</code></pre> <pre><code>try:\n    results = db.query(\"INVALID CYPHER\")\nexcept RuntimeError as e:\n    print(f\"Query error: {e}\")\nexcept ValueError as e:\n    print(f\"Invalid parameter: {e}\")\nexcept OSError as e:\n    print(f\"Database I/O error: {e}\")\n</code></pre>"},{"location":"getting-started/programming-guide/#complete-example-social-network","title":"Complete Example: Social Network","text":"<p>Here's a complete example building a simple social network application.</p> RustPython <pre><code>use uni::prelude::*;\nuse std::collections::HashMap;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create database\n    let db = Uni::open(\"./social-network\")\n        .cache_size(512 * 1024 * 1024)\n        .build()\n        .await?;\n\n    // Define schema\n    db.schema()\n        .label(\"User\")\n            .property(\"username\", DataType::String)\n            .property(\"email\", DataType::String)\n            .property(\"joined\", DataType::Int32)\n            .index(\"username\", IndexType::Scalar(ScalarType::Hash))\n        .label(\"Post\")\n            .property(\"content\", DataType::String)\n            .property(\"timestamp\", DataType::Int64)\n        .edge_type(\"FOLLOWS\", &amp;[\"User\"], &amp;[\"User\"])\n        .edge_type(\"POSTED\", &amp;[\"User\"], &amp;[\"Post\"])\n        .edge_type(\"LIKES\", &amp;[\"User\"], &amp;[\"Post\"])\n        .apply()\n        .await?;\n\n    // Create users\n    db.transaction(|tx| async move {\n        tx.execute(\"CREATE (u:User {username: 'alice', email: 'alice@example.com', joined: 2023})\").await?;\n        tx.execute(\"CREATE (u:User {username: 'bob', email: 'bob@example.com', joined: 2023})\").await?;\n        tx.execute(\"CREATE (u:User {username: 'carol', email: 'carol@example.com', joined: 2024})\").await?;\n\n        // Create follow relationships\n        tx.execute(r#\"\n            MATCH (a:User {username: 'alice'}), (b:User {username: 'bob'})\n            CREATE (a)-[:FOLLOWS]-&gt;(b)\n        \"#).await?;\n        tx.execute(r#\"\n            MATCH (b:User {username: 'bob'}), (c:User {username: 'carol'})\n            CREATE (b)-[:FOLLOWS]-&gt;(c)\n        \"#).await?;\n\n        Ok(())\n    }).await?;\n\n    // Create posts\n    db.execute(r#\"\n        MATCH (a:User {username: 'alice'})\n        CREATE (a)-[:POSTED]-&gt;(p:Post {content: 'Hello world!', timestamp: 1704067200000})\n    \"#).await?;\n\n    // Query: Get user's feed (posts from people they follow)\n    let feed = db.query_with(r#\"\n        MATCH (me:User {username: $username})-[:FOLLOWS]-&gt;(friend:User)-[:POSTED]-&gt;(post:Post)\n        RETURN friend.username AS author, post.content AS content, post.timestamp AS ts\n        ORDER BY post.timestamp DESC\n        LIMIT 20\n    \"#)\n        .param(\"username\", \"alice\")\n        .fetch_all()\n        .await?;\n\n    println!(\"Alice's Feed:\");\n    for row in &amp;feed {\n        println!(\"  @{}: {}\",\n            row.get::&lt;String&gt;(\"author\")?,\n            row.get::&lt;String&gt;(\"content\")?\n        );\n    }\n\n    // Query: Suggest friends (friends of friends not already following)\n    let suggestions = db.query_with(r#\"\n        MATCH (me:User {username: $username})-[:FOLLOWS*2]-&gt;(suggestion:User)\n        WHERE NOT (me)-[:FOLLOWS]-&gt;(suggestion)\n          AND suggestion.username &lt;&gt; $username\n        RETURN DISTINCT suggestion.username AS username, COUNT(*) AS mutual\n        ORDER BY mutual DESC\n        LIMIT 5\n    \"#)\n        .param(\"username\", \"alice\")\n        .fetch_all()\n        .await?;\n\n    println!(\"\\nFriend Suggestions:\");\n    for row in &amp;suggestions {\n        println!(\"  @{} ({} mutual)\",\n            row.get::&lt;String&gt;(\"username\")?,\n            row.get::&lt;i64&gt;(\"mutual\")?\n        );\n    }\n\n    // Run PageRank to find influential users\n    let influential = db.query(r#\"\n        CALL algo.pageRank(['User'], ['FOLLOWS'])\n        YIELD nodeId, score\n        MATCH (u:User) WHERE id(u) = nodeId\n        RETURN u.username AS username, score\n        ORDER BY score DESC\n        LIMIT 5\n    \"#).await?;\n\n    println!(\"\\nMost Influential Users:\");\n    for row in &amp;influential {\n        println!(\"  @{}: {:.4}\",\n            row.get::&lt;String&gt;(\"username\")?,\n            row.get::&lt;f64&gt;(\"score\")?\n        );\n    }\n\n    Ok(())\n}\n</code></pre> <pre><code>import uni\n\ndef main():\n    # Create database\n    db = uni.DatabaseBuilder.open(\"./social-network\") \\\n        .cache_size(512 * 1024 * 1024) \\\n        .build()\n\n    # Define schema\n    db.create_label(\"User\")\n    db.add_property(\"User\", \"username\", \"string\", False)\n    db.add_property(\"User\", \"email\", \"string\", False)\n    db.add_property(\"User\", \"joined\", \"int\", False)\n    db.create_scalar_index(\"User\", \"username\", \"hash\")\n\n    db.create_label(\"Post\")\n    db.add_property(\"Post\", \"content\", \"string\", False)\n    db.add_property(\"Post\", \"timestamp\", \"int\", False)\n\n    db.create_edge_type(\"FOLLOWS\", [\"User\"], [\"User\"])\n    db.create_edge_type(\"POSTED\", [\"User\"], [\"Post\"])\n    db.create_edge_type(\"LIKES\", [\"User\"], [\"Post\"])\n\n    # Create users in transaction\n    tx = db.begin()\n    try:\n        tx.query(\"CREATE (u:User {username: 'alice', email: 'alice@example.com', joined: 2023})\")\n        tx.query(\"CREATE (u:User {username: 'bob', email: 'bob@example.com', joined: 2023})\")\n        tx.query(\"CREATE (u:User {username: 'carol', email: 'carol@example.com', joined: 2024})\")\n\n        # Create follow relationships\n        tx.query(\"\"\"\n            MATCH (a:User {username: 'alice'}), (b:User {username: 'bob'})\n            CREATE (a)-[:FOLLOWS]-&gt;(b)\n        \"\"\")\n        tx.query(\"\"\"\n            MATCH (b:User {username: 'bob'}), (c:User {username: 'carol'})\n            CREATE (b)-[:FOLLOWS]-&gt;(c)\n        \"\"\")\n\n        tx.commit()\n    except Exception as e:\n        tx.rollback()\n        raise e\n\n    # Create posts\n    db.execute(\"\"\"\n        MATCH (a:User {username: 'alice'})\n        CREATE (a)-[:POSTED]-&gt;(p:Post {content: 'Hello world!', timestamp: 1704067200000})\n    \"\"\")\n\n    # Query: Get user's feed\n    feed = db.query_with(\"\"\"\n        MATCH (me:User {username: $username})-[:FOLLOWS]-&gt;(friend:User)-[:POSTED]-&gt;(post:Post)\n        RETURN friend.username AS author, post.content AS content, post.timestamp AS ts\n        ORDER BY post.timestamp DESC\n        LIMIT 20\n    \"\"\").param(\"username\", \"alice\").fetch_all()\n\n    print(\"Alice's Feed:\")\n    for row in feed:\n        print(f\"  @{row['author']}: {row['content']}\")\n\n    # Query: Suggest friends\n    suggestions = db.query_with(\"\"\"\n        MATCH (me:User {username: $username})-[:FOLLOWS*2]-&gt;(suggestion:User)\n        WHERE NOT (me)-[:FOLLOWS]-&gt;(suggestion)\n          AND suggestion.username &lt;&gt; $username\n        RETURN DISTINCT suggestion.username AS username, COUNT(*) AS mutual\n        ORDER BY mutual DESC\n        LIMIT 5\n    \"\"\").param(\"username\", \"alice\").fetch_all()\n\n    print(\"\\nFriend Suggestions:\")\n    for row in suggestions:\n        print(f\"  @{row['username']} ({row['mutual']} mutual)\")\n\n    # Run PageRank\n    influential = db.query(\"\"\"\n        CALL algo.pageRank(['User'], ['FOLLOWS'])\n        YIELD nodeId, score\n        MATCH (u:User) WHERE id(u) = nodeId\n        RETURN u.username AS username, score\n        ORDER BY score DESC\n        LIMIT 5\n    \"\"\")\n\n    print(\"\\nMost Influential Users:\")\n    for row in influential:\n        print(f\"  @{row['username']}: {row['score']:.4f}\")\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"getting-started/programming-guide/#next-steps","title":"Next Steps","text":"<p>You now have the foundation to build applications with Uni. Continue learning:</p> Topic Description Cypher Querying Complete query language reference Vector Search Semantic search patterns Schema Design Best practices for graph modeling Performance Tuning Optimization techniques Rust API Reference Complete Rust API docs Python API Reference Complete Python API docs"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>Get Uni running with real data in under 5 minutes. This guide walks you through building the project, importing a sample dataset, and executing your first graph queries.</p>"},{"location":"getting-started/quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have: - Uni installed (Installation Guide) - At least 1 GB free disk space for sample data - Terminal access</p>"},{"location":"getting-started/quickstart/#step-1-build-the-project","title":"Step 1: Build the Project","text":"<p>If you haven't already built Uni, compile it in release mode for optimal performance:</p> <pre><code>cd uni\ncargo build --release\n</code></pre> <p>The binary will be available at <code>target/release/uni</code>. For convenience, you can add it to your PATH:</p> <pre><code>export PATH=\"$PWD/target/release:$PATH\"\n</code></pre>"},{"location":"getting-started/quickstart/#step-2-explore-the-demo-dataset","title":"Step 2: Explore the Demo Dataset","text":"<p>Uni includes a sample dataset based on academic papers and citations, perfect for learning graph queries.</p>"},{"location":"getting-started/quickstart/#dataset-overview","title":"Dataset Overview","text":"Entity Description Sample Size Papers Academic publications with titles, years, and embeddings ~1,000 Citations Directed edges from citing to cited papers ~5,000"},{"location":"getting-started/quickstart/#data-format","title":"Data Format","text":"<p>Vertices (<code>papers.jsonl</code>): <pre><code>{\"id\": \"paper_001\", \"title\": \"Attention Is All You Need\", \"year\": 2017, \"venue\": \"NeurIPS\", \"embedding\": [0.12, -0.34, ...]}\n{\"id\": \"paper_002\", \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\", \"year\": 2018, \"venue\": \"NAACL\", \"embedding\": [0.08, -0.21, ...]}\n</code></pre></p> <p>Edges (<code>citations.jsonl</code>): <pre><code>{\"src\": \"paper_002\", \"dst\": \"paper_001\"}\n{\"src\": \"paper_003\", \"dst\": \"paper_001\"}\n</code></pre></p> <p>The <code>src</code> paper cites the <code>dst</code> paper. In graph terms: <code>(paper_002)-[:CITES]-&gt;(paper_001)</code>.</p>"},{"location":"getting-started/quickstart/#step-3-import-data","title":"Step 3: Import Data","text":"<p>Use the <code>import</code> command to ingest the sample dataset. This creates the graph structure, property storage, and vector indexes.</p> <pre><code>uni import semantic-scholar \\\n    --papers demos/demo01/data/papers.jsonl \\\n    --citations demos/demo01/data/citations.jsonl \\\n    --output ./my-first-graph\n</code></pre>"},{"location":"getting-started/quickstart/#what-happens-during-import","title":"What Happens During Import","text":"<pre><code>[1/5] Validating schema...\n[2/5] Parsing vertex data (1,000 papers)...\n[3/5] Allocating vertex IDs...\n[4/5] Building adjacency index (5,000 edges)...\n[5/5] Writing to Lance storage...\n\nImport complete!\n  Vertices: 1,000\n  Edges: 5,000\n  Storage: ./my-first-graph (12.4 MB)\n</code></pre> <p>The import process: 1. Schema Validation \u2014 Ensures all properties match expected types 2. ID Allocation \u2014 Maps string IDs to internal 64-bit integers (VIDs) 3. Graph Construction \u2014 Builds CSR-format adjacency lists 4. Property Storage \u2014 Writes columnar data to Lance datasets 5. Vector Indexing \u2014 Creates HNSW indexes for embedding search</p>"},{"location":"getting-started/quickstart/#step-4-use-the-interactive-repl","title":"Step 4: Use the Interactive REPL","text":"<p>The easiest way to explore Uni is via the interactive shell (REPL). It supports syntax highlighting, command history, and formatted table output.</p> <p>Start the REPL by running <code>uni</code> without any arguments (or with the <code>repl</code> command):</p> <pre><code>uni --path ./my-first-graph\n</code></pre> <p>You should see the welcome message:</p> <pre><code>Welcome to UniDB CLI\nType 'help' for commands or enter a Cypher query.\nuni&gt; \n</code></pre>"},{"location":"getting-started/quickstart/#try-these-queries-in-the-repl","title":"Try These Queries in the REPL:","text":"<p>1. Count all papers: <pre><code>MATCH (p:Paper) RETURN COUNT(p)\n</code></pre></p> <p>2. Find papers cited by \"Attention Is All You Need\": <pre><code>MATCH (source:Paper {title: 'Attention Is All You Need'})-[:CITES]-&gt;(cited)\nRETURN cited.title, cited.year\nORDER BY cited.year DESC\n</code></pre></p> <p>3. Clear the screen: <pre><code>clear\n</code></pre></p> <p>4. Exit the shell: <pre><code>exit\n</code></pre></p>"},{"location":"getting-started/quickstart/#step-5-run-one-off-queries","title":"Step 5: Run One-off Queries","text":"<p>You can also run queries directly from your terminal using the <code>query</code> command:</p> <pre><code>uni query \"MATCH (p:Paper) RETURN COUNT(p)\" --path ./my-first-graph\n</code></pre>"},{"location":"getting-started/quickstart/#step-6-create-new-data","title":"Step 6: Create New Data","text":"<p>Add new papers and citations with <code>CREATE</code>:</p> <pre><code># Create a new paper\nuni query \"\n    CREATE (p:Paper {\n        id: 'new_paper_001',\n        title: 'My Research Paper',\n        year: 2024,\n        venue: 'ArXiv'\n    })\n    RETURN p.title\n\" --path ./my-first-graph\n\n# Create a citation edge\nuni query \"\n    MATCH (citing:Paper), (cited:Paper)\n    WHERE citing.id = 'new_paper_001'\n      AND cited.title = 'Attention Is All You Need'\n    CREATE (citing)-[:CITES]-&gt;(cited)\n    RETURN citing.title, cited.title\n\" --path ./my-first-graph\n</code></pre>"},{"location":"getting-started/quickstart/#understanding-query-execution","title":"Understanding Query Execution","text":"<p>When you run a query, Uni:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   1. Parse     \u2502 \u2500\u2500\u25b6 \u2502   2. Plan      \u2502 \u2500\u2500\u25b6 \u2502   3. Execute   \u2502\n\u2502    Cypher      \u2502     \u2502   Optimize     \u2502     \u2502   Vectorized   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                      \u2502                      \u2502\n        \u25bc                      \u25bc                      \u25bc\n   \"MATCH (n)...\"      LogicalPlan with       Process batches\n   becomes AST         filter pushdown        of 1024 rows\n</code></pre> <ol> <li>Parse: Cypher text \u2192 Abstract Syntax Tree</li> <li>Plan: AST \u2192 Optimized Logical Plan (with predicate pushdown)</li> <li>Execute: Vectorized operators process Arrow batches</li> </ol>"},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"<p>You've successfully: - Imported graph data from JSONL files - Traversed graph relationships with MATCH - Filtered results with WHERE clauses - Aggregated data with COUNT and ORDER BY - Searched vectors with semantic similarity</p>"},{"location":"getting-started/quickstart/#continue-learning","title":"Continue Learning","text":"Topic Description CLI Reference All CLI commands and options Cypher Querying Complete query language guide Vector Search Deep dive into semantic search Data Ingestion Import strategies and formats Architecture Understand Uni's internals"},{"location":"getting-started/quickstart/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/quickstart/#no-vertices-found","title":"\"No vertices found\"","text":"<p>Ensure your JSONL files have the correct format: <pre><code>head -1 papers.jsonl\n# Should output valid JSON: {\"id\": \"...\", \"title\": \"...\", ...}\n</code></pre></p>"},{"location":"getting-started/quickstart/#property-not-found","title":"\"Property not found\"","text":"<p>Check that query property names match your schema exactly (case-sensitive): <pre><code># Wrong: WHERE p.Title = '...'\n# Right: WHERE p.title = '...'\n</code></pre></p>"},{"location":"getting-started/quickstart/#path-does-not-exist","title":"\"Path does not exist\"","text":"<p>Provide the full path to your storage directory: <pre><code># Use absolute paths for clarity\nuni query \"...\" --path /home/user/my-first-graph\n</code></pre></p>"},{"location":"getting-started/quickstart/#slow-queries","title":"Slow queries","text":"<p>For large datasets, ensure vector indexes are built: <pre><code>uni query \"SHOW INDEXES\" --path ./my-first-graph\n</code></pre></p>"},{"location":"guides/","title":"Developer Guides","text":"<p>Practical guides for building applications with Uni.</p>   ### [Cypher Querying](cypher-querying.md) Complete OpenCypher reference with pattern matching, filtering, and aggregations.     ### [Vector Search](vector-search.md) Semantic similarity search with HNSW and IVF_PQ indexes.     ### [Data Ingestion](data-ingestion.md) Bulk import, streaming writes, and ETL patterns.     ### [Schema Design](schema-design.md) Best practices for modeling your data as a property graph.     ### [Performance Tuning](performance-tuning.md) Optimization strategies for queries, indexes, and storage."},{"location":"guides/#common-tasks","title":"Common Tasks","text":""},{"location":"guides/#query-your-graph","title":"Query Your Graph","text":"<pre><code>MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\nWHERE p.year &gt; 2020\nRETURN cited.title, COUNT(*) as citations\nORDER BY citations DESC\nLIMIT 10\n</code></pre>"},{"location":"guides/#vector-similarity-search","title":"Vector Similarity Search","text":"<pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node, score\nRETURN node.title, score\n</code></pre>"},{"location":"guides/#bulk-data-import","title":"Bulk Data Import","text":"<pre><code>uni import semantic-scholar \\\n  --papers papers.jsonl \\\n  --citations edges.jsonl \\\n  --output ./storage\n</code></pre>"},{"location":"guides/#next-steps","title":"Next Steps","text":"<ul> <li>New to graph queries? Start with Cypher Querying</li> <li>Building AI features? See Vector Search</li> <li>Loading large datasets? Check Data Ingestion</li> </ul>"},{"location":"guides/cypher-querying/","title":"Cypher Query Language","text":"<p>Uni supports a substantial subset of the OpenCypher query language, optimized for vectorized execution. This guide covers all supported syntax with practical examples.</p>"},{"location":"guides/cypher-querying/#overview","title":"Overview","text":"<p>Cypher is a declarative graph query language that uses ASCII-art patterns to describe graph structures:</p> <pre><code>// Pattern: (startNode)-[relationship]-&gt;(endNode)\nMATCH (person:Person)-[:KNOWS]-&gt;(friend:Person)\nWHERE person.age &gt; 30\nRETURN friend.name\n</code></pre>"},{"location":"guides/cypher-querying/#query-structure","title":"Query Structure","text":"<p>A complete Cypher query follows this structure:</p> <pre><code>[MATCH clause]      -- Pattern matching\n[WHERE clause]      -- Filtering\n[WITH clause]       -- Intermediate processing\n[RETURN clause]     -- Output projection\n[ORDER BY clause]   -- Sorting\n[SKIP/LIMIT clause] -- Pagination\n</code></pre>"},{"location":"guides/cypher-querying/#example-query","title":"Example Query","text":"<pre><code>MATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)\nWHERE p.year &gt;= 2020 AND a.affiliation = 'MIT'\nRETURN p.title, a.name, p.year\nORDER BY p.year DESC\nLIMIT 10\n</code></pre>"},{"location":"guides/cypher-querying/#match-clause","title":"MATCH Clause","text":"<p>The <code>MATCH</code> clause specifies graph patterns to find.</p>"},{"location":"guides/cypher-querying/#node-patterns","title":"Node Patterns","text":"<pre><code>// Any node\nMATCH (n)\n\n// Node with label\nMATCH (p:Paper)\n\n// Node with multiple labels (future)\nMATCH (n:Paper:Preprint)\n\n// Node with variable binding\nMATCH (paper:Paper)\nRETURN paper.title\n\n// Anonymous node (no variable)\nMATCH (:Paper)-[:CITES]-&gt;(cited)\nRETURN cited.title\n</code></pre>"},{"location":"guides/cypher-querying/#node-properties-in-pattern","title":"Node Properties in Pattern","text":"<pre><code>// Filter in pattern (equivalent to WHERE)\nMATCH (p:Paper {year: 2023})\nRETURN p.title\n\n// Multiple properties\nMATCH (p:Paper {year: 2023, venue: 'NeurIPS'})\nRETURN p.title\n</code></pre>"},{"location":"guides/cypher-querying/#relationship-patterns","title":"Relationship Patterns","text":"<pre><code>// Outgoing relationship\nMATCH (a)-[:KNOWS]-&gt;(b)\n\n// Incoming relationship\nMATCH (a)&lt;-[:KNOWS]-(b)\n\n// Either direction\nMATCH (a)-[:KNOWS]-(b)\n\n// Any relationship type\nMATCH (a)-[r]-&gt;(b)\n\n// Relationship with variable\nMATCH (p:Paper)-[c:CITES]-&gt;(cited:Paper)\nRETURN c  // Access edge properties\n</code></pre>"},{"location":"guides/cypher-querying/#multi-hop-patterns","title":"Multi-Hop Patterns","text":"<pre><code>// 2-hop path\nMATCH (a:Paper)-[:CITES]-&gt;(b:Paper)-[:CITES]-&gt;(c:Paper)\nRETURN a.title, b.title, c.title\n\n// Chain multiple relationships\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)-[:AFFILIATED_WITH]-&gt;(u:University)\nRETURN p.title, a.name, u.name\n</code></pre>"},{"location":"guides/cypher-querying/#variable-length-paths","title":"Variable-Length Paths","text":"<p>Variable-length path patterns allow traversing multiple hops in a single pattern.</p> <pre><code>// 1 to 3 hops\nMATCH (a:Paper)-[:CITES*1..3]-&gt;(b:Paper)\nRETURN a.title, b.title\n\n// Exactly 2 hops\nMATCH (a)-[:KNOWS*2]-&gt;(b)\n\n// Any length (use with caution on large graphs)\nMATCH (a)-[:KNOWS*]-&gt;(b)\n\n// Zero or more hops\nMATCH (a)-[:KNOWS*0..]-&gt;(b)\n\n// With path variable\nMATCH path = (a:Paper)-[:CITES*1..5]-&gt;(b:Paper)\nWHERE a.title = 'Attention Is All You Need'\nRETURN path, length(path) AS hops\n</code></pre>"},{"location":"guides/cypher-querying/#where-clause","title":"WHERE Clause","text":"<p>The <code>WHERE</code> clause filters matched patterns.</p>"},{"location":"guides/cypher-querying/#comparison-operators","title":"Comparison Operators","text":"<pre><code>// Equality\nWHERE p.year = 2023\n\n// Inequality\nWHERE p.year &lt;&gt; 2020\nWHERE p.year != 2020\n\n// Comparison\nWHERE p.year &gt; 2020\nWHERE p.year &gt;= 2020\nWHERE p.year &lt; 2025\nWHERE p.year &lt;= 2025\n</code></pre>"},{"location":"guides/cypher-querying/#boolean-logic","title":"Boolean Logic","text":"<pre><code>// AND\nWHERE p.year &gt; 2020 AND p.venue = 'NeurIPS'\n\n// OR\nWHERE p.venue = 'NeurIPS' OR p.venue = 'ICML'\n\n// NOT\nWHERE NOT p.is_retracted\n\n// Parentheses for grouping\nWHERE (p.year &gt; 2020 AND p.venue = 'NeurIPS') OR p.citations &gt; 1000\n</code></pre>"},{"location":"guides/cypher-querying/#null-handling","title":"NULL Handling","text":"<pre><code>// Check for NULL\nWHERE p.doi IS NULL\nWHERE p.doi IS NOT NULL\n\n// COALESCE (use default if NULL)\nRETURN COALESCE(p.nickname, p.name) AS display_name\n</code></pre>"},{"location":"guides/cypher-querying/#string-operations","title":"String Operations","text":"<pre><code>// Starts with\nWHERE p.title STARTS WITH 'Attention'\n\n// Ends with\nWHERE p.title ENDS WITH 'Networks'\n\n// Contains (uses JSON FTS index if available)\nWHERE p.title CONTAINS 'Transformer'\n\n// Full-text search on JSON document column (requires JSON FTS index)\nWHERE a._doc CONTAINS 'graph database'\n\n// Path-specific JSON FTS search\nWHERE a._doc.title CONTAINS 'graph'\n\n// Regular expression (future)\nWHERE p.title =~ '.*Transform.*'\n</code></pre> <p>Note: The <code>CONTAINS</code> operator is automatically routed to JSON FTS indexes when the column has an FTS index, enabling BM25-based full-text search with relevance ranking.</p>"},{"location":"guides/cypher-querying/#list-operations","title":"List Operations","text":"<pre><code>// IN list\nWHERE p.venue IN ['NeurIPS', 'ICML', 'ICLR']\n\n// NOT IN\nWHERE p.venue NOT IN ['Workshop', 'Demo']\n</code></pre>"},{"location":"guides/cypher-querying/#property-existence","title":"Property Existence","text":"<pre><code>// Check if property exists\nWHERE p.abstract IS NOT NULL\n\n// In pattern\nWHERE EXISTS(p.doi)\n</code></pre>"},{"location":"guides/cypher-querying/#return-clause","title":"RETURN Clause","text":"<p>The <code>RETURN</code> clause specifies output columns.</p>"},{"location":"guides/cypher-querying/#basic-projections","title":"Basic Projections","text":"<pre><code>// Single property\nRETURN p.title\n\n// Multiple properties\nRETURN p.title, p.year, p.venue\n\n// All properties (*)\nRETURN p.*\n\n// Entire node\nRETURN p\n</code></pre>"},{"location":"guides/cypher-querying/#aliases","title":"Aliases","text":"<pre><code>// AS keyword\nRETURN p.title AS paper_title, a.name AS author_name\n\n// Expression aliases\nRETURN p.year + 1 AS next_year\n</code></pre>"},{"location":"guides/cypher-querying/#expressions","title":"Expressions","text":"<pre><code>// Arithmetic\nRETURN p.citations * 2 AS double_citations\n\n// String concatenation\nRETURN p.title + ' (' + p.venue + ')' AS formatted\n\n// Conditional (CASE)\nRETURN CASE\n  WHEN p.citations &gt; 1000 THEN 'High Impact'\n  WHEN p.citations &gt; 100 THEN 'Medium Impact'\n  ELSE 'Low Impact'\nEND AS impact_level\n</code></pre>"},{"location":"guides/cypher-querying/#distinct","title":"DISTINCT","text":"<pre><code>// Remove duplicates\nRETURN DISTINCT p.venue\n\n// Distinct combinations\nRETURN DISTINCT p.venue, p.year\n</code></pre>"},{"location":"guides/cypher-querying/#aggregations","title":"Aggregations","text":"<p>Uni supports standard aggregation functions.</p>"},{"location":"guides/cypher-querying/#aggregation-functions","title":"Aggregation Functions","text":"Function Description Example <code>COUNT(*)</code> Count all rows <code>RETURN COUNT(*)</code> <code>COUNT(x)</code> Count non-null values <code>RETURN COUNT(p.doi)</code> <code>COUNT(DISTINCT x)</code> Count distinct values <code>RETURN COUNT(DISTINCT p.venue)</code> <code>SUM(x)</code> Sum numeric values <code>RETURN SUM(p.citations)</code> <code>AVG(x)</code> Average <code>RETURN AVG(p.citations)</code> <code>MIN(x)</code> Minimum <code>RETURN MIN(p.year)</code> <code>MAX(x)</code> Maximum <code>RETURN MAX(p.year)</code> <code>COLLECT(x)</code> Collect into list <code>RETURN COLLECT(p.title)</code>"},{"location":"guides/cypher-querying/#implicit-grouping","title":"Implicit Grouping","text":"<p>Non-aggregated columns become GROUP BY keys:</p> <pre><code>// Group by venue, count papers per venue\nMATCH (p:Paper)\nRETURN p.venue, COUNT(p) AS paper_count\nORDER BY paper_count DESC\n</code></pre>"},{"location":"guides/cypher-querying/#aggregation-examples","title":"Aggregation Examples","text":"<pre><code>// Count papers per author\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)\nRETURN a.name, COUNT(p) AS papers, AVG(p.citations) AS avg_citations\nORDER BY papers DESC\n\n// Most cited papers per venue\nMATCH (p:Paper)\nRETURN p.venue, MAX(p.citations) AS top_citations, COUNT(p) AS total\nORDER BY top_citations DESC\n</code></pre>"},{"location":"guides/cypher-querying/#window-functions","title":"Window Functions","text":"<p>Window functions perform calculations across a set of rows related to the current row, without collapsing results like aggregations.</p>"},{"location":"guides/cypher-querying/#basic-syntax","title":"Basic Syntax","text":"<pre><code>function_name(args) OVER (\n  [PARTITION BY partition_expr, ...]\n  [ORDER BY order_expr [ASC|DESC], ...]\n)\n</code></pre>"},{"location":"guides/cypher-querying/#supported-window-functions","title":"Supported Window Functions","text":"Function Description Example <code>row_number()</code> Sequential row number <code>row_number() OVER (ORDER BY p.year)</code> <code>rank()</code> Rank with gaps for ties <code>rank() OVER (ORDER BY p.citations DESC)</code> <code>dense_rank()</code> Rank without gaps <code>dense_rank() OVER (ORDER BY p.citations DESC)</code> <code>sum()</code> Running sum <code>sum(p.citations) OVER (ORDER BY p.year)</code> <code>avg()</code> Running average <code>avg(p.citations) OVER (PARTITION BY p.venue)</code> <code>count()</code> Running count <code>count(*) OVER (PARTITION BY p.venue)</code> <code>min()</code> / <code>max()</code> Running min/max <code>max(p.citations) OVER (PARTITION BY p.author)</code>"},{"location":"guides/cypher-querying/#examples","title":"Examples","text":"<p>Ranking within partitions: <pre><code>MATCH (p:Paper)\nRETURN p.title, p.venue, p.citations,\n       rank() OVER (PARTITION BY p.venue ORDER BY p.citations DESC) AS venue_rank\nORDER BY p.venue, venue_rank\n</code></pre></p> <p>Running totals: <pre><code>MATCH (p:Paper)\nWHERE p.author = 'Alice'\nRETURN p.title, p.year, p.citations,\n       sum(p.citations) OVER (ORDER BY p.year) AS cumulative_citations\nORDER BY p.year\n</code></pre></p> <p>Top N per group: <pre><code>MATCH (p:Paper)\nWITH p, row_number() OVER (PARTITION BY p.venue ORDER BY p.citations DESC) AS rn\nWHERE rn &lt;= 3\nRETURN p.venue, p.title, p.citations\nORDER BY p.venue, p.citations DESC\n</code></pre></p>"},{"location":"guides/cypher-querying/#scalar-functions","title":"Scalar Functions","text":"<p>Uni provides a comprehensive set of scalar functions for data transformation.</p>"},{"location":"guides/cypher-querying/#string-functions","title":"String Functions","text":"Function Description Example <code>toUpper(s)</code> / <code>upper(s)</code> Convert to uppercase <code>RETURN toUpper('hello')</code> \u2192 <code>'HELLO'</code> <code>toLower(s)</code> / <code>lower(s)</code> Convert to lowercase <code>RETURN toLower('HELLO')</code> \u2192 <code>'hello'</code> <code>trim(s)</code> Remove leading/trailing whitespace <code>RETURN trim('  hi  ')</code> \u2192 <code>'hi'</code> <code>ltrim(s)</code> Remove leading whitespace <code>RETURN ltrim('  hi')</code> \u2192 <code>'hi'</code> <code>rtrim(s)</code> Remove trailing whitespace <code>RETURN rtrim('hi  ')</code> \u2192 <code>'hi'</code> <code>substring(s, start, [len])</code> Extract substring <code>RETURN substring('hello', 1, 3)</code> \u2192 <code>'ell'</code> <code>left(s, n)</code> First n characters <code>RETURN left('hello', 2)</code> \u2192 <code>'he'</code> <code>right(s, n)</code> Last n characters <code>RETURN right('hello', 2)</code> \u2192 <code>'lo'</code> <code>reverse(s)</code> Reverse string <code>RETURN reverse('hello')</code> \u2192 <code>'olleh'</code> <code>replace(s, old, new)</code> Replace occurrences <code>RETURN replace('hello', 'l', 'x')</code> \u2192 <code>'hexxo'</code> <code>split(s, delim)</code> Split into list <code>RETURN split('a,b,c', ',')</code> \u2192 <code>['a','b','c']</code> <code>lpad(s, len, [pad])</code> Pad left to length <code>RETURN lpad('5', 3, '0')</code> \u2192 <code>'005'</code> <code>rpad(s, len, [pad])</code> Pad right to length <code>RETURN rpad('5', 3, '0')</code> \u2192 <code>'500'</code>"},{"location":"guides/cypher-querying/#math-functions","title":"Math Functions","text":"Function Description Example <code>abs(n)</code> Absolute value <code>RETURN abs(-5)</code> \u2192 <code>5</code> <code>ceil(n)</code> Round up <code>RETURN ceil(4.2)</code> \u2192 <code>5</code> <code>floor(n)</code> Round down <code>RETURN floor(4.8)</code> \u2192 <code>4</code> <code>round(n)</code> Round to nearest <code>RETURN round(4.5)</code> \u2192 <code>5</code> <code>sqrt(n)</code> Square root <code>RETURN sqrt(16)</code> \u2192 <code>4</code> <code>sign(n)</code> Sign (-1, 0, 1) <code>RETURN sign(-5)</code> \u2192 <code>-1</code> <code>log(n)</code> Natural logarithm <code>RETURN log(2.718)</code> \u2192 <code>~1</code> <code>log10(n)</code> Base-10 logarithm <code>RETURN log10(100)</code> \u2192 <code>2</code> <code>exp(n)</code> e^n <code>RETURN exp(1)</code> \u2192 <code>~2.718</code> <code>power(base, exp)</code> / <code>pow(base, exp)</code> Exponentiation <code>RETURN power(2, 3)</code> \u2192 <code>8</code> <code>sin(n)</code>, <code>cos(n)</code>, <code>tan(n)</code> Trigonometric <code>RETURN sin(0)</code> \u2192 <code>0</code>"},{"location":"guides/cypher-querying/#list-functions","title":"List Functions","text":"Function Description Example <code>size(list)</code> Length of list/string/map <code>RETURN size([1,2,3])</code> \u2192 <code>3</code> <code>head(list)</code> First element <code>RETURN head([1,2,3])</code> \u2192 <code>1</code> <code>tail(list)</code> All but first element <code>RETURN tail([1,2,3])</code> \u2192 <code>[2,3]</code> <code>last(list)</code> Last element <code>RETURN last([1,2,3])</code> \u2192 <code>3</code> <code>keys(map)</code> Keys of a map <code>RETURN keys({a:1, b:2})</code> \u2192 <code>['a','b']</code> <code>range(start, end, [step])</code> Generate number sequence <code>RETURN range(1, 5)</code> \u2192 <code>[1,2,3,4,5]</code>"},{"location":"guides/cypher-querying/#path-functions","title":"Path Functions","text":"Function Description Example <code>length(path)</code> Number of relationships in path <code>RETURN length(path)</code> <code>nodes(path)</code> List of nodes in path <code>RETURN nodes(path)</code> <code>relationships(path)</code> List of relationships in path <code>RETURN relationships(path)</code>"},{"location":"guides/cypher-querying/#type-conversion-functions","title":"Type Conversion Functions","text":"Function Description Example <code>toInteger(x)</code> Convert to integer <code>RETURN toInteger('42')</code> \u2192 <code>42</code> <code>toFloat(x)</code> Convert to float <code>RETURN toFloat('3.14')</code> \u2192 <code>3.14</code> <code>toString(x)</code> Convert to string <code>RETURN toString(42)</code> \u2192 <code>'42'</code> <code>toBoolean(x)</code> Convert to boolean <code>RETURN toBoolean('true')</code> \u2192 <code>true</code>"},{"location":"guides/cypher-querying/#null-handling-functions","title":"Null Handling Functions","text":"Function Description Example <code>coalesce(x, y, ...)</code> First non-null value <code>RETURN coalesce(null, 'default')</code> \u2192 <code>'default'</code> <code>nullif(a, b)</code> Return null if a = b <code>RETURN nullif(5, 5)</code> \u2192 <code>null</code>"},{"location":"guides/cypher-querying/#example-usage","title":"Example Usage","text":"<pre><code>// String manipulation\nMATCH (p:Paper)\nRETURN toUpper(p.title) AS upper_title,\n       substring(p.abstract, 0, 100) AS abstract_preview\n\n// Math operations\nMATCH (p:Paper)\nRETURN p.title, round(p.citations / 10.0) * 10 AS rounded_citations\n\n// List operations\nMATCH (a:Author)\nWHERE size(a.affiliations) &gt; 1\nRETURN a.name, head(a.affiliations) AS primary_affiliation\n\n// Type conversion\nMATCH (p:Paper)\nWHERE toInteger(p.year_str) &gt; 2020\nRETURN p.title\n</code></pre>"},{"location":"guides/cypher-querying/#order-by-skip-limit","title":"ORDER BY, SKIP, LIMIT","text":""},{"location":"guides/cypher-querying/#sorting","title":"Sorting","text":"<pre><code>// Ascending (default)\nORDER BY p.year\n\n// Descending\nORDER BY p.year DESC\n\n// Multiple columns\nORDER BY p.year DESC, p.title ASC\n\n// By alias\nRETURN p.title, p.citations AS cites\nORDER BY cites DESC\n</code></pre>"},{"location":"guides/cypher-querying/#pagination","title":"Pagination","text":"<pre><code>// First 10 results\nLIMIT 10\n\n// Skip first 20, take next 10\nSKIP 20\nLIMIT 10\n\n// Combined\nRETURN p.title\nORDER BY p.year DESC\nSKIP 100\nLIMIT 25\n</code></pre>"},{"location":"guides/cypher-querying/#create-clause","title":"CREATE Clause","text":"<p>Create new nodes and relationships.</p>"},{"location":"guides/cypher-querying/#creating-nodes","title":"Creating Nodes","text":"<pre><code>// Simple node\nCREATE (p:Paper {title: 'My Paper'})\n\n// With properties\nCREATE (p:Paper {\n  title: 'New Research',\n  year: 2024,\n  venue: 'ArXiv',\n  citations: 0\n})\nRETURN p\n\n// Multiple nodes\nCREATE (a:Author {name: 'Alice'}), (b:Author {name: 'Bob'})\n</code></pre>"},{"location":"guides/cypher-querying/#creating-relationships","title":"Creating Relationships","text":"<pre><code>// Between existing nodes\nMATCH (p:Paper {title: 'Paper A'}), (a:Author {name: 'Alice'})\nCREATE (p)-[:AUTHORED_BY {position: 1}]-&gt;(a)\n\n// Create node and relationship together\nCREATE (p:Paper {title: 'New Paper'})-[:AUTHORED_BY]-&gt;(a:Author {name: 'New Author'})\n</code></pre>"},{"location":"guides/cypher-querying/#returning-created-elements","title":"Returning Created Elements","text":"<pre><code>CREATE (p:Paper {title: 'My Paper', year: 2024})\nRETURN p.title, p.year\n</code></pre>"},{"location":"guides/cypher-querying/#with-clause","title":"WITH Clause","text":"<p>The <code>WITH</code> clause chains query parts together.</p>"},{"location":"guides/cypher-querying/#intermediate-processing","title":"Intermediate Processing","text":"<pre><code>// Filter after aggregation\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)\nWITH a, COUNT(p) AS paper_count\nWHERE paper_count &gt; 5\nRETURN a.name, paper_count\n</code></pre>"},{"location":"guides/cypher-querying/#subquery-like-behavior","title":"Subquery-like Behavior","text":"<pre><code>// First find top authors, then their papers\nMATCH (a:Author)&lt;-[:AUTHORED_BY]-(p:Paper)\nWITH a, COUNT(p) AS papers\nORDER BY papers DESC\nLIMIT 10\nMATCH (a)&lt;-[:AUTHORED_BY]-(recent:Paper)\nWHERE recent.year &gt;= 2022\nRETURN a.name, recent.title\n</code></pre>"},{"location":"guides/cypher-querying/#unwind-clause","title":"UNWIND Clause","text":"<p>Expand a list into individual rows.</p> <pre><code>// Expand literal list\nUNWIND [1, 2, 3] AS num\nRETURN num\n\n// Expand list property\nMATCH (p:Paper)\nUNWIND p.keywords AS keyword\nRETURN keyword, COUNT(*) AS usage\nORDER BY usage DESC\n\n// Create multiple from list\nUNWIND ['Alice', 'Bob', 'Charlie'] AS name\nCREATE (a:Author {name: name})\n</code></pre>"},{"location":"guides/cypher-querying/#call-clause-procedures","title":"CALL Clause (Procedures)","text":"<p>Invoke built-in procedures.</p>"},{"location":"guides/cypher-querying/#vector-search","title":"Vector Search","text":"<pre><code>// Basic vector search\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node, distance\nRETURN node.title, distance\n\n// With threshold\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 100, 0.3)\nYIELD node, distance\nWHERE distance &lt; 0.2\nRETURN node.title, distance\n</code></pre>"},{"location":"guides/cypher-querying/#schema-introspection","title":"Schema Introspection","text":"<pre><code>// List labels\nCALL db.labels()\nYIELD label\nRETURN label\n\n// List relationship types\nCALL db.relationshipTypes()\nYIELD relationshipType\nRETURN relationshipType\n\n// List indexes\nCALL db.indexes()\nYIELD name, type, labelsOrTypes, properties\nRETURN *\n</code></pre>"},{"location":"guides/cypher-querying/#index-management","title":"Index Management","text":""},{"location":"guides/cypher-querying/#create-indexes","title":"Create Indexes","text":"<pre><code>// Scalar index\nCREATE INDEX ON :Paper(year)\n\n// Named index\nCREATE INDEX paper_year FOR (p:Paper) ON (p.year)\n\n// Vector index\nCREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper) ON p.embedding\nOPTIONS {index_type: 'hnsw', metric: 'cosine'}\n\n// JSON Full-Text index\nCREATE JSON FULLTEXT INDEX article_fts\nFOR (a:Article) ON _doc\nOPTIONS {with_positions: true}\n</code></pre>"},{"location":"guides/cypher-querying/#drop-indexes","title":"Drop Indexes","text":"<pre><code>DROP INDEX paper_year\n</code></pre>"},{"location":"guides/cypher-querying/#show-indexes","title":"Show Indexes","text":"<pre><code>SHOW INDEXES\n</code></pre>"},{"location":"guides/cypher-querying/#query-parameters","title":"Query Parameters","text":"<p>Use parameters to avoid injection and improve plan caching.</p>"},{"location":"guides/cypher-querying/#parameter-syntax","title":"Parameter Syntax","text":"<pre><code>// In query\nMATCH (p:Paper)\nWHERE p.year = $year AND p.venue = $venue\nRETURN p.title\n</code></pre>"},{"location":"guides/cypher-querying/#cli-usage","title":"CLI Usage","text":"<pre><code>uni query \"MATCH (p:Paper) WHERE p.year = \\$year RETURN p\" \\\n    --params '{\"year\": 2023}' \\\n    --path ./storage\n</code></pre>"},{"location":"guides/cypher-querying/#session-variables","title":"Session Variables","text":"<p>Session variables provide scoped context that's automatically available in all queries within a session. This is ideal for multi-tenant applications.</p>"},{"location":"guides/cypher-querying/#creating-a-session","title":"Creating a Session","text":"<pre><code>// Rust API\nlet session = db.session()\n    .set(\"tenant_id\", \"acme-corp\")\n    .set(\"user_id\", \"user-123\")\n    .set(\"granted_tags\", vec![\"public\", \"team:eng\"])\n    .build();\n</code></pre>"},{"location":"guides/cypher-querying/#using-session-variables","title":"Using Session Variables","text":"<p>Access session variables with the <code>$session.</code> prefix:</p> <pre><code>// Automatic tenant filtering\nMATCH (d:Document)\nWHERE d.tenant_id = $session.tenant_id\nRETURN d.title\n\n// Multiple session variables\nMATCH (e:Event)\nWHERE e.tenant_id = $session.tenant_id\n  AND e.created_by = $session.user_id\nRETURN e\n\n// Combining session variables with query parameters\nMATCH (d:Document)\nWHERE d.tenant_id = $session.tenant_id\n  AND d.status = $status\nRETURN d\n</code></pre>"},{"location":"guides/cypher-querying/#session-variable-benefits","title":"Session Variable Benefits","text":"Benefit Description Reduced boilerplate No need to pass tenant_id to every query Security Variables are immutable after session creation Consistency Same context applied to all queries in session Multi-tenancy Natural pattern for SaaS applications"},{"location":"guides/cypher-querying/#session-queries-vs-regular-queries","title":"Session Queries vs Regular Queries","text":"<pre><code>// Without session (repetitive)\ndb.query_with(\"MATCH (d:Document) WHERE d.tenant = $t RETURN d\")\n    .param(\"t\", \"acme\")\n    .fetch_all().await?;\n\n// With session (cleaner)\nlet session = db.session().set(\"tenant\", \"acme\").build();\nsession.query(\"MATCH (d:Document) WHERE d.tenant = $session.tenant RETURN d\").await?;\n</code></pre>"},{"location":"guides/cypher-querying/#temporal-queries","title":"Temporal Queries","text":"<p>Uni provides functions for querying temporal (time-based) data with validity ranges.</p>"},{"location":"guides/cypher-querying/#validat-function","title":"validAt Function","text":"<p>Check if a node or edge was valid at a specific point in time:</p> <pre><code>// Basic validAt usage\nMATCH (e:Event)\nWHERE uni.validAt(e, 'valid_from', 'valid_to', datetime($time))\nRETURN e.name, e.valid_from, e.valid_to\n</code></pre> <p>Parameters: - <code>e</code>: Node or edge to check - <code>'valid_from'</code>: Property name for start time - <code>'valid_to'</code>: Property name for end time - <code>datetime($time)</code>: Point in time to check</p> <p>Semantics: <code>valid_from &lt;= time &lt; valid_to</code> (half-open interval)</p>"},{"location":"guides/cypher-querying/#valid_at-macro","title":"VALID_AT Macro","text":"<p>For convenience, use the <code>VALID_AT</code> macro with default property names:</p> <pre><code>// Macro form (uses 'valid_from' and 'valid_to' by default)\nMATCH (e:Event)\nWHERE e VALID_AT datetime('2024-06-15T12:00:00Z')\nRETURN e.name\n</code></pre>"},{"location":"guides/cypher-querying/#custom-property-names","title":"Custom Property Names","text":"<p>Specify custom property names if your schema differs:</p> <pre><code>// With custom property names\nMATCH (c:Contract)\nWHERE c VALID_AT(datetime($check_time), 'start_date', 'end_date')\nRETURN c.name, c.value\n</code></pre>"},{"location":"guides/cypher-querying/#temporal-query-patterns","title":"Temporal Query Patterns","text":"<p>Find currently valid records:</p> <pre><code>MATCH (e:Employee)\nWHERE uni.validAt(e, 'hire_date', 'termination_date', datetime())\nRETURN e.name, e.department\n</code></pre> <p>Find records valid at a historical point:</p> <pre><code>MATCH (p:Price)\nWHERE p.product_id = $product_id\n  AND uni.validAt(p, 'effective_from', 'effective_to', datetime('2024-01-01'))\nRETURN p.amount\n</code></pre> <p>Temporal edges:</p> <pre><code>MATCH (e:Employee)-[r:WORKS_IN]-&gt;(d:Department)\nWHERE uni.validAt(r, 'start_date', 'end_date', datetime($as_of_date))\nRETURN e.name, d.name\n</code></pre> <p>Open-ended validity (NULL end date):</p> <pre><code>// Records with NULL valid_to are considered currently valid\nMATCH (m:Membership)\nWHERE m.valid_to IS NULL\n  OR m.valid_to &gt; datetime()\nRETURN m\n</code></pre>"},{"location":"guides/cypher-querying/#delete-clause","title":"DELETE Clause","text":"<p>Remove nodes and relationships from the graph.</p>"},{"location":"guides/cypher-querying/#deleting-relationships","title":"Deleting Relationships","text":"<pre><code>// Delete a specific relationship\nMATCH (a:Author)-[r:AUTHORED]-&gt;(p:Paper)\nWHERE a.name = 'Alice' AND p.title = 'Old Paper'\nDELETE r\n\n// Delete all relationships of a type\nMATCH ()-[r:DEPRECATED]-&gt;()\nDELETE r\n</code></pre>"},{"location":"guides/cypher-querying/#deleting-nodes","title":"Deleting Nodes","text":"<pre><code>// Delete a node (must have no relationships)\nMATCH (p:Paper {title: 'Deleted Paper'})\nDELETE p\n\n// Delete node and all its relationships (DETACH)\nMATCH (p:Paper {title: 'Deleted Paper'})\nDETACH DELETE p\n\n// Delete multiple nodes\nMATCH (p:Paper)\nWHERE p.year &lt; 1990\nDETACH DELETE p\n</code></pre>"},{"location":"guides/cypher-querying/#conditional-deletion","title":"Conditional Deletion","text":"<pre><code>// Delete only if condition is met\nMATCH (p:Paper)\nWHERE p.citations = 0 AND p.year &lt; 2000\nDETACH DELETE p\nRETURN COUNT(*) AS deleted_count\n</code></pre>"},{"location":"guides/cypher-querying/#union-clause","title":"UNION Clause","text":"<p>Combine results from multiple queries.</p>"},{"location":"guides/cypher-querying/#union-distinct","title":"UNION (Distinct)","text":"<pre><code>// Combine results, removing duplicates\nMATCH (a:Author {affiliation: 'MIT'})\nRETURN a.name AS name\nUNION\nMATCH (a:Author {affiliation: 'Stanford'})\nRETURN a.name AS name\n</code></pre>"},{"location":"guides/cypher-querying/#union-all-keep-duplicates","title":"UNION ALL (Keep Duplicates)","text":"<pre><code>// Combine results, keeping all rows\nMATCH (p:Paper)-[:CITES]-&gt;(:Paper {title: 'Paper A'})\nRETURN p.title AS title\nUNION ALL\nMATCH (p:Paper)-[:CITES]-&gt;(:Paper {title: 'Paper B'})\nRETURN p.title AS title\n</code></pre>"},{"location":"guides/cypher-querying/#multi-way-union","title":"Multi-way UNION","text":"<pre><code>// Combine multiple queries\nMATCH (a:Author) WHERE a.h_index &gt; 50\nRETURN a.name AS name, 'high_impact' AS category\nUNION\nMATCH (a:Author) WHERE a.papers &gt; 100\nRETURN a.name AS name, 'prolific' AS category\nUNION\nMATCH (a:Author) WHERE a.citations &gt; 10000\nRETURN a.name AS name, 'highly_cited' AS category\n</code></pre>"},{"location":"guides/cypher-querying/#with-recursive-clause","title":"WITH RECURSIVE Clause","text":"<p>Execute recursive queries using Common Table Expressions (CTEs).</p>"},{"location":"guides/cypher-querying/#basic-recursive-query","title":"Basic Recursive Query","text":"<pre><code>// Find all transitive citations (papers cited by cited papers)\nWITH RECURSIVE citation_chain AS (\n  // Base case: direct citations\n  MATCH (p:Paper {title: 'Root Paper'})-[:CITES]-&gt;(cited:Paper)\n  RETURN cited\n  UNION\n  // Recursive case: citations of citations\n  MATCH (c:citation_chain)-[:CITES]-&gt;(next:Paper)\n  RETURN next\n)\nMATCH (p:citation_chain)\nRETURN p.title\n</code></pre>"},{"location":"guides/cypher-querying/#recursive-path-finding","title":"Recursive Path Finding","text":"<pre><code>// Find all ancestors in a hierarchy\nWITH RECURSIVE ancestors AS (\n  MATCH (n:Category {name: 'Machine Learning'})\n  RETURN n\n  UNION\n  MATCH (a:ancestors)-[:PARENT]-&gt;(parent:Category)\n  RETURN parent\n)\nMATCH (a:ancestors)\nRETURN a.name AS category_hierarchy\n</code></pre>"},{"location":"guides/cypher-querying/#explain-clause","title":"EXPLAIN Clause","text":"<p>Inspect the query execution plan without running the query.</p>"},{"location":"guides/cypher-querying/#basic-explain","title":"Basic EXPLAIN","text":"<pre><code>// Show query plan\nEXPLAIN MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\nWHERE p.year &gt; 2020\nRETURN cited.title, COUNT(*) AS citation_count\nORDER BY citation_count DESC\nLIMIT 10\n</code></pre>"},{"location":"guides/cypher-querying/#understanding-the-plan","title":"Understanding the Plan","text":"<p>The EXPLAIN output shows: - Scan operations: How data is accessed (index scan, full scan) - Filter operations: Where predicates are applied - Join operations: How patterns are matched - Aggregation: Grouping and aggregation steps - Sort/Limit: Final ordering and pagination - Index usage: Which indexes are used and why - Cost estimates: Estimated rows and query cost</p>"},{"location":"guides/cypher-querying/#explain-output-example","title":"EXPLAIN Output Example","text":"<pre><code>Plan:\n\u251c\u2500 Scan: Paper\n\u2502  \u251c\u2500 Filter: year &gt; 2020\n\u2502  \u2502  \u2514\u2500 Index: paper_year_btree (BTREE) \u2713\n\u2502  \u251c\u2500 Estimated rows: 500\n\u2502  \u2514\u2500 Cost: 12.5\n\u251c\u2500 Expand: CITES (OUTGOING)\n\u2502  \u251c\u2500 Estimated paths: 2500\n\u2502  \u2514\u2500 Cost: 125.0\n\u2514\u2500 Target: Paper\n   \u2514\u2500 Estimated rows: 2500\n\nIndex Usage:\n  \u2713 Paper.year \u2192 paper_year_btree (BTREE)\n  \u2717 Paper.venue \u2192 paper_venue_idx (not in filter)\n\nTotal estimated cost: 137.5\n</code></pre>"},{"location":"guides/cypher-querying/#profile-clause","title":"PROFILE Clause","text":"<p>Execute the query with runtime statistics collection.</p>"},{"location":"guides/cypher-querying/#basic-profile","title":"Basic PROFILE","text":"<pre><code>// Execute and collect statistics\nPROFILE MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\nWHERE p.year &gt; 2020\nRETURN cited.title, COUNT(*) AS citation_count\nORDER BY citation_count DESC\nLIMIT 10\n</code></pre>"},{"location":"guides/cypher-querying/#profile-output","title":"PROFILE Output","text":"<p>PROFILE returns detailed execution metrics:</p> <pre><code>Execution Profile:\n\u251c\u2500 Scan: Paper\n\u2502  \u251c\u2500 Actual rows: 423\n\u2502  \u251c\u2500 Time: 12.3ms\n\u2502  \u2514\u2500 Index hits: 423\n\u251c\u2500 Expand: CITES\n\u2502  \u251c\u2500 Actual paths: 1892\n\u2502  \u2514\u2500 Time: 45.6ms\n\u2514\u2500 Project\n   \u251c\u2500 Actual rows: 1892\n   \u2514\u2500 Time: 1.2ms\n\nSummary:\n  Total time: 59.1ms\n  Peak memory: 2.4MB\n  Rows returned: 1892\n</code></pre>"},{"location":"guides/cypher-querying/#using-profile-for-optimization","title":"Using PROFILE for Optimization","text":"<pre><code>// Compare two query approaches\nPROFILE MATCH (a:Author)-[:AUTHORED]-&gt;(p:Paper)\nWHERE a.name = 'Alice' AND p.year &gt; 2020\nRETURN p.title\n\n// vs\n\nPROFILE MATCH (p:Paper)\nWHERE p.year &gt; 2020\nMATCH (a:Author {name: 'Alice'})-[:AUTHORED]-&gt;(p)\nRETURN p.title\n</code></pre>"},{"location":"guides/cypher-querying/#common-query-patterns","title":"Common Query Patterns","text":""},{"location":"guides/cypher-querying/#find-connected-nodes","title":"Find Connected Nodes","text":"<pre><code>MATCH (start:Paper {title: 'Attention Is All You Need'})\nMATCH (start)-[:CITES]-&gt;(cited)\nRETURN cited.title, cited.year\nORDER BY cited.year DESC\n</code></pre>"},{"location":"guides/cypher-querying/#bidirectional-relationships","title":"Bidirectional Relationships","text":"<pre><code>// Papers that cite each other\nMATCH (a:Paper)-[:CITES]-&gt;(b:Paper)-[:CITES]-&gt;(a)\nRETURN a.title, b.title\n</code></pre>"},{"location":"guides/cypher-querying/#shortest-path-future","title":"Shortest Path (Future)","text":"<pre><code>// Shortest path between two nodes\nMATCH path = shortestPath((a:Author {name: 'Alice'})-[:COAUTHOR*]-(b:Author {name: 'Bob'}))\nRETURN path\n</code></pre>"},{"location":"guides/cypher-querying/#degree-counting","title":"Degree Counting","text":"<pre><code>// Count outgoing relationships\nMATCH (p:Paper)-[c:CITES]-&gt;()\nRETURN p.title, COUNT(c) AS out_degree\nORDER BY out_degree DESC\n</code></pre>"},{"location":"guides/cypher-querying/#top-k-with-ties","title":"Top-K with Ties","text":"<pre><code>MATCH (p:Paper)\nWITH p, p.citations AS cites\nORDER BY cites DESC\nLIMIT 10\nRETURN p.title, cites\n</code></pre>"},{"location":"guides/cypher-querying/#graph-algorithms","title":"Graph Algorithms","text":"<p>Uni provides 36 high-performance graph algorithms available via the <code>algo</code> namespace.</p>"},{"location":"guides/cypher-querying/#centrality-algorithms","title":"Centrality Algorithms","text":"Algorithm Procedure Description PageRank <code>algo.pageRank</code> Importance based on incoming links Betweenness <code>algo.betweenness</code> Nodes on shortest paths Closeness <code>algo.closeness</code> Average distance to all nodes Degree Centrality <code>algo.degreeCentrality</code> Connection count Harmonic Centrality <code>algo.harmonicCentrality</code> Harmonic mean distance Eigenvector Centrality <code>algo.eigenvectorCentrality</code> Influence via neighbors Katz Centrality <code>algo.katzCentrality</code> Weighted path influence <pre><code>// PageRank\nCALL algo.pageRank(['Paper'], ['CITES'])\nYIELD nodeId, score\nRETURN nodeId, score\nORDER BY score DESC\n\n// Betweenness Centrality\nCALL algo.betweenness(['Author'], ['COAUTHOR'], true, 100)\nYIELD nodeId, score\n\n// Closeness Centrality\nCALL algo.closeness(['Station'], ['CONNECTS'])\nYIELD nodeId, score\n</code></pre>"},{"location":"guides/cypher-querying/#community-detection-algorithms","title":"Community Detection Algorithms","text":"Algorithm Procedure Description Louvain <code>algo.louvain</code> Modularity-based community detection Label Propagation <code>algo.labelPropagation</code> Fast community detection WCC <code>algo.wcc</code> Weakly connected components SCC <code>algo.scc</code> Strongly connected components K-Core <code>algo.kCore</code> K-core decomposition Triangle Count <code>algo.triangleCount</code> Count triangles per node <pre><code>// Louvain\nCALL algo.louvain(['User'], ['INTERACTS'])\nYIELD nodeId, communityId\n\n// Label Propagation\nCALL algo.labelPropagation(['User'], ['INTERACTS'])\nYIELD nodeId, communityId\n\n// Weakly Connected Components\nCALL algo.wcc(['User'], ['INTERACTS'])\nYIELD nodeId, componentId\n\n// Strongly Connected Components\nCALL algo.scc(['Task'], ['DEPENDS_ON'])\nYIELD nodeId, componentId\n\n// K-Core Decomposition\nCALL algo.kCore(['User'], ['FRIEND'], 3)\nYIELD nodeId, coreNumber\n\n// Triangle Count\nCALL algo.triangleCount(['User'], ['FRIEND'])\nYIELD nodeId, triangleCount\n</code></pre>"},{"location":"guides/cypher-querying/#path-finding-algorithms","title":"Path Finding Algorithms","text":"Algorithm Procedure Description Dijkstra <code>algo.dijkstra</code> Shortest weighted path Bellman-Ford <code>algo.bellmanFord</code> Shortest path with negative weights A* <code>algo.astar</code> Heuristic shortest path Bidirectional Dijkstra <code>algo.bidirectionalDijkstra</code> Two-way shortest path K-Shortest Paths <code>algo.kShortestPaths</code> Multiple shortest paths All Simple Paths <code>algo.allSimplePaths</code> All paths between nodes APSP <code>algo.allPairsShortestPath</code> All pairs shortest path <pre><code>// Dijkstra shortest path\nCALL algo.dijkstra(['Station'], ['CONNECTS'], $startId, $endId, 'distance')\nYIELD path, cost\n\n// K-Shortest Paths\nCALL algo.kShortestPaths(['Station'], ['CONNECTS'], $startId, $endId, 5)\nYIELD path, cost\n\n// All Pairs Shortest Path\nCALL algo.allPairsShortestPath(['Station'], ['CONNECTS'])\nYIELD sourceNodeId, targetNodeId, distance\n</code></pre>"},{"location":"guides/cypher-querying/#similarity-traversal-algorithms","title":"Similarity &amp; Traversal Algorithms","text":"Algorithm Procedure Description Node Similarity <code>algo.nodeSimilarity</code> Jaccard similarity Random Walk <code>algo.randomWalk</code> Random graph traversal Maximal Cliques <code>algo.maximalCliques</code> Find all maximal cliques Graph Coloring <code>algo.graphColoring</code> Vertex coloring <pre><code>// Node Similarity (Jaccard)\nCALL algo.nodeSimilarity(['Product'], ['PURCHASED'])\nYIELD node1, node2, similarity\n\n// Random Walk\nCALL algo.randomWalk(['Page'], ['LINKS'], 10, 5)\nYIELD path\n</code></pre>"},{"location":"guides/cypher-querying/#structural-analysis-algorithms","title":"Structural Analysis Algorithms","text":"Algorithm Procedure Description Topological Sort <code>algo.topologicalSort</code> DAG ordering Cycle Detection <code>algo.cycleDetection</code> Find cycles Bipartite Check <code>algo.bipartiteCheck</code> Test bipartiteness Bridges <code>algo.bridges</code> Find bridge edges Articulation Points <code>algo.articulationPoints</code> Find cut vertices Elementary Circuits <code>algo.elementaryCircuits</code> Find all simple cycles <pre><code>// Topological sort (for DAGs)\nCALL algo.topologicalSort(['Task'], ['DEPENDS_ON'])\nYIELD nodeId, order\n\n// Find articulation points\nCALL algo.articulationPoints(['Router'], ['CONNECTS'])\nYIELD nodeId\n</code></pre>"},{"location":"guides/cypher-querying/#flow-matching-algorithms","title":"Flow &amp; Matching Algorithms","text":"Algorithm Procedure Description Maximum Matching <code>algo.maxMatching</code> Maximum cardinality matching Minimum Spanning Tree <code>algo.mst</code> MST using Prim/Kruskal Dinic's Algorithm <code>algo.dinic</code> Maximum flow Ford-Fulkerson <code>algo.fordFulkerson</code> Maximum flow <pre><code>// Minimum Spanning Tree\nCALL algo.mst(['City'], ['ROAD'], 'distance')\nYIELD edge, cost\n\n// Maximum Matching\nCALL algo.maxMatching(['Worker', 'Job'], ['CAN_DO'])\nYIELD node1, node2\n</code></pre>"},{"location":"guides/cypher-querying/#schema-ddl","title":"Schema DDL","text":"<p>Uni supports Data Definition Language (DDL) statements for managing schema.</p>"},{"location":"guides/cypher-querying/#create-label-vertex-type","title":"Create Label (Vertex Type)","text":"<pre><code>// Create a label with properties\nCREATE LABEL Paper (\n  title STRING NOT NULL,\n  year INT32,\n  abstract STRING,\n  embedding VECTOR(768)\n)\n\n// Create label with default values\nCREATE LABEL Author (\n  name STRING NOT NULL,\n  h_index INT32 DEFAULT 0,\n  active BOOLEAN DEFAULT true\n)\n</code></pre>"},{"location":"guides/cypher-querying/#create-edge-type","title":"Create Edge Type","text":"<pre><code>// Create edge type with source/destination constraints\nCREATE EDGE TYPE AUTHORED FROM Author TO Paper (\n  position INT32,\n  corresponding BOOLEAN DEFAULT false\n)\n\n// Edge type between multiple label types\nCREATE EDGE TYPE COLLABORATES FROM Author TO Author (\n  papers_count INT32\n)\n</code></pre>"},{"location":"guides/cypher-querying/#alter-schema","title":"Alter Schema","text":"<pre><code>// Add a property to an existing label\nALTER LABEL Paper ADD abstract STRING\n\n// Drop a property\nALTER LABEL Paper DROP deprecated_field\n\n// Rename a property\nALTER LABEL Paper RENAME old_name TO new_name\n</code></pre>"},{"location":"guides/cypher-querying/#drop-schema-elements","title":"Drop Schema Elements","text":"<pre><code>// Drop a label (must have no vertices)\nDROP LABEL TempLabel\n\n// Drop an edge type\nDROP EDGE TYPE OLD_RELATIONSHIP\n</code></pre>"},{"location":"guides/cypher-querying/#constraints","title":"Constraints","text":"<p>Define and manage data integrity constraints.</p>"},{"location":"guides/cypher-querying/#create-constraints","title":"Create Constraints","text":"<pre><code>// Unique constraint\nCREATE CONSTRAINT paper_doi_unique\nFOR (p:Paper) REQUIRE p.doi IS UNIQUE\n\n// Existence constraint (property must be present)\nCREATE CONSTRAINT author_name_exists\nFOR (a:Author) REQUIRE a.name IS NOT NULL\n\n// Check constraint (custom validation)\nCREATE CONSTRAINT paper_year_valid\nFOR (p:Paper) REQUIRE p.year &gt;= 1900 AND p.year &lt;= 2100\n</code></pre>"},{"location":"guides/cypher-querying/#show-constraints","title":"Show Constraints","text":"<pre><code>// List all constraints\nSHOW CONSTRAINTS\n\n// Filter by label\nSHOW CONSTRAINTS FOR :Paper\n</code></pre>"},{"location":"guides/cypher-querying/#drop-constraints","title":"Drop Constraints","text":"<pre><code>DROP CONSTRAINT paper_doi_unique\n</code></pre>"},{"location":"guides/cypher-querying/#database-management","title":"Database Management","text":"<p>Administrative commands and procedures for database maintenance.</p>"},{"location":"guides/cypher-querying/#backup","title":"BACKUP","text":"<p>Create a backup of the database to a specified destination.</p> <pre><code>// Backup to local path\nBACKUP TO './backups/backup_2026_01_17'\n\n// Backup to S3\nBACKUP TO 's3://my-bucket/backups/backup_2026_01_17'\n\n// Backup with options\nBACKUP TO './backups/full' WITH incremental = false, compress = true\n</code></pre>"},{"location":"guides/cypher-querying/#vacuum","title":"VACUUM","text":"<p>Reclaim storage space by removing deleted data and compacting files.</p> <pre><code>// Perform vacuum operation\nVACUUM\n\n// Note: VACUUM may take time on large databases\n// and temporarily increases I/O load\n</code></pre>"},{"location":"guides/cypher-querying/#checkpoint","title":"CHECKPOINT","text":"<p>Force a checkpoint to flush all pending writes to durable storage.</p> <pre><code>// Force checkpoint\nCHECKPOINT\n\n// Useful before taking external backups\n// or when durability guarantee is needed immediately\n</code></pre>"},{"location":"guides/cypher-querying/#compaction","title":"Compaction","text":"<pre><code>// Trigger storage compaction\nCALL db.compact()\nYIELD fragmentsCompacted, bytesReclaimed, duration\n\n// Check compaction status\nCALL db.compactionStatus()\nYIELD status, progress, estimatedRemaining\n</code></pre>"},{"location":"guides/cypher-querying/#snapshots","title":"Snapshots","text":"<pre><code>// Create a named snapshot\nCALL db.snapshot.create('before_migration')\nYIELD name, created, size\n\n// List available snapshots\nCALL db.snapshot.list()\nYIELD name, created, size\n\n// Restore to a snapshot\nCALL db.snapshot.restore('before_migration')\n</code></pre>"},{"location":"guides/cypher-querying/#schema-introspection_1","title":"Schema Introspection","text":"<pre><code>// List all labels\nCALL db.labels()\nYIELD label, propertyCount, nodeCount, indexCount\nRETURN label, nodeCount\n\n// List all relationship types\nCALL db.relationshipTypes()\nYIELD type, sourceLabels, targetLabels, propertyCount\nRETURN type\n\n// List all edge types (alias)\nCALL db.edgeTypes()\nYIELD type, sourceLabels, targetLabels, propertyCount\n\n// List all indexes\nCALL db.indexes()\nYIELD name, type, label, properties, state\nWHERE type = 'VECTOR'\nRETURN name, label\n\n// List all constraints\nCALL db.constraints()\nYIELD name, type, label, properties, enabled\nRETURN name, type\n\n// Get detailed label info\nCALL db.schema.labelInfo('Paper')\nYIELD property, dataType, nullable, indexed, unique\nRETURN property, dataType\n</code></pre>"},{"location":"guides/cypher-querying/#schema-ddl-procedures","title":"Schema DDL Procedures","text":"<p>Create and modify schema at runtime via procedures:</p> <pre><code>// Create a new label\nCALL db.createLabel('Product', {\n  properties: {\n    name: { type: 'STRING', nullable: false },\n    price: { type: 'FLOAT64' },\n    embedding: { type: 'VECTOR', dimensions: 128 }\n  }\n})\n\n// Create an edge type\nCALL db.createEdgeType('PURCHASED', ['Customer'], ['Product'], {\n  properties: {\n    quantity: { type: 'INT32' },\n    timestamp: { type: 'TIMESTAMP' }\n  }\n})\n\n// Create an index\nCALL db.createIndex('Product', 'name', { type: 'BTREE' })\n\n// Create a vector index\nCALL db.createIndex('Product', 'embedding', {\n  type: 'VECTOR',\n  metric: 'cosine',\n  index_type: 'hnsw',\n  m: 16,\n  ef_construction: 200\n})\n\n// Create a constraint\nCALL db.createConstraint('Product', 'UNIQUE', ['sku'])\n\n// Drop operations\nCALL db.dropLabel('TempLabel')\nCALL db.dropEdgeType('OLD_RELATIONSHIP')\nCALL db.dropIndex('Product', 'old_index')\nCALL db.dropConstraint('Product', 'constraint_name')\n</code></pre>"},{"location":"guides/cypher-querying/#crdt-properties","title":"CRDT Properties","text":"<p>Uni supports CRDT (Conflict-free Replicated Data Type) properties for distributed, eventually-consistent data. CRDT properties can be defined in the schema and manipulated via Cypher.</p>"},{"location":"guides/cypher-querying/#schema-definition","title":"Schema Definition","text":"<p>Define CRDT properties in your schema:</p> <pre><code>{\n  \"properties\": {\n    \"Paper\": {\n      \"title\": { \"type\": \"String\", \"nullable\": false },\n      \"view_count\": { \"type\": \"Crdt\", \"crdt_type\": \"GCounter\" },\n      \"tags\": { \"type\": \"Crdt\", \"crdt_type\": \"ORSet\" },\n      \"metadata\": { \"type\": \"Crdt\", \"crdt_type\": \"LWWMap\" }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/cypher-querying/#supported-crdt-types","title":"Supported CRDT Types","text":"Type Description Cypher Operations <code>GCounter</code> Grow-only counter Increment only <code>GSet</code> Grow-only set Add only <code>ORSet</code> Add/remove set (add-wins) Add, remove <code>LWWRegister</code> Single value (last-writer-wins) Set value <code>LWWMap</code> Key-value map (per-key LWW) Put, remove keys <code>Rga</code> Ordered sequence Insert, delete at position"},{"location":"guides/cypher-querying/#querying-crdt-properties","title":"Querying CRDT Properties","text":"<pre><code>// Read CRDT values (returns materialized value)\nMATCH (p:Paper {id: 'paper_001'})\nRETURN p.view_count, p.tags\n\n// GCounter returns total count\n// ORSet returns list of visible elements\n// LWWMap returns map of non-tombstoned entries\n</code></pre>"},{"location":"guides/cypher-querying/#updating-crdt-properties","title":"Updating CRDT Properties","text":"<p>CRDT updates use special syntax to ensure conflict-free merging:</p> <pre><code>// Increment a GCounter\nMATCH (p:Paper {id: 'paper_001'})\nSET p.view_count = crdt.increment(p.view_count, 1)\n\n// Add to an ORSet\nMATCH (p:Paper {id: 'paper_001'})\nSET p.tags = crdt.add(p.tags, 'machine-learning')\n\n// Remove from an ORSet\nMATCH (p:Paper {id: 'paper_001'})\nSET p.tags = crdt.remove(p.tags, 'deprecated-tag')\n\n// Update LWWMap\nMATCH (p:Paper {id: 'paper_001'})\nSET p.metadata = crdt.put(p.metadata, 'reviewed', true)\n</code></pre>"},{"location":"guides/cypher-querying/#crdt-functions","title":"CRDT Functions","text":"Function CRDT Types Description <code>crdt.increment(counter, n)</code> GCounter Increment by n <code>crdt.add(set, elem)</code> GSet, ORSet Add element <code>crdt.remove(set, elem)</code> ORSet Remove element <code>crdt.set(register, value)</code> LWWRegister Set value <code>crdt.put(map, key, value)</code> LWWMap Put key-value <code>crdt.delete(map, key)</code> LWWMap Delete key <code>crdt.insert(rga, index, elem)</code> Rga Insert at position <code>crdt.deleteAt(rga, index)</code> Rga Delete at position"},{"location":"guides/cypher-querying/#distributed-sync","title":"Distributed Sync","text":"<p>CRDT properties enable conflict-free synchronization across distributed nodes:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Node A    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   Node B    \u2502\n\u2502             \u2502         \u2502             \u2502\n\u2502 increment   \u2502         \u2502 increment   \u2502\n\u2502 view_count  \u2502         \u2502 view_count  \u2502\n\u2502    +5       \u2502         \u2502    +3       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                       \u2502\n       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n                   \u25bc\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502   Merged    \u2502\n            \u2502 view_count  \u2502\n            \u2502     = 8     \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>For detailed CRDT semantics and merge behavior, see CRDT Types.</p>"},{"location":"guides/cypher-querying/#cypher-feature-status","title":"Cypher Feature Status","text":"Feature Status MATCH (basic patterns) Stable WHERE (comparisons, boolean) Stable RETURN, ORDER BY, LIMIT, SKIP Stable Aggregations (COUNT, SUM, AVG, MIN, MAX, COLLECT) Stable Window Functions (OVER clause) Stable Scalar Functions (40+ functions) Stable CREATE (nodes and relationships) Stable WITH clause Stable UNWIND Stable CALL procedures Stable Index management Stable JSON Full-Text Search (CONTAINS) Stable Variable-length paths (<code>*1..3</code>) Stable MERGE Stable SET / REMOVE Stable DELETE / DETACH DELETE Stable UNION / UNION ALL Stable WITH RECURSIVE (CTEs) Stable EXPLAIN (with index usage) Stable PROFILE (runtime statistics) Stable Session Variables (<code>$session.*</code>) Stable Temporal Queries (<code>uni.validAt</code>, <code>VALID_AT</code>) Stable Schema DDL (CREATE/ALTER/DROP LABEL) Stable Schema DDL Procedures (<code>db.createLabel</code>, etc.) Stable Constraints (UNIQUE, EXISTS, CHECK) Stable Composite Key Constraints Stable Graph Algorithms (36 algorithms) Stable CRDT Properties Stable Database Management (BACKUP, VACUUM, CHECKPOINT) Stable Snapshots (create, list, restore) Stable Schema Introspection (db.labels, db.indexes, etc.) Stable Inverted Index (ANY IN pattern) Stable OPTIONAL MATCH Planned Subqueries Planned"},{"location":"guides/cypher-querying/#next-steps","title":"Next Steps","text":"<ul> <li>Vector Search \u2014 Semantic similarity queries</li> <li>Data Ingestion \u2014 Bulk import and streaming writes</li> <li>Performance Tuning \u2014 Query optimization strategies</li> <li>Troubleshooting \u2014 Common issues and solutions</li> </ul>"},{"location":"guides/data-ingestion/","title":"Data Ingestion Guide","text":"<p>This guide covers all methods for getting data into Uni, from bulk imports to streaming writes and programmatic access.</p>"},{"location":"guides/data-ingestion/#overview","title":"Overview","text":"<p>Uni supports multiple ingestion patterns:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         DATA INGESTION PATTERNS                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    BULK IMPORT      \u2502   STREAMING WRITE   \u2502      PROGRAMMATIC API           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 JSONL files       \u2502 \u2022 Real-time inserts \u2502 \u2022 Rust crate API                \u2502\n\u2502 \u2022 CLI import        \u2502 \u2022 HTTP API          \u2502 \u2022 Writer interface              \u2502\n\u2502 \u2022 One-time load     \u2502 \u2022 Continuous        \u2502 \u2022 Fine-grained control          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Best for:           \u2502 Best for:           \u2502 Best for:                       \u2502\n\u2502 Initial data load   \u2502 Live applications   \u2502 Custom pipelines                \u2502\n\u2502 Batch migrations    \u2502 Event streaming     \u2502 Integration code                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/data-ingestion/#bulk-import-cli","title":"Bulk Import (CLI)","text":"<p>The fastest way to load large datasets.</p>"},{"location":"guides/data-ingestion/#input-file-format","title":"Input File Format","text":""},{"location":"guides/data-ingestion/#vertices-jsonl","title":"Vertices (JSONL)","text":"<p>Each line is a JSON object representing a vertex:</p> <pre><code>{\"id\": \"paper_001\", \"title\": \"Attention Is All You Need\", \"year\": 2017, \"venue\": \"NeurIPS\", \"embedding\": [0.12, -0.34, ...]}\n{\"id\": \"paper_002\", \"title\": \"BERT\", \"year\": 2018, \"venue\": \"NAACL\", \"embedding\": [0.08, -0.21, ...]}\n</code></pre> <p>Required Fields: - <code>id</code> (String): Unique external identifier</p> <p>Optional Fields: - Any property defined in your schema - Properties not in schema are ignored</p> <p>Special Fields: - <code>_label</code>: Override default label (if multiple labels)</p>"},{"location":"guides/data-ingestion/#edges-jsonl","title":"Edges (JSONL)","text":"<p>Each line is a JSON object representing an edge:</p> <pre><code>{\"src\": \"paper_002\", \"dst\": \"paper_001\"}\n{\"src\": \"paper_003\", \"dst\": \"paper_001\", \"weight\": 0.95}\n</code></pre> <p>Required Fields: - <code>src</code> (String): Source vertex external ID - <code>dst</code> (String): Destination vertex external ID</p> <p>Optional Fields: - <code>type</code>: Edge type (default: inferred from import config) - Any edge property defined in schema</p>"},{"location":"guides/data-ingestion/#running-import","title":"Running Import","text":"<p>Basic Import:</p> <pre><code>uni import semantic-scholar \\\n    --papers ./data/papers.jsonl \\\n    --citations ./data/citations.jsonl \\\n    --output ./storage\n</code></pre> <p>With Custom Schema:</p> <pre><code>uni import my-dataset \\\n    --papers ./vertices.jsonl \\\n    --citations ./edges.jsonl \\\n    --schema ./schema.json \\\n    --output ./storage\n</code></pre> <p>Tuned for Large Data:</p> <pre><code>uni import wikipedia \\\n    --papers ./articles.jsonl \\\n    --citations ./links.jsonl \\\n    --batch-size 50000 \\\n    --output s3://my-bucket/wiki-graph\n</code></pre>"},{"location":"guides/data-ingestion/#import-options","title":"Import Options","text":"Option Default Description <code>--papers</code> Required Path to vertex JSONL file <code>--citations</code> Required Path to edge JSONL file <code>--output</code> <code>./storage</code> Output storage path <code>--schema</code> Auto-inferred Path to schema JSON <code>--batch-size</code> 10000 Records per batch <code>--skip-validation</code> false Skip schema validation <code>--force</code> false Overwrite existing storage"},{"location":"guides/data-ingestion/#import-process","title":"Import Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           IMPORT PIPELINE                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   [1] SCHEMA LOADING                                                        \u2502\n\u2502       \u2514\u2500\u2500 Load or infer schema from data                                    \u2502\n\u2502                                                                             \u2502\n\u2502   [2] VERTEX PASS                                                           \u2502\n\u2502       \u251c\u2500\u2500 Stream JSONL file                                                 \u2502\n\u2502       \u251c\u2500\u2500 Validate properties against schema                                \u2502\n\u2502       \u251c\u2500\u2500 Allocate VIDs (label_id &lt;&lt; 48 | offset)                          \u2502\n\u2502       \u251c\u2500\u2500 Build ext_id \u2192 VID mapping                                        \u2502\n\u2502       \u2514\u2500\u2500 Write to Lance vertex datasets (batched)                          \u2502\n\u2502                                                                             \u2502\n\u2502   [3] EDGE PASS                                                             \u2502\n\u2502       \u251c\u2500\u2500 Stream JSONL file                                                 \u2502\n\u2502       \u251c\u2500\u2500 Resolve src/dst ext_ids to VIDs                                  \u2502\n\u2502       \u251c\u2500\u2500 Allocate EIDs                                                     \u2502\n\u2502       \u2514\u2500\u2500 Write to Lance edge datasets (batched)                            \u2502\n\u2502                                                                             \u2502\n\u2502   [4] ADJACENCY BUILD                                                       \u2502\n\u2502       \u251c\u2500\u2500 Group edges by (edge_type, direction, source_label)              \u2502\n\u2502       \u251c\u2500\u2500 Build CSR-style neighbor lists                                    \u2502\n\u2502       \u2514\u2500\u2500 Write to Lance adjacency datasets                                 \u2502\n\u2502                                                                             \u2502\n\u2502   [5] INDEX BUILD                                                           \u2502\n\u2502       \u251c\u2500\u2500 Build vector indexes (HNSW/IVF) if configured                    \u2502\n\u2502       \u2514\u2500\u2500 Build scalar indexes if configured                                \u2502\n\u2502                                                                             \u2502\n\u2502   [6] SNAPSHOT                                                              \u2502\n\u2502       \u2514\u2500\u2500 Write manifest with all dataset versions                          \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/data-ingestion/#schema-definition","title":"Schema Definition","text":""},{"location":"guides/data-ingestion/#auto-inference","title":"Auto-Inference","text":"<p>If no schema is provided, Uni infers types from data:</p> <pre><code># Schema inferred from first N records\nuni import my-data --papers data.jsonl --citations edges.jsonl\n</code></pre> <p>Inference Rules: - Integer \u2192 <code>Int64</code> - Float \u2192 <code>Float64</code> - String \u2192 <code>String</code> - Array of floats \u2192 <code>Vector</code> (dimension from first record) - Object \u2192 <code>Json</code></p>"},{"location":"guides/data-ingestion/#manual-schema","title":"Manual Schema","text":"<p>For production, define an explicit schema:</p> <pre><code>{\n  \"schema_version\": 1,\n\n  \"labels\": {\n    \"Paper\": { \"id\": 1, \"is_document\": false },\n    \"Author\": { \"id\": 2, \"is_document\": false }\n  },\n\n  \"edge_types\": {\n    \"CITES\": {\n      \"id\": 1,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Paper\"]\n    },\n    \"AUTHORED_BY\": {\n      \"id\": 2,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Author\"]\n    }\n  },\n\n  \"properties\": {\n    \"Paper\": {\n      \"title\": { \"type\": \"String\", \"nullable\": false },\n      \"year\": { \"type\": \"Int32\", \"nullable\": true },\n      \"abstract\": { \"type\": \"String\", \"nullable\": true },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 }\n    },\n    \"Author\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"email\": { \"type\": \"String\", \"nullable\": true }\n    },\n    \"AUTHORED_BY\": {\n      \"position\": { \"type\": \"Int32\", \"nullable\": true }\n    }\n  },\n\n  \"indexes\": {\n    \"paper_embeddings\": {\n      \"type\": \"vector\",\n      \"label\": \"Paper\",\n      \"property\": \"embedding\",\n      \"config\": { \"index_type\": \"hnsw\", \"metric\": \"cosine\" }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/data-ingestion/#streaming-writes-cypher","title":"Streaming Writes (Cypher)","text":"<p>For real-time applications, use CREATE statements.</p>"},{"location":"guides/data-ingestion/#creating-vertices","title":"Creating Vertices","text":"<pre><code>// Single vertex\nCREATE (p:Paper {\n  title: 'New Research Paper',\n  year: 2024,\n  venue: 'ArXiv'\n})\nRETURN p\n\n// With external ID\nCREATE (p:Paper {\n  id: 'paper_new_001',\n  title: 'New Research'\n})\n</code></pre>"},{"location":"guides/data-ingestion/#creating-edges","title":"Creating Edges","text":"<pre><code>// Between existing vertices\nMATCH (p:Paper {id: 'paper_001'}), (a:Author {id: 'author_001'})\nCREATE (p)-[:AUTHORED_BY {position: 1}]-&gt;(a)\n\n// Create both nodes and edge\nCREATE (p:Paper {title: 'New Paper'})-[:AUTHORED_BY]-&gt;(a:Author {name: 'New Author'})\n</code></pre>"},{"location":"guides/data-ingestion/#batch-creates","title":"Batch Creates","text":"<pre><code>// Multiple vertices\nUNWIND $papers AS paper\nCREATE (p:Paper {\n  id: paper.id,\n  title: paper.title,\n  year: paper.year\n})\n\n// Multiple edges\nUNWIND $edges AS edge\nMATCH (src:Paper {id: edge.src}), (dst:Paper {id: edge.dst})\nCREATE (src)-[:CITES]-&gt;(dst)\n</code></pre>"},{"location":"guides/data-ingestion/#http-api","title":"HTTP API","text":"<pre><code># Create via HTTP\ncurl -X POST http://localhost:8080/query \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"query\": \"CREATE (p:Paper {title: $title, year: $year})\",\n    \"params\": {\"title\": \"New Paper\", \"year\": 2024}\n  }'\n</code></pre>"},{"location":"guides/data-ingestion/#programmatic-api-rust","title":"Programmatic API (Rust)","text":"<p>For maximum control, use the Rust API directly.</p>"},{"location":"guides/data-ingestion/#bulk-loading-with-bulkwriter","title":"Bulk Loading with BulkWriter","text":"<p>The <code>BulkWriter</code> API provides high-performance bulk loading with deferred index building:</p> <pre><code>use uni::prelude::*;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    let db = Uni::open(\"./my-graph\").build().await?;\n\n    // Create a bulk writer with deferred indexing\n    let mut bulk = db.bulk_writer()\n        .defer_vector_indexes(true)   // Defer vector index updates\n        .defer_scalar_indexes(true)   // Defer scalar index updates\n        .batch_size(10_000)           // Flush every 10K records\n        .on_progress(|progress| {\n            println!(\"{}: {} rows processed\",\n                progress.phase, progress.rows_processed);\n        })\n        .build()?;\n\n    // Bulk insert vertices\n    let vertices: Vec&lt;HashMap&lt;String, Value&gt;&gt; = papers\n        .iter()\n        .map(|p| {\n            let mut props = HashMap::new();\n            props.insert(\"title\".into(), Value::String(p.title.clone()));\n            props.insert(\"year\".into(), Value::Int32(p.year));\n            props.insert(\"embedding\".into(), Value::Vector(p.embedding.clone()));\n            props\n        })\n        .collect();\n\n    let vids = bulk.insert_vertices(\"Paper\", vertices).await?;\n    println!(\"Inserted {} vertices\", vids.len());\n\n    // Bulk insert edges\n    let edges: Vec&lt;EdgeData&gt; = citations\n        .iter()\n        .map(|c| EdgeData {\n            src_vid: vid_map[&amp;c.from],\n            dst_vid: vid_map[&amp;c.to],\n            properties: HashMap::new(),\n        })\n        .collect();\n\n    let eids = bulk.insert_edges(\"CITES\", edges).await?;\n    println!(\"Inserted {} edges\", eids.len());\n\n    // Commit and rebuild indexes\n    let stats = bulk.commit().await?;\n    println!(\"Bulk load complete:\");\n    println!(\"  Vertices: {}\", stats.vertices_inserted);\n    println!(\"  Edges: {}\", stats.edges_inserted);\n    println!(\"  Indexes rebuilt: {}\", stats.indexes_rebuilt);\n    println!(\"  Duration: {:?}\", stats.duration);\n\n    Ok(())\n}\n</code></pre>"},{"location":"guides/data-ingestion/#bulkwriter-options","title":"BulkWriter Options","text":"Option Description Default <code>defer_vector_indexes(bool)</code> Defer vector index updates until commit <code>false</code> <code>defer_scalar_indexes(bool)</code> Defer scalar index updates until commit <code>false</code> <code>batch_size(usize)</code> Records per batch before flushing <code>10_000</code> <code>async_indexes(bool)</code> Build indexes in background after commit <code>false</code> <code>on_progress(callback)</code> Progress callback for monitoring None"},{"location":"guides/data-ingestion/#progress-monitoring","title":"Progress Monitoring","text":"<pre><code>let mut bulk = db.bulk_writer()\n    .on_progress(|progress| {\n        match progress.phase {\n            BulkPhase::Inserting =&gt; {\n                println!(\"Inserting: {}/{}\",\n                    progress.rows_processed,\n                    progress.total_rows.unwrap_or(0));\n            }\n            BulkPhase::RebuildingVectorIndex { label, property } =&gt; {\n                println!(\"Building vector index: {}.{}\", label, property);\n            }\n            BulkPhase::RebuildingScalarIndex { label, property } =&gt; {\n                println!(\"Building scalar index: {}.{}\", label, property);\n            }\n            BulkPhase::Finalizing =&gt; {\n                println!(\"Finalizing snapshot...\");\n            }\n            _ =&gt; {}\n        }\n    })\n    .build()?;\n</code></pre>"},{"location":"guides/data-ingestion/#aborting-bulk-operations","title":"Aborting Bulk Operations","text":"<pre><code>let mut bulk = db.bulk_writer().build()?;\nbulk.insert_vertices(\"Paper\", vertices).await?;\n\n// Something went wrong - abort without committing\nbulk.abort().await?;\n// No data is persisted\n</code></pre>"},{"location":"guides/data-ingestion/#performance-guidelines","title":"Performance Guidelines","text":"Dataset Size Recommended Settings &lt; 100K <code>batch_size: 5_000</code>, <code>defer_*: false</code> 100K - 1M <code>batch_size: 10_000</code>, <code>defer_*: true</code> 1M - 10M <code>batch_size: 50_000</code>, <code>defer_*: true</code> &gt; 10M <code>batch_size: 100_000</code>, <code>defer_*: true</code>, <code>async_indexes: true</code>"},{"location":"guides/data-ingestion/#low-level-writer-api","title":"Low-Level Writer API","text":"<p>For fine-grained control, use the low-level writer:</p> <pre><code>use uni::prelude::*;\nuse std::sync::Arc;\n\n#[tokio::main]\nasync fn main() -&gt; anyhow::Result&lt;()&gt; {\n    // Load or create schema\n    let schema_manager = Arc::new(\n        SchemaManager::load(Path::new(\"./storage/schema.json\")).await?\n    );\n\n    // Create storage manager\n    let storage = Arc::new(\n        StorageManager::new(\"./storage\", schema_manager.clone())\n    );\n\n    // Create writer\n    let writer = Writer::new(\n        storage.clone(),\n        schema_manager.clone(),\n        WriteConfig::default()\n    );\n\n    Ok(())\n}\n</code></pre>"},{"location":"guides/data-ingestion/#insert-vertices","title":"Insert Vertices","text":"<pre><code>use uni::core::{Vid, Properties};\n\n// Allocate VID\nlet label_id = schema_manager.get_label_id(\"Paper\")?;\nlet vid = writer.allocate_vid(label_id)?;\n\n// Build properties\nlet mut props = Properties::new();\nprops.insert(\"title\".into(), Value::String(\"New Paper\".into()));\nprops.insert(\"year\".into(), Value::Int32(2024));\n\n// Insert\nwriter.insert_vertex(vid, props).await?;\n</code></pre>"},{"location":"guides/data-ingestion/#insert-edges","title":"Insert Edges","text":"<pre><code>use uni::core::{Eid, Direction};\n\n// Get VIDs (from query or allocation)\nlet src_vid: Vid = /* ... */;\nlet dst_vid: Vid = /* ... */;\n\n// Allocate EID\nlet edge_type_id = schema_manager.get_edge_type_id(\"CITES\")?;\nlet eid = writer.allocate_eid(edge_type_id)?;\n\n// Build properties\nlet mut props = Properties::new();\nprops.insert(\"weight\".into(), Value::Float64(0.95));\n\n// Insert\nwriter.insert_edge(src_vid, dst_vid, eid, edge_type_id, props).await?;\n</code></pre>"},{"location":"guides/data-ingestion/#batch-inserts","title":"Batch Inserts","text":"<pre><code>// Batch vertex insert\nlet vertices: Vec&lt;(Vid, Properties)&gt; = papers\n    .iter()\n    .map(|p| {\n        let vid = writer.allocate_vid(label_id)?;\n        let props = build_properties(p);\n        Ok((vid, props))\n    })\n    .collect::&lt;Result&lt;Vec&lt;_&gt;&gt;&gt;()?;\n\nwriter.insert_vertices_batch(vertices).await?;\n\n// Batch edge insert\nlet edges: Vec&lt;(Vid, Vid, Eid, u16, Properties)&gt; = /* ... */;\nwriter.insert_edges_batch(edges).await?;\n</code></pre>"},{"location":"guides/data-ingestion/#flush-to-storage","title":"Flush to Storage","text":"<pre><code>// Manual flush\nwriter.flush_to_l1().await?;\n\n// Auto-flush on threshold\nlet config = WriteConfig {\n    max_mutations_before_flush: 10000,\n    auto_flush: true,\n    ..Default::default()\n};\n</code></pre>"},{"location":"guides/data-ingestion/#data-transformation","title":"Data Transformation","text":""},{"location":"guides/data-ingestion/#converting-csv-to-jsonl","title":"Converting CSV to JSONL","text":"<pre><code>import csv\nimport json\n\n# Convert CSV to JSONL\nwith open('papers.csv', 'r') as csv_file, open('papers.jsonl', 'w') as jsonl_file:\n    reader = csv.DictReader(csv_file)\n    for row in reader:\n        # Transform as needed\n        record = {\n            'id': row['paper_id'],\n            'title': row['title'],\n            'year': int(row['year']),\n            'venue': row['venue']\n        }\n        jsonl_file.write(json.dumps(record) + '\\n')\n</code></pre>"},{"location":"guides/data-ingestion/#adding-embeddings","title":"Adding Embeddings","text":"<pre><code>import json\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\nwith open('papers_raw.jsonl', 'r') as infile, open('papers.jsonl', 'w') as outfile:\n    for line in infile:\n        record = json.loads(line)\n        # Generate embedding from title + abstract\n        text = record['title'] + ' ' + record.get('abstract', '')\n        embedding = model.encode(text).tolist()\n        record['embedding'] = embedding\n        outfile.write(json.dumps(record) + '\\n')\n</code></pre>"},{"location":"guides/data-ingestion/#extracting-from-database","title":"Extracting from Database","text":"<pre><code>import psycopg2\nimport json\n\nconn = psycopg2.connect(\"postgresql://...\")\ncursor = conn.cursor()\n\n# Export vertices\ncursor.execute(\"SELECT id, title, year FROM papers\")\nwith open('papers.jsonl', 'w') as f:\n    for row in cursor:\n        record = {'id': str(row[0]), 'title': row[1], 'year': row[2]}\n        f.write(json.dumps(record) + '\\n')\n\n# Export edges\ncursor.execute(\"SELECT citing_id, cited_id FROM citations\")\nwith open('citations.jsonl', 'w') as f:\n    for row in cursor:\n        record = {'src': str(row[0]), 'dst': str(row[1])}\n        f.write(json.dumps(record) + '\\n')\n</code></pre>"},{"location":"guides/data-ingestion/#incremental-updates","title":"Incremental Updates","text":""},{"location":"guides/data-ingestion/#append-only-pattern","title":"Append-Only Pattern","text":"<pre><code># Initial load\nuni import initial --papers papers_v1.jsonl --citations edges_v1.jsonl --output ./storage\n\n# Incremental update (append new data)\nuni import incremental --papers papers_new.jsonl --citations edges_new.jsonl \\\n    --output ./storage --mode append\n</code></pre>"},{"location":"guides/data-ingestion/#delta-processing","title":"Delta Processing","text":"<pre><code>// Add new vertices\nUNWIND $new_papers AS paper\nMERGE (p:Paper {id: paper.id})\nSET p.title = paper.title, p.year = paper.year\n\n// Add new edges\nUNWIND $new_edges AS edge\nMATCH (src:Paper {id: edge.src}), (dst:Paper {id: edge.dst})\nMERGE (src)-[:CITES]-&gt;(dst)\n</code></pre>"},{"location":"guides/data-ingestion/#validation-error-handling","title":"Validation &amp; Error Handling","text":""},{"location":"guides/data-ingestion/#schema-validation","title":"Schema Validation","text":"<pre><code># Validate data against schema\nuni validate --data papers.jsonl --schema schema.json\n\n# Output:\n# Validated 10,000 records\n# Errors: 0\n# Warnings: 12 (nullable fields missing)\n</code></pre>"},{"location":"guides/data-ingestion/#common-errors","title":"Common Errors","text":"Error Cause Solution <code>Property type mismatch</code> Wrong data type Check schema types <code>Unknown property</code> Property not in schema Add to schema or filter <code>Vector dimension mismatch</code> Wrong embedding size Ensure consistent dimensions <code>Duplicate ID</code> Non-unique ext_id Deduplicate source data <code>Missing required property</code> Null in non-nullable Fix source data"},{"location":"guides/data-ingestion/#error-recovery","title":"Error Recovery","text":"<pre><code># Continue on errors (log failures)\nuni import data --papers papers.jsonl --citations edges.jsonl \\\n    --output ./storage \\\n    --on-error continue \\\n    --error-log errors.jsonl\n</code></pre>"},{"location":"guides/data-ingestion/#performance-tips","title":"Performance Tips","text":""},{"location":"guides/data-ingestion/#large-file-handling","title":"Large File Handling","text":"<pre><code># Use streaming (default)\nuni import large --papers huge_file.jsonl ...\n\n# Split large files\nsplit -l 1000000 huge_file.jsonl chunk_\n# Import chunks sequentially or in parallel\n</code></pre>"},{"location":"guides/data-ingestion/#memory-management","title":"Memory Management","text":"<pre><code># Tune batch size based on memory\nuni import data --batch-size 5000 ...  # Lower for less memory\n\n# Monitor memory\nRUST_LOG=uni=debug uni import ... 2&gt;&amp;1 | grep memory\n</code></pre>"},{"location":"guides/data-ingestion/#parallel-import","title":"Parallel Import","text":"<pre><code># If data can be partitioned\nuni import shard1 --papers shard1.jsonl ... --output ./storage/shard1 &amp;\nuni import shard2 --papers shard2.jsonl ... --output ./storage/shard2 &amp;\nwait\n</code></pre>"},{"location":"guides/data-ingestion/#next-steps","title":"Next Steps","text":"<ul> <li>Schema Design \u2014 Best practices for schema definition</li> <li>Vector Search \u2014 Working with embeddings</li> <li>Performance Tuning \u2014 Optimization strategies</li> </ul>"},{"location":"guides/performance-tuning/","title":"Performance Tuning Guide","text":"<p>This guide covers strategies for optimizing Uni's performance across query execution, storage, indexing, and resource utilization.</p>"},{"location":"guides/performance-tuning/#performance-overview","title":"Performance Overview","text":"<p>Uni's performance characteristics:</p> Operation Typical Latency Optimization Target Point lookup 2-5ms Index usage 1-hop traversal 4-8ms Adjacency cache Vector KNN (k=10) 1-3ms Index tuning Aggregation (1M rows) 50-200ms Predicate pushdown Bulk insert (10K) 5-10ms Batch size"},{"location":"guides/performance-tuning/#query-optimization","title":"Query Optimization","text":""},{"location":"guides/performance-tuning/#1-use-predicate-pushdown","title":"1. Use Predicate Pushdown","text":"<p>Push filters to storage for massive I/O reduction:</p> <pre><code>// Good: Filter pushed to Lance\nMATCH (p:Paper)\nWHERE p.year &gt; 2020 AND p.venue = 'NeurIPS'\nRETURN p.title\n\n// Bad: Filter applied after full scan\nMATCH (p:Paper)\nWHERE p.title CONTAINS 'Transformer'  // Cannot push CONTAINS\nRETURN p.title\n</code></pre> <p>Pushable Predicates: - <code>=</code>, <code>&lt;&gt;</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code> - <code>IN [list]</code> - <code>IS NULL</code>, <code>IS NOT NULL</code> - <code>AND</code> combinations of above</p> <p>Non-Pushable Predicates: - <code>CONTAINS</code>, <code>STARTS WITH</code>, <code>ENDS WITH</code> - Function calls: <code>lower(x) = 'value'</code> - <code>OR</code> with different properties</p>"},{"location":"guides/performance-tuning/#2-limit-early","title":"2. Limit Early","text":"<p>Apply LIMIT as early as possible:</p> <pre><code>// Good: Limit applied early in pipeline\nMATCH (p:Paper)\nWHERE p.year &gt; 2020\nRETURN p.title\nORDER BY p.year DESC\nLIMIT 10\n\n// Bad: Process all then limit\nMATCH (p:Paper)-[:CITES]-&gt;(cited)\nWITH p, COUNT(cited) AS citation_count\nORDER BY citation_count DESC\nRETURN p.title, citation_count\nLIMIT 10  // All citations computed before limit\n</code></pre>"},{"location":"guides/performance-tuning/#3-project-only-needed-properties","title":"3. Project Only Needed Properties","text":"<p>Don't fetch unnecessary properties:</p> <pre><code>// Good: Only fetch needed properties\nMATCH (p:Paper)\nRETURN p.title, p.year\n\n// Bad: Fetch all properties\nMATCH (p:Paper)\nRETURN p  // Loads all properties including large ones\n\n// Worse: Return unused properties\nMATCH (p:Paper)\nRETURN p.title, p.abstract, p.embedding  // embedding loaded but unused\n</code></pre>"},{"location":"guides/performance-tuning/#4-use-indexes","title":"4. Use Indexes","text":"<p>Ensure indexes exist for filter properties:</p> <pre><code>-- Check if index is used\nEXPLAIN MATCH (p:Paper) WHERE p.year = 2023 RETURN p.title\n\n-- Create index if missing\nCREATE INDEX paper_year FOR (p:Paper) ON (p.year)\n</code></pre>"},{"location":"guides/performance-tuning/#5-optimize-traversal-patterns","title":"5. Optimize Traversal Patterns","text":"<p>Structure patterns for efficient execution:</p> <pre><code>// Good: Filter before traverse\nMATCH (p:Paper)\nWHERE p.year &gt; 2020\nMATCH (p)-[:CITES]-&gt;(cited)\nRETURN p.title, cited.title\n\n// Good: Traverse from smaller set\nMATCH (seed:Paper {title: 'Attention Is All You Need'})\nMATCH (seed)-[:CITES]-&gt;(cited)\nRETURN cited.title\n\n// Bad: Full cross-product\nMATCH (p1:Paper), (p2:Paper)\nWHERE p1.title = p2.title  // Cartesian join\nRETURN p1, p2\n</code></pre>"},{"location":"guides/performance-tuning/#index-tuning","title":"Index Tuning","text":""},{"location":"guides/performance-tuning/#vector-index-configuration","title":"Vector Index Configuration","text":""},{"location":"guides/performance-tuning/#hnsw-tuning","title":"HNSW Tuning","text":"Parameter Default Low Latency High Recall <code>m</code> 16 16 48 <code>ef_construction</code> 200 100 500 <code>ef_search</code> 100 50 200 <pre><code>// High recall configuration\nCREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper) ON p.embedding\nOPTIONS {\n  index_type: \"hnsw\",\n  metric: \"cosine\",\n  m: 48,\n  ef_construction: 400\n}\n</code></pre>"},{"location":"guides/performance-tuning/#ivf_pq-tuning","title":"IVF_PQ Tuning","text":"Parameter Default Memory Optimized Recall Optimized <code>num_partitions</code> 256 512 256 <code>num_sub_vectors</code> 8 8 48 <code>num_probes</code> 20 10 50"},{"location":"guides/performance-tuning/#scalar-index-selection","title":"Scalar Index Selection","text":"Query Pattern Index Type Notes Equality (<code>= value</code>) Hash O(1) lookup Range (<code>&gt; value</code>) BTree Range scan Low cardinality Bitmap Efficient for categories High cardinality unique Hash Best for IDs <pre><code>-- Hash for exact match (faster)\nCREATE INDEX paper_doi FOR (p:Paper) ON (p.doi) OPTIONS { type: \"hash\" }\n\n-- BTree for range queries\nCREATE INDEX paper_year FOR (p:Paper) ON (p.year) OPTIONS { type: \"btree\" }\n\n-- Bitmap for categories\nCREATE INDEX paper_venue FOR (p:Paper) ON (p.venue) OPTIONS { type: \"bitmap\" }\n</code></pre>"},{"location":"guides/performance-tuning/#composite-indexes","title":"Composite Indexes","text":"<p>Create composite indexes for common filter combinations:</p> <pre><code>-- Composite index for common query pattern\nCREATE INDEX paper_venue_year FOR (p:Paper) ON (p.venue, p.year)\n\n-- Query uses the composite index\nMATCH (p:Paper)\nWHERE p.venue = 'NeurIPS' AND p.year &gt; 2020\nRETURN p.title\n</code></pre>"},{"location":"guides/performance-tuning/#storage-optimization","title":"Storage Optimization","text":""},{"location":"guides/performance-tuning/#batch-size-tuning","title":"Batch Size Tuning","text":"<p>Tune batch sizes for your workload:</p> <pre><code># Import with larger batches (more memory, faster)\nuni import data --batch-size 50000 ...\n\n# Import with smaller batches (less memory)\nuni import data --batch-size 5000 ...\n</code></pre> <p>Guidelines: - Increase batch size if memory allows (faster) - Decrease if OOM errors occur - Default (10000) is good for most cases</p>"},{"location":"guides/performance-tuning/#l0-buffer-configuration","title":"L0 Buffer Configuration","text":"<p>Tune the in-memory write buffer:</p> <pre><code>let config = WriteConfig {\n    max_mutations_before_flush: 10000,  // Flush threshold\n    max_l0_size_bytes: 128 * 1024 * 1024,  // 128 MB max\n    auto_flush: true,\n};\n</code></pre> <p>Trade-offs: - Larger L0: Better write throughput, higher memory, longer recovery - Smaller L0: Lower memory, more frequent flushes, faster recovery</p>"},{"location":"guides/performance-tuning/#compaction","title":"Compaction","text":"<p>Trigger compaction after bulk operations:</p> <pre><code># Manual compaction\nuni compact --path ./storage\n\n# Compaction levels\nuni compact --path ./storage --level l1  # L0 \u2192 L1 only\nuni compact --path ./storage --level l2  # Full compaction\n</code></pre>"},{"location":"guides/performance-tuning/#cache-configuration","title":"Cache Configuration","text":""},{"location":"guides/performance-tuning/#adjacency-cache","title":"Adjacency Cache","text":"<p>The CSR adjacency cache is critical for traversal performance:</p> <pre><code>let storage = StorageManager::with_config(\n    path,\n    schema_manager,\n    StorageConfig {\n        adjacency_cache_size: 1_000_000,  // Max cached vertices\n        adjacency_cache_ttl: Duration::from_secs(3600),\n    }\n);\n</code></pre> <p>Sizing Guidelines: - Size for your \"hot\" working set - Monitor cache hit ratio - Increase if traversals are slow after warmup</p>"},{"location":"guides/performance-tuning/#property-cache","title":"Property Cache","text":"<p>Configure the property LRU cache:</p> <pre><code>let prop_manager = PropertyManager::with_config(\n    storage,\n    schema_manager,\n    PropertyConfig {\n        cache_capacity: 100_000,  // Cached property entries\n        batch_load_size: 1000,    // Properties per batch load\n    }\n);\n</code></pre>"},{"location":"guides/performance-tuning/#query-analysis","title":"Query Analysis","text":""},{"location":"guides/performance-tuning/#explain","title":"EXPLAIN","text":"<p>View the query plan without execution:</p> <pre><code>uni query \"MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN p.title\" \\\n    --explain --path ./storage\n</code></pre> <p>Output: <pre><code>Query Plan:\n\u251c\u2500\u2500 Project [p.title]\n\u2502   \u2514\u2500\u2500 Scan [:Paper]\n\u2502         \u21b3 Index: paper_year (year &gt; 2020)\n\u2502         \u21b3 Pushdown: year &gt; 2020\n\nEstimated rows: 5,000\nIndex usage: BTree (paper_year)\n</code></pre></p>"},{"location":"guides/performance-tuning/#profile","title":"PROFILE","text":"<p>Execute with timing breakdown:</p> <pre><code>uni query \"MATCH (p:Paper)-[:CITES]-&gt;(c) RETURN COUNT(c)\" \\\n    --profile --path ./storage\n</code></pre> <p>Output: <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 COUNT(c)  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 45,231    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nExecution Profile:\n  Parse:      0.8ms\n  Plan:       1.2ms\n  Execute:    42.3ms\n    \u251c\u2500\u2500 Scan:       12.1ms (28.6%)  [10,000 rows]\n    \u251c\u2500\u2500 Traverse:   24.5ms (57.9%)  [45,231 edges]\n    \u2514\u2500\u2500 Aggregate:   5.7ms (13.5%)  [1 row]\n  Total:      44.3ms\n</code></pre></p>"},{"location":"guides/performance-tuning/#identifying-bottlenecks","title":"Identifying Bottlenecks","text":"Profile Pattern Likely Cause Solution High Scan time No index, large result set Add index, add filters High Traverse time Cold cache, many edges Warm cache, limit hops High Aggregate time Large group count Add LIMIT, pre-aggregate High memory Large intermediate results Stream results, limit"},{"location":"guides/performance-tuning/#parallel-execution","title":"Parallel Execution","text":""},{"location":"guides/performance-tuning/#morsel-driven-parallelism","title":"Morsel-Driven Parallelism","text":"<p>Uni uses morsel-driven parallelism for large queries:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         PARALLEL EXECUTION                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Source Data: [\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500]           \u2502\n\u2502                         \u2502                                                   \u2502\n\u2502                         \u25bc                                                   \u2502\n\u2502   Morsels:     [\u2500\u2500\u2500\u2500] [\u2500\u2500\u2500\u2500] [\u2500\u2500\u2500\u2500] [\u2500\u2500\u2500\u2500] [\u2500\u2500\u2500\u2500] [\u2500\u2500\u2500\u2500]                   \u2502\n\u2502                  \u2502       \u2502       \u2502       \u2502       \u2502       \u2502                  \u2502\n\u2502                  \u25bc       \u25bc       \u25bc       \u25bc       \u25bc       \u25bc                  \u2502\n\u2502   Workers:     [W1]   [W2]   [W3]   [W4]   [W1]   [W2]                     \u2502\n\u2502                  \u2502       \u2502       \u2502       \u2502       \u2502       \u2502                  \u2502\n\u2502                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2502\n\u2502                                   \u2502                                         \u2502\n\u2502                                   \u25bc                                         \u2502\n\u2502   Merge:                     [Results]                                      \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/performance-tuning/#concurrency-configuration","title":"Concurrency Configuration","text":"<pre><code>let executor = Executor::with_config(\n    storage,\n    ExecutorConfig {\n        worker_threads: 8,       // Parallel workers\n        morsel_size: 4096,       // Rows per morsel\n        max_concurrent_io: 16,   // Parallel I/O operations\n    }\n);\n</code></pre> <p>Guidelines: - Set workers to CPU core count - Increase morsel size for simpler queries - Decrease morsel size for complex operators</p>"},{"location":"guides/performance-tuning/#memory-management","title":"Memory Management","text":""},{"location":"guides/performance-tuning/#memory-budget","title":"Memory Budget","text":"<p>Monitor and limit memory usage:</p> <pre><code># Monitor memory during query\nRUST_LOG=uni=debug uni query \"...\" 2&gt;&amp;1 | grep -i memory\n\n# Set memory limits\nexport UNI_MAX_MEMORY_MB=4096\n</code></pre>"},{"location":"guides/performance-tuning/#reducing-memory-usage","title":"Reducing Memory Usage","text":"<ol> <li>Smaller batch sizes: <code>--batch-size 5000</code></li> <li>Smaller caches: Reduce cache capacities</li> <li>Stream large results: Use SKIP/LIMIT pagination</li> <li>Avoid large intermediates: Filter early</li> </ol>"},{"location":"guides/performance-tuning/#memory-profile","title":"Memory Profile","text":"<pre><code>// Enable memory tracking\nlet storage = StorageManager::with_config(\n    path,\n    schema_manager,\n    StorageConfig {\n        enable_memory_tracking: true,\n        memory_limit_bytes: 4 * 1024 * 1024 * 1024,  // 4 GB\n    }\n);\n\n// Query memory stats\nlet stats = storage.memory_stats();\nprintln!(\"Adjacency cache: {} MB\", stats.adjacency_cache_mb);\nprintln!(\"Property cache: {} MB\", stats.property_cache_mb);\nprintln!(\"L0 buffer: {} MB\", stats.l0_buffer_mb);\n</code></pre>"},{"location":"guides/performance-tuning/#io-optimization","title":"I/O Optimization","text":""},{"location":"guides/performance-tuning/#object-store-configuration","title":"Object Store Configuration","text":"<p>For S3/GCS backends:</p> <pre><code>let storage = StorageManager::new_with_object_store(\n    \"s3://bucket/path\",\n    schema_manager,\n    ObjectStoreConfig {\n        max_connections: 32,\n        connect_timeout: Duration::from_secs(10),\n        read_timeout: Duration::from_secs(30),\n        retry_attempts: 3,\n    }\n);\n</code></pre>"},{"location":"guides/performance-tuning/#local-cache-for-remote-storage","title":"Local Cache for Remote Storage","text":"<pre><code>let storage = StorageManager::new_with_cache(\n    \"s3://bucket/path\",\n    schema_manager,\n    CacheConfig {\n        local_cache_path: \"/tmp/uni-cache\",\n        max_cache_size_bytes: 10 * 1024 * 1024 * 1024,  // 10 GB\n        eviction_policy: EvictionPolicy::LRU,\n    }\n);\n</code></pre>"},{"location":"guides/performance-tuning/#read-ahead","title":"Read-Ahead","text":"<p>Configure read-ahead for sequential scans:</p> <pre><code>let config = StorageConfig {\n    read_ahead_size: 64 * 1024 * 1024,  // 64 MB\n    prefetch_enabled: true,\n};\n</code></pre>"},{"location":"guides/performance-tuning/#benchmarking","title":"Benchmarking","text":""},{"location":"guides/performance-tuning/#built-in-benchmarks","title":"Built-in Benchmarks","text":"<pre><code># Run all benchmarks\ncargo bench\n\n# Run specific benchmark\ncargo bench -- vector_search\n\n# Save baseline\ncargo bench -- --save-baseline main\n\n# Compare to baseline\ncargo bench -- --baseline main\n</code></pre>"},{"location":"guides/performance-tuning/#custom-benchmarks","title":"Custom Benchmarks","text":"<pre><code>use criterion::{criterion_group, criterion_main, Criterion};\n\nfn benchmark_traversal(c: &amp;mut Criterion) {\n    let storage = setup_storage();\n\n    c.bench_function(\"1-hop traversal\", |b| {\n        b.iter(|| {\n            let query = \"MATCH (p:Paper)-[:CITES]-&gt;(c) RETURN COUNT(c)\";\n            executor.execute(query).unwrap()\n        })\n    });\n}\n\ncriterion_group!(benches, benchmark_traversal);\ncriterion_main!(benches);\n</code></pre>"},{"location":"guides/performance-tuning/#performance-checklist","title":"Performance Checklist","text":"<p>Before deploying to production:</p> <ul> <li> Indexes created for filter properties</li> <li> Vector indexes tuned for recall/latency trade-off</li> <li> Batch sizes tuned for workload</li> <li> Cache sizes appropriate for working set</li> <li> Queries use pushable predicates where possible</li> <li> LIMIT applied early in query patterns</li> <li> Only needed properties projected</li> <li> Memory limits configured</li> <li> I/O timeouts set for remote storage</li> <li> Monitoring enabled for cache hit rates</li> </ul>"},{"location":"guides/performance-tuning/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture \u2014 Understand system internals</li> <li>Vectorized Execution \u2014 Batch processing details</li> <li>Storage Engine \u2014 Storage layer optimization</li> <li>Benchmarks \u2014 Performance metrics</li> </ul>"},{"location":"guides/schema-design/","title":"Schema Design Guide","text":"<p>A well-designed schema is crucial for performance, maintainability, and query efficiency. This guide covers best practices for modeling your domain in Uni.</p>"},{"location":"guides/schema-design/#schema-design-principles","title":"Schema Design Principles","text":""},{"location":"guides/schema-design/#1-model-the-domain-not-the-queries","title":"1. Model the Domain, Not the Queries","text":"<p>Design your schema around your domain entities, not specific queries:</p> <pre><code>\u2713 Good: Entities represent real-world concepts\n  Paper, Author, Venue, Citation\n\n\u2717 Bad: Entities shaped by specific queries\n  PaperWithAuthorNames, RecentPapersByVenue\n</code></pre>"},{"location":"guides/schema-design/#2-use-labels-for-types-not-states","title":"2. Use Labels for Types, Not States","text":"<p>Labels define entity types, not transient states:</p> <pre><code>\u2713 Good: Labels are stable types\n  :Paper, :Author, :Venue\n\n\u2717 Bad: Labels represent changeable states\n  :PublishedPaper, :DraftPaper, :RetractedPaper\n  (Use a \"status\" property instead)\n</code></pre>"},{"location":"guides/schema-design/#3-relationships-are-first-class","title":"3. Relationships Are First-Class","text":"<p>Graph relationships are powerful\u2014use them:</p> <pre><code>\u2713 Good: Relationships as edges\n  (paper)-[:AUTHORED_BY]-&gt;(author)\n  (paper)-[:CITES]-&gt;(cited)\n\n\u2717 Bad: Relationships as properties\n  Paper { author_ids: [\"a1\", \"a2\"] }\n</code></pre>"},{"location":"guides/schema-design/#4-keep-vertices-focused","title":"4. Keep Vertices Focused","text":"<p>Each vertex should represent one cohesive entity:</p> <pre><code>\u2713 Good: Focused vertex\n  Paper { title, year, abstract }\n\n\u2717 Bad: Kitchen sink vertex\n  Paper { title, year, author_name, venue_name, citation_count }\n  (author_name, venue_name should be separate vertices)\n</code></pre>"},{"location":"guides/schema-design/#labels","title":"Labels","text":""},{"location":"guides/schema-design/#naming-conventions","title":"Naming Conventions","text":"Convention Example Rationale Singular nouns <code>:Paper</code> Represents one entity PascalCase <code>:ResearchPaper</code> Standard convention Descriptive <code>:AcademicPaper</code> Clear meaning Avoid abbreviations <code>:Organization</code> not <code>:Org</code> Readable"},{"location":"guides/schema-design/#label-granularity","title":"Label Granularity","text":"<p>Too Few Labels: <pre><code>// All entities in one label - hard to query efficiently\n:Entity { type: \"paper\", ... }\n:Entity { type: \"author\", ... }\n</code></pre></p> <p>Too Many Labels: <pre><code>// Fragmented - complex schema, poor caching\n:NeurIPSPaper, :ICMLPaper, :ICLRPaper, :ArXivPaper\n</code></pre></p> <p>Just Right: <pre><code>// Labels represent fundamental types\n:Paper { venue: \"NeurIPS\" }  // venue is a property\n:Author\n:Venue\n</code></pre></p>"},{"location":"guides/schema-design/#label-hierarchy-considerations","title":"Label Hierarchy Considerations","text":"<p>Uni uses single-label vertices (encoded in VID). If you need hierarchies:</p> <pre><code>// Option 1: Property-based classification\n:Paper { paper_type: \"research\", venue_type: \"conference\" }\n\n// Option 2: Separate labels with relationships\n:Paper, :ConferenceSubmission\n(paper)-[:SUBMITTED_TO]-&gt;(conference)\n\n// Option 3: Composition via edges\n:Paper, :Category\n(paper)-[:IN_CATEGORY]-&gt;(category)\n</code></pre>"},{"location":"guides/schema-design/#edge-types","title":"Edge Types","text":""},{"location":"guides/schema-design/#naming-conventions_1","title":"Naming Conventions","text":"Convention Example Rationale UPPER_SNAKE_CASE <code>:AUTHORED_BY</code> Visually distinct from labels Verb phrases <code>:CITES</code>, <code>:BELONGS_TO</code> Describes relationship Past tense or present <code>:WROTE</code> or <code>:WRITES</code> Consistent style Active voice <code>:CITES</code> not <code>:CITED_BY</code> Clear direction"},{"location":"guides/schema-design/#direction-semantics","title":"Direction Semantics","text":"<p>Choose direction based on typical query patterns:</p> <pre><code>// Natural reading direction: subject -[verb]-&gt; object\n(paper)-[:CITES]-&gt;(cited_paper)      // Paper cites another paper\n(paper)-[:AUTHORED_BY]-&gt;(author)     // Paper is authored by author\n(author)-[:WORKS_AT]-&gt;(institution)  // Author works at institution\n\n// Query from either direction\nMATCH (a:Author)&lt;-[:AUTHORED_BY]-(p:Paper)  // Find author's papers\nMATCH (p:Paper)-[:AUTHORED_BY]-&gt;(a:Author)  // Find paper's authors\n</code></pre>"},{"location":"guides/schema-design/#edge-properties","title":"Edge Properties","text":"<p>Use edge properties sparingly for relationship metadata:</p> <pre><code>{\n  \"edge_types\": {\n    \"AUTHORED_BY\": {\n      \"id\": 1,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Author\"]\n    }\n  },\n  \"properties\": {\n    \"AUTHORED_BY\": {\n      \"position\": { \"type\": \"Int32\" },      // Author order\n      \"contribution\": { \"type\": \"String\" }   // Role: \"lead\", \"contributor\"\n    }\n  }\n}\n</code></pre> <p>When to Use Edge Properties: - Relationship metadata (timestamps, weights, roles) - Data specific to the relationship, not the connected vertices</p> <p>When to Avoid Edge Properties: - Frequently updated data (edges are immutable) - Large data (embeddings, documents)</p>"},{"location":"guides/schema-design/#property-design","title":"Property Design","text":""},{"location":"guides/schema-design/#data-type-selection","title":"Data Type Selection","text":"Data Type Use Case Example <code>String</code> Text, identifiers title, name, doi <code>Int32</code> Small integers year, count <code>Int64</code> Large integers timestamp_ms, big_count <code>Float64</code> Decimal values price, score <code>Bool</code> Flags is_published, is_retracted <code>Timestamp</code> Date/time created_at, published_at <code>Vector</code> Embeddings embedding, image_vector <code>Json</code> Semi-structured metadata, config"},{"location":"guides/schema-design/#nullability","title":"Nullability","text":"<p>Be intentional about nullable properties:</p> <pre><code>{\n  \"Paper\": {\n    // Required: every paper has these\n    \"title\": { \"type\": \"String\", \"nullable\": false },\n\n    // Optional: not all papers have these\n    \"abstract\": { \"type\": \"String\", \"nullable\": true },\n    \"doi\": { \"type\": \"String\", \"nullable\": true }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#property-naming","title":"Property Naming","text":"Convention Example Notes snake_case <code>created_at</code> Consistent with JSON Descriptive <code>citation_count</code> not <code>cc</code> Self-documenting No prefixes <code>title</code> not <code>paper_title</code> Label provides context"},{"location":"guides/schema-design/#avoid-property-bloat","title":"Avoid Property Bloat","text":"<pre><code>\u2713 Good: Focused properties\n  Paper { title, year, venue, abstract, doi }\n\n\u2717 Bad: Everything on one vertex\n  Paper {\n    title, year, venue, abstract, doi,\n    author_names,        // Should be vertex + edge\n    all_citations,       // Should be edges\n    raw_pdf_bytes,       // Too large\n    processing_status    // Transient state\n  }\n</code></pre>"},{"location":"guides/schema-design/#vector-properties","title":"Vector Properties","text":""},{"location":"guides/schema-design/#dimension-planning","title":"Dimension Planning","text":"<p>Vector dimensions are immutable after schema creation:</p> <pre><code>{\n  \"embedding\": {\n    \"type\": \"Vector\",\n    \"dimensions\": 768  // Cannot change later\n  }\n}\n</code></pre> <p>Choosing Dimensions:</p> Model Family Typical Dimensions Notes Sentence Transformers 384-768 General text OpenAI embeddings 1536-3072 Commercial CLIP 512-768 Multimodal Custom Varies Match your model"},{"location":"guides/schema-design/#multiple-embeddings","title":"Multiple Embeddings","text":"<p>For different embedding types, use separate properties:</p> <pre><code>{\n  \"Paper\": {\n    \"title_embedding\": { \"type\": \"Vector\", \"dimensions\": 384 },\n    \"abstract_embedding\": { \"type\": \"Vector\", \"dimensions\": 768 },\n    \"figure_embedding\": { \"type\": \"Vector\", \"dimensions\": 512 }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#embedding-versioning","title":"Embedding Versioning","text":"<p>When upgrading embedding models:</p> <pre><code>{\n  \"Paper\": {\n    // Current\n    \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 },\n\n    // Legacy (deprecated)\n    \"embedding_v1\": { \"type\": \"Vector\", \"dimensions\": 384 }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#document-mode","title":"Document Mode","text":""},{"location":"guides/schema-design/#when-to-use-document-mode","title":"When to Use Document Mode","text":"<p>Enable <code>is_document: true</code> for entities with: - Highly variable/nested structure - Frequently changing schema - Semi-structured metadata</p> <pre><code>{\n  \"labels\": {\n    \"Paper\": {\n      \"id\": 1,\n      \"is_document\": true\n    }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#document-properties","title":"Document Properties","text":"<pre><code>CREATE (p:Paper {\n  title: \"Research Paper\",\n  year: 2024,\n  // Document field for flexible data\n  _doc: {\n    figures: [\n      { id: \"fig1\", caption: \"Architecture\" },\n      { id: \"fig2\", caption: \"Results\" }\n    ],\n    supplementary: {\n      code_url: \"https://github.com/...\",\n      datasets: [\"imagenet\", \"coco\"]\n    },\n    review_scores: [8, 7, 9]\n  }\n})\n</code></pre>"},{"location":"guides/schema-design/#json-vs-typed-properties","title":"JSON vs Typed Properties","text":"Use Typed Properties Use JSON Frequently queried Rarely queried Stable schema Evolving schema Needs indexing No indexing needed Performance critical Flexibility critical"},{"location":"guides/schema-design/#index-planning","title":"Index Planning","text":""},{"location":"guides/schema-design/#index-strategy","title":"Index Strategy","text":"<p>Plan indexes based on query patterns:</p> <pre><code>{\n  \"indexes\": {\n    // Vector index for similarity search\n    \"paper_embeddings\": {\n      \"type\": \"vector\",\n      \"label\": \"Paper\",\n      \"property\": \"embedding\",\n      \"config\": { \"index_type\": \"hnsw\", \"metric\": \"cosine\" }\n    },\n\n    // Scalar index for frequent filters\n    \"paper_year\": {\n      \"type\": \"scalar\",\n      \"label\": \"Paper\",\n      \"property\": \"year\",\n      \"config\": { \"index_type\": \"btree\" }\n    },\n\n    // Scalar index for unique lookups\n    \"paper_doi\": {\n      \"type\": \"scalar\",\n      \"label\": \"Paper\",\n      \"property\": \"doi\",\n      \"config\": { \"index_type\": \"hash\" }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#index-selection-guidelines","title":"Index Selection Guidelines","text":"Query Pattern Index Type Example <code>WHERE x = 5</code> BTree or Hash Year, ID <code>WHERE x &gt; 5</code> BTree Year ranges <code>WHERE x IN [...]</code> BTree or Bitmap Categories Vector similarity HNSW or IVF_PQ Embeddings Text search Full-text Title, abstract"},{"location":"guides/schema-design/#schema-evolution","title":"Schema Evolution","text":""},{"location":"guides/schema-design/#adding-properties","title":"Adding Properties","text":"<p>Safe operation\u2014existing data gets NULL:</p> <pre><code>// Before\n{ \"Paper\": { \"title\": \"String\" } }\n\n// After (add new property)\n{ \"Paper\": {\n    \"title\": \"String\",\n    \"citation_count\": { \"type\": \"Int32\", \"nullable\": true }  // New\n}}\n</code></pre>"},{"location":"guides/schema-design/#deprecating-properties","title":"Deprecating Properties","text":"<p>Use state markers for gradual removal:</p> <pre><code>{\n  \"Paper\": {\n    \"old_field\": {\n      \"type\": \"String\",\n      \"state\": \"deprecated\",\n      \"deprecated_since\": \"2024-01-01\",\n      \"migration_hint\": \"Use new_field instead\"\n    },\n    \"new_field\": { \"type\": \"String\" }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#adding-labelsedge-types","title":"Adding Labels/Edge Types","text":"<p>Safe operation\u2014new types get new ID ranges:</p> <pre><code>// Add new label\n{\n  \"labels\": {\n    \"Paper\": { \"id\": 1 },\n    \"Preprint\": { \"id\": 2 }  // New label\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#breaking-changes-avoid","title":"Breaking Changes (Avoid)","text":"<p>These require data migration: - Changing property types - Changing vector dimensions - Renaming labels (ID is fixed) - Changing edge type direction semantics</p>"},{"location":"guides/schema-design/#example-schemas","title":"Example Schemas","text":""},{"location":"guides/schema-design/#academic-papers","title":"Academic Papers","text":"<pre><code>{\n  \"schema_version\": 1,\n\n  \"labels\": {\n    \"Paper\": { \"id\": 1, \"is_document\": true },\n    \"Author\": { \"id\": 2 },\n    \"Venue\": { \"id\": 3 },\n    \"Institution\": { \"id\": 4 }\n  },\n\n  \"edge_types\": {\n    \"CITES\": { \"id\": 1, \"src_labels\": [\"Paper\"], \"dst_labels\": [\"Paper\"] },\n    \"AUTHORED_BY\": { \"id\": 2, \"src_labels\": [\"Paper\"], \"dst_labels\": [\"Author\"] },\n    \"PUBLISHED_IN\": { \"id\": 3, \"src_labels\": [\"Paper\"], \"dst_labels\": [\"Venue\"] },\n    \"AFFILIATED_WITH\": { \"id\": 4, \"src_labels\": [\"Author\"], \"dst_labels\": [\"Institution\"] }\n  },\n\n  \"properties\": {\n    \"Paper\": {\n      \"title\": { \"type\": \"String\", \"nullable\": false },\n      \"abstract\": { \"type\": \"String\", \"nullable\": true },\n      \"year\": { \"type\": \"Int32\", \"nullable\": false },\n      \"doi\": { \"type\": \"String\", \"nullable\": true },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 }\n    },\n    \"Author\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"email\": { \"type\": \"String\", \"nullable\": true },\n      \"orcid\": { \"type\": \"String\", \"nullable\": true }\n    },\n    \"Venue\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"type\": { \"type\": \"String\", \"nullable\": true }\n    },\n    \"AUTHORED_BY\": {\n      \"position\": { \"type\": \"Int32\", \"nullable\": true }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#e-commerce","title":"E-Commerce","text":"<pre><code>{\n  \"schema_version\": 1,\n\n  \"labels\": {\n    \"User\": { \"id\": 1 },\n    \"Product\": { \"id\": 2 },\n    \"Category\": { \"id\": 3 },\n    \"Order\": { \"id\": 4 }\n  },\n\n  \"edge_types\": {\n    \"PURCHASED\": { \"id\": 1, \"src_labels\": [\"User\"], \"dst_labels\": [\"Product\"] },\n    \"VIEWED\": { \"id\": 2, \"src_labels\": [\"User\"], \"dst_labels\": [\"Product\"] },\n    \"IN_CATEGORY\": { \"id\": 3, \"src_labels\": [\"Product\"], \"dst_labels\": [\"Category\"] },\n    \"ORDERED\": { \"id\": 4, \"src_labels\": [\"Order\"], \"dst_labels\": [\"Product\"] },\n    \"PLACED_BY\": { \"id\": 5, \"src_labels\": [\"Order\"], \"dst_labels\": [\"User\"] }\n  },\n\n  \"properties\": {\n    \"User\": {\n      \"email\": { \"type\": \"String\", \"nullable\": false },\n      \"name\": { \"type\": \"String\", \"nullable\": true },\n      \"preference_embedding\": { \"type\": \"Vector\", \"dimensions\": 128 }\n    },\n    \"Product\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"description\": { \"type\": \"String\", \"nullable\": true },\n      \"price\": { \"type\": \"Float64\", \"nullable\": false },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 384 }\n    },\n    \"PURCHASED\": {\n      \"quantity\": { \"type\": \"Int32\", \"nullable\": false },\n      \"timestamp\": { \"type\": \"Timestamp\", \"nullable\": false }\n    }\n  }\n}\n</code></pre>"},{"location":"guides/schema-design/#schema-validation-checklist","title":"Schema Validation Checklist","text":"<p>Before deploying your schema:</p> <ul> <li> All labels use singular PascalCase nouns</li> <li> All edge types use UPPER_SNAKE_CASE verbs</li> <li> All properties use snake_case</li> <li> Required properties are marked <code>nullable: false</code></li> <li> Vector dimensions match your embedding model</li> <li> Edge type constraints match your domain rules</li> <li> Indexes planned for common query patterns</li> <li> No circular dependencies or overly complex relationships</li> <li> Document mode used only where needed</li> <li> Schema version tracked for evolution</li> </ul>"},{"location":"guides/schema-design/#next-steps","title":"Next Steps","text":"<ul> <li>Data Ingestion \u2014 Import data with your schema</li> <li>Indexing \u2014 Configure indexes</li> <li>Cypher Querying \u2014 Query your schema</li> </ul>"},{"location":"guides/vector-search/","title":"Vector Search Guide","text":"<p>Uni treats vector search as a first-class citizen, deeply integrated with the graph traversal engine. This guide covers schema design, index configuration, query patterns, and performance optimization for semantic similarity search.</p>"},{"location":"guides/vector-search/#overview","title":"Overview","text":"<p>Vector search enables finding similar items based on high-dimensional embeddings:</p> <pre><code>Query: \"papers about attention mechanisms\"\n         \u2502\n         \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Embed Query      \u2502\n    \u2502  \u2192 [0.12, -0.34,  \u2502\n    \u2502     0.56, ...]    \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Vector Index     \u2502\n    \u2502  (HNSW / IVF_PQ)  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Top-K Results    \u2502\n    \u2502  - Attention...   \u2502\n    \u2502  - Transformer... \u2502\n    \u2502  - BERT...        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"guides/vector-search/#setting-up-vector-search","title":"Setting Up Vector Search","text":""},{"location":"guides/vector-search/#step-1-define-vector-schema","title":"Step 1: Define Vector Schema","text":"<p>Add a <code>Vector</code> type property to your schema:</p> <pre><code>{\n  \"properties\": {\n    \"Paper\": {\n      \"title\": { \"type\": \"String\", \"nullable\": false },\n      \"abstract\": { \"type\": \"String\", \"nullable\": true },\n      \"embedding\": {\n        \"type\": \"Vector\",\n        \"dimensions\": 768\n      }\n    },\n    \"Product\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"description_embedding\": {\n        \"type\": \"Vector\",\n        \"dimensions\": 384\n      },\n      \"image_embedding\": {\n        \"type\": \"Vector\",\n        \"dimensions\": 512\n      }\n    }\n  }\n}\n</code></pre> <p>Dimension Guidelines:</p> Model Dimensions Use Case all-MiniLM-L6-v2 384 General text, fast BGE-base-en-v1.5 768 High quality text OpenAI text-embedding-3-small 1536 Commercial, high quality CLIP ViT-B/32 512 Image + text"},{"location":"guides/vector-search/#step-2-create-vector-index","title":"Step 2: Create Vector Index","text":"<p>Create an index for efficient similarity search:</p> <p>HNSW (Recommended for most cases):</p> <pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper)\nON p.embedding\nOPTIONS {\n  index_type: \"hnsw\",\n  metric: \"cosine\",\n  m: 32,\n  ef_construction: 200\n}\n</code></pre> <p>IVF_PQ (For memory-constrained environments):</p> <pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper)\nON p.embedding\nOPTIONS {\n  index_type: \"ivf_pq\",\n  metric: \"cosine\",\n  num_partitions: 1024,\n  num_sub_vectors: 48\n}\n</code></pre>"},{"location":"guides/vector-search/#step-3-import-data-with-embeddings","title":"Step 3: Import Data with Embeddings","text":"<p>Your import data should include embedding vectors:</p> <pre><code>{\"id\": \"paper_001\", \"title\": \"Attention Is All You Need\", \"embedding\": [0.12, -0.34, 0.56, ...]}\n{\"id\": \"paper_002\", \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\", \"embedding\": [0.08, -0.21, 0.42, ...]}\n</code></pre>"},{"location":"guides/vector-search/#querying-vectors","title":"Querying Vectors","text":""},{"location":"guides/vector-search/#basic-knn-search","title":"Basic KNN Search","text":"<p>Find the K nearest neighbors to a query vector:</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node, distance\nRETURN node.title, distance\nORDER BY distance\n</code></pre> <p>Parameters: - <code>'Paper'</code>: Label to search - <code>'embedding'</code>: Vector property name - <code>$query_vector</code>: Query vector (list of floats) - <code>10</code>: Number of results (K)</p>"},{"location":"guides/vector-search/#with-distance-threshold","title":"With Distance Threshold","text":"<p>Filter results by distance:</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 100, 0.3)\nYIELD node, distance\nWHERE distance &lt; 0.2\nRETURN node.title, distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#hybrid-vector-property-filters","title":"Hybrid: Vector + Property Filters","text":"<p>Combine vector search with property filtering:</p> <pre><code>CALL db.idx.vector.query('Paper', 'embedding', $query_vector, 50)\nYIELD node AS paper, distance\nWHERE paper.year &gt;= 2020 AND paper.venue IN ['NeurIPS', 'ICML']\nRETURN paper.title, paper.year, distance\nORDER BY distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#hybrid-graph-vector-queries","title":"Hybrid Graph + Vector Queries","text":"<p>The real power comes from combining graph traversal with vector search.</p>"},{"location":"guides/vector-search/#pattern-1-vector-search-graph-expansion","title":"Pattern 1: Vector Search \u2192 Graph Expansion","text":"<p>Find similar papers, then explore their citations:</p> <pre><code>// Find papers similar to query\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 10)\nYIELD node AS seed, distance\n\n// Expand to citations\nMATCH (seed)-[:CITES]-&gt;(cited:Paper)\nRETURN seed.title AS source, cited.title AS cited_paper, distance\nORDER BY distance, cited.year DESC\n</code></pre>"},{"location":"guides/vector-search/#pattern-2-graph-context-vector-search","title":"Pattern 2: Graph Context \u2192 Vector Search","text":"<p>Start from a known node, find similar neighbors:</p> <pre><code>// Start from a specific paper\nMATCH (seed:Paper {title: 'Attention Is All You Need'})\n\n// Get its embedding\nWITH seed, seed.embedding AS seed_embedding\n\n// Find papers cited by seed that are similar to seed\nMATCH (seed)-[:CITES]-&gt;(cited:Paper)\nWHERE vector_similarity(seed_embedding, cited.embedding) &gt; 0.8\nRETURN cited.title, cited.year\n</code></pre>"},{"location":"guides/vector-search/#pattern-3-multi-hop-with-similarity-filter","title":"Pattern 3: Multi-Hop with Similarity Filter","text":"<p>Find papers in citation chain with semantic similarity:</p> <pre><code>MATCH (start:Paper {title: 'Attention Is All You Need'})\nMATCH (start)-[:CITES]-&gt;(hop1:Paper)-[:CITES]-&gt;(hop2:Paper)\nWHERE vector_similarity(start.embedding, hop2.embedding) &gt; 0.7\nRETURN DISTINCT hop2.title, hop2.year\nORDER BY hop2.year DESC\nLIMIT 20\n</code></pre>"},{"location":"guides/vector-search/#pattern-4-authors-similar-papers","title":"Pattern 4: Author's Similar Papers","text":"<p>Find an author's papers similar to a query:</p> <pre><code>// Vector search for similar papers\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 100)\nYIELD node AS paper, distance\n\n// Filter to specific author\nMATCH (paper)-[:AUTHORED_BY]-&gt;(a:Author {name: 'Geoffrey Hinton'})\nRETURN paper.title, paper.year, distance\nORDER BY distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#generating-embeddings","title":"Generating Embeddings","text":""},{"location":"guides/vector-search/#using-fastembed-built-in","title":"Using FastEmbed (Built-in)","text":"<p>Uni includes FastEmbed for local embedding generation:</p> <pre><code>use uni::embedding::{EmbeddingService, FastEmbedService, FastEmbedModel};\n\n// Create service\nlet service = FastEmbedService::new(FastEmbedModel::AllMiniLML6V2)?;\n\n// Embed text\nlet texts = vec![\"attention mechanisms in transformers\", \"graph neural networks\"];\nlet embeddings = service.embed(&amp;texts).await?;\n// embeddings: Vec&lt;Vec&lt;f32&gt;&gt; with 384 dimensions each\n</code></pre> <p>Available Models:</p> Model Dimensions Speed Quality <code>AllMiniLML6V2</code> 384 Fast Good <code>BGESmallENV15</code> 384 Fast Good <code>BGEBaseENV15</code> 768 Medium Better <code>NomicEmbedTextV15</code> 768 Medium Better <code>MultilingualE5Small</code> 384 Fast Multilingual"},{"location":"guides/vector-search/#using-external-apis","title":"Using External APIs","text":"<p>For production, you might use external embedding APIs:</p> <pre><code>import openai\nimport json\n\n# Generate embeddings\ndef embed_text(text):\n    response = openai.Embedding.create(\n        input=text,\n        model=\"text-embedding-3-small\"\n    )\n    return response['data'][0]['embedding']\n\n# Prepare JSONL with embeddings\npapers = [\n    {\"id\": \"p1\", \"title\": \"Paper 1\", \"embedding\": embed_text(\"Paper 1 abstract\")},\n    {\"id\": \"p2\", \"title\": \"Paper 2\", \"embedding\": embed_text(\"Paper 2 abstract\")},\n]\n\nwith open(\"papers.jsonl\", \"w\") as f:\n    for paper in papers:\n        f.write(json.dumps(paper) + \"\\n\")\n</code></pre>"},{"location":"guides/vector-search/#distance-metrics","title":"Distance Metrics","text":""},{"location":"guides/vector-search/#cosine-similarity","title":"Cosine Similarity","text":"<p>Best for normalized embeddings (most text models):</p> <pre><code>similarity = A \u00b7 B / (||A|| \u00d7 ||B||)\ndistance = 1 - similarity\n</code></pre> <ul> <li>Range: 0 (identical) to 2 (opposite)</li> <li>Use when: Magnitude doesn't matter, only direction</li> </ul>"},{"location":"guides/vector-search/#l2-euclidean-distance","title":"L2 (Euclidean) Distance","text":"<p>Best for embeddings where magnitude matters:</p> <pre><code>distance = \u221a\u03a3(a\u1d62 - b\u1d62)\u00b2\n</code></pre> <ul> <li>Range: 0 (identical) to \u221e</li> <li>Use when: Absolute position in space matters</li> </ul>"},{"location":"guides/vector-search/#dot-product","title":"Dot Product","text":"<p>Best for unnormalized embeddings:</p> <pre><code>similarity = A \u00b7 B\ndistance = -similarity (negated for ranking)\n</code></pre> <ul> <li>Range: -\u221e to +\u221e</li> <li>Use when: Embeddings have meaningful magnitudes</li> </ul>"},{"location":"guides/vector-search/#index-tuning","title":"Index Tuning","text":""},{"location":"guides/vector-search/#hnsw-parameters","title":"HNSW Parameters","text":"<pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper) ON p.embedding\nOPTIONS {\n  index_type: \"hnsw\",\n  metric: \"cosine\",\n\n  // Build-time parameters\n  m: 32,               // Connections per node (16-64)\n  ef_construction: 200, // Build-time search width (100-500)\n\n  // Query-time parameters (set at query)\n  // ef_search: 100     // Query-time search width (50-200)\n}\n</code></pre> <p>Tuning Guide:</p> Scenario m ef_construction ef_search Speed priority 16 100 50 Balanced 32 200 100 Recall priority 48 400 200 Maximum recall 64 500 300"},{"location":"guides/vector-search/#ivf_pq-parameters","title":"IVF_PQ Parameters","text":"<pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper) ON p.embedding\nOPTIONS {\n  index_type: \"ivf_pq\",\n  metric: \"cosine\",\n\n  num_partitions: 1024,  // \u221an is good start\n  num_sub_vectors: 48,   // Higher = better recall\n  num_probes: 50         // Query-time clusters to search\n}\n</code></pre> <p>Memory vs Recall Trade-off:</p> num_sub_vectors Memory per vector Recall 8 8 bytes Lower 16 16 bytes Medium 32 32 bytes Good 48 48 bytes Better 64 64 bytes Best"},{"location":"guides/vector-search/#performance-optimization","title":"Performance Optimization","text":""},{"location":"guides/vector-search/#pre-filtering-strategy","title":"Pre-filtering Strategy","text":"<p>For hybrid queries, filter order matters:</p> <pre><code>// Good: Vector search first, then filter\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 100)\nYIELD node AS paper, distance\nWHERE paper.year &gt;= 2020  // Filter after vector search\nRETURN paper.title, distance\nLIMIT 10\n\n// Alternative: Over-fetch then filter\nCALL db.idx.vector.query('Paper', 'embedding', $query_vector, 500)\nYIELD node AS paper, distance\nWHERE paper.year &gt;= 2020 AND paper.venue = 'NeurIPS'\nRETURN paper.title, distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#batch-queries","title":"Batch Queries","text":"<p>For multiple queries, batch them:</p> <pre><code>// Process multiple query vectors efficiently\nlet queries = vec![query1, query2, query3];\nlet results = storage.batch_vector_search(\n    \"Paper\",\n    \"embedding\",\n    &amp;queries,\n    10  // k per query\n).await?;\n</code></pre>"},{"location":"guides/vector-search/#caching-query-vectors","title":"Caching Query Vectors","text":"<p>Pre-compute and cache frequent query embeddings:</p> <pre><code>// Store computed query embedding\nCREATE (q:Query {\n  text: 'transformer architectures',\n  embedding: $precomputed_embedding,\n  created_at: datetime()\n})\n\n// Reuse later\nMATCH (q:Query {text: 'transformer architectures'})\nCALL db.idx.vector.query('Paper', 'embedding', q.embedding, 10)\nYIELD node, distance\nRETURN node.title, distance\n</code></pre>"},{"location":"guides/vector-search/#use-cases","title":"Use Cases","text":""},{"location":"guides/vector-search/#semantic-document-search","title":"Semantic Document Search","text":"<pre><code>// Find documents similar to a natural language query\nWITH $query_embedding AS query_vec\nCALL db.idx.vector.query('Document', 'content_embedding', query_vec, 20)\nYIELD node AS doc, distance\nRETURN doc.title, doc.summary, distance\nORDER BY distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#recommendation-system","title":"Recommendation System","text":"<pre><code>// Find products similar to what user viewed\nMATCH (u:User {id: $user_id})-[:VIEWED]-&gt;(viewed:Product)\nWITH COLLECT(viewed.embedding) AS viewed_embeddings\n\n// Average the embeddings (simplified)\nWITH reduce(sum = [0.0]*384, e IN viewed_embeddings |\n  [i IN range(0, 383) | sum[i] + e[i]]) AS summed,\n  size(viewed_embeddings) AS count\nWITH [x IN summed | x / count] AS avg_embedding\n\nCALL db.idx.vector.query('Product', 'embedding', avg_embedding, 20)\nYIELD node AS product, distance\nWHERE NOT EXISTS((u)-[:VIEWED]-&gt;(product))  // Exclude already viewed\nRETURN product.name, product.price, distance\nLIMIT 10\n</code></pre>"},{"location":"guides/vector-search/#duplicate-detection","title":"Duplicate Detection","text":"<pre><code>// Find near-duplicate documents\nMATCH (d:Document)\nCALL db.idx.vector.query('Document', 'embedding', d.embedding, 5)\nYIELD node AS similar, distance\nWHERE similar.id &lt;&gt; d.id AND distance &lt; 0.1  // Very similar\nRETURN d.title, similar.title, distance\n</code></pre>"},{"location":"guides/vector-search/#clustering-via-vector-search","title":"Clustering via Vector Search","text":"<pre><code>// Find clusters of similar papers\nMATCH (seed:Paper)\nWHERE seed.citations &gt; 100  // Start from influential papers\nCALL db.idx.vector.query('Paper', 'embedding', seed.embedding, 20)\nYIELD node AS similar, distance\nWHERE distance &lt; 0.3\nRETURN seed.title AS cluster_center, COLLECT(similar.title) AS cluster_members\n</code></pre>"},{"location":"guides/vector-search/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/vector-search/#low-recall","title":"Low Recall","text":"<p>Symptoms: Missing expected results</p> <p>Solutions: 1. Increase <code>ef_search</code> (HNSW) or <code>num_probes</code> (IVF) 2. Increase K and post-filter 3. Check embedding model consistency (same model for indexing and querying) 4. Verify dimension matches</p>"},{"location":"guides/vector-search/#slow-queries","title":"Slow Queries","text":"<p>Symptoms: High latency on vector search</p> <p>Solutions: 1. Reduce <code>ef_search</code> if recall is acceptable 2. Use IVF_PQ instead of HNSW for large datasets 3. Pre-filter with scalar indexes when possible 4. Ensure index is built (not building)</p>"},{"location":"guides/vector-search/#memory-issues","title":"Memory Issues","text":"<p>Symptoms: OOM during indexing or queries</p> <p>Solutions: 1. Switch to IVF_PQ (compressed vectors) 2. Reduce HNSW <code>m</code> parameter 3. Shard data across multiple indexes 4. Use streaming index build</p>"},{"location":"guides/vector-search/#next-steps","title":"Next Steps","text":"<ul> <li>Indexing \u2014 All index types and configuration</li> <li>Performance Tuning \u2014 Optimization strategies</li> <li>Data Ingestion \u2014 Import data with embeddings</li> </ul>"},{"location":"internals/","title":"Internals","text":"<p>Deep dive into Uni's implementation details.</p>   ### [Vectorized Execution](vectorized-execution.md) Batch processing, Arrow integration, and SIMD-accelerated operations.     ### [Storage Engine](storage-engine.md) Lance integration, LSM design, and the L0/L1/L2 layer architecture.     ### [Query Planning](query-planning.md) Planner internals, optimization passes, and physical plan generation.     ### [Benchmarks](benchmarks.md) Performance measurements, methodology, and comparison data."},{"location":"internals/#implementation-overview","title":"Implementation Overview","text":"<p>Uni's internals are organized into four major subsystems:</p>"},{"location":"internals/#query-processing","title":"Query Processing","text":"<ol> <li>Parser \u2014 Cypher syntax to AST (based on sqlparser)</li> <li>Planner \u2014 Logical plan with optimization passes</li> <li>Executor \u2014 Vectorized physical operators</li> </ol>"},{"location":"internals/#runtime","title":"Runtime","text":"<ol> <li>L0 Buffer \u2014 In-memory gryf graph for mutations</li> <li>CSR Cache \u2014 Compressed adjacency for O(1) traversal</li> <li>Property Manager \u2014 Lazy loading from Lance</li> </ol>"},{"location":"internals/#storage","title":"Storage","text":"<ol> <li>Lance Datasets \u2014 Columnar storage with versioning</li> <li>WAL \u2014 Write-ahead log for durability</li> <li>Indexes \u2014 Vector (HNSW/IVF_PQ), scalar, hash</li> </ol>"},{"location":"internals/#object-store","title":"Object Store","text":"<ol> <li>object_store crate for S3/GCS/Azure/local</li> <li>Local caching for frequently accessed data</li> <li>Manifest files for snapshot isolation</li> </ol>"},{"location":"internals/#key-design-decisions","title":"Key Design Decisions","text":"Decision Rationale Vectorized execution 100-500x faster than row-at-a-time Lance for storage Native vector indexes + versioning gryf for in-memory Fast graph algorithms in Rust Single-writer model Simplicity over distributed complexity"},{"location":"internals/#next-steps","title":"Next Steps","text":"<p>Start with Vectorized Execution to understand how queries are processed.</p>"},{"location":"internals/api-gap-plan/","title":"API Gap Implementation Plan","text":"<p>This document outlines the plan to expose internal Uni features that currently have no public access path (neither Rust API nor Cypher).</p>"},{"location":"internals/api-gap-plan/#gap-summary","title":"Gap Summary","text":"Gap Current State Priority Effort Background Compaction Manual only, not exposed P1 5-6 days S3/GCS Storage <code>std::fs</code> in metadata ops P1 7-10 days FTS Queries Index creation only P2 3-4 days Snapshot Management Internal only P3 2-3 days"},{"location":"internals/api-gap-plan/#1-background-compaction","title":"1. Background Compaction","text":""},{"location":"internals/api-gap-plan/#current-state","title":"Current State","text":"<ul> <li>L0 \u2192 L1 Flush: \u2705 Automatic (triggers at 10K mutations via <code>check_flush()</code>)</li> <li>L1 \u2192 L2 Compaction: \u274c Manual only, not exposed in public API</li> <li>L1 runs accumulate without automatic compaction</li> <li>No background thread for compaction</li> <li>No write throttling when L1 grows too large</li> </ul>"},{"location":"internals/api-gap-plan/#industry-comparison","title":"Industry Comparison","text":"Database Compaction Model RocksDB Background threads, automatic, write stalling LanceDB Cloud Automatic background compaction LanceDB OSS Manual via <code>table.optimize()</code> SQLite <code>auto_vacuum</code> pragma or manual <code>VACUUM</code> Uni (current) Manual only, not exposed"},{"location":"internals/api-gap-plan/#proposed-solution","title":"Proposed Solution","text":""},{"location":"internals/api-gap-plan/#phase-1-background-compaction-thread","title":"Phase 1: Background Compaction Thread","text":"<pre><code>pub struct CompactionConfig {\n    /// Enable background compaction (default: true)\n    pub enabled: bool,\n\n    /// Max L1 runs before triggering compaction (default: 4)\n    pub max_l1_runs: usize,\n\n    /// Max L1 size in bytes before compaction (default: 256MB)\n    pub max_l1_size_bytes: u64,\n\n    /// Max age of oldest L1 run before compaction (default: 1 hour)\n    pub max_l1_age: Duration,\n\n    /// Background check interval (default: 30s)\n    pub check_interval: Duration,\n\n    /// Number of compaction worker threads (default: 1)\n    pub worker_threads: usize,\n}\n\nimpl Default for CompactionConfig {\n    fn default() -&gt; Self {\n        Self {\n            enabled: true,\n            max_l1_runs: 4,\n            max_l1_size_bytes: 256 * 1024 * 1024,\n            max_l1_age: Duration::from_secs(3600),\n            check_interval: Duration::from_secs(30),\n            worker_threads: 1,\n        }\n    }\n}\n</code></pre>"},{"location":"internals/api-gap-plan/#phase-2-compaction-scheduler","title":"Phase 2: Compaction Scheduler","text":"<pre><code>impl Uni {\n    /// Starts background compaction worker (called internally on build)\n    fn start_background_compaction(&amp;self) {\n        if !self.config.compaction.enabled {\n            return;\n        }\n\n        let uni = self.clone();\n        tokio::spawn(async move {\n            let mut interval = tokio::time::interval(uni.config.compaction.check_interval);\n            loop {\n                interval.tick().await;\n\n                if let Some(task) = uni.pick_compaction_task() {\n                    if let Err(e) = uni.execute_compaction(task).await {\n                        log::error!(\"Compaction failed: {}\", e);\n                    }\n                }\n            }\n        });\n    }\n\n    fn pick_compaction_task(&amp;self) -&gt; Option&lt;CompactionTask&gt; {\n        let status = self.compaction_status();\n\n        // Check triggers in priority order\n        if status.l1_runs &gt;= self.config.compaction.max_l1_runs {\n            return Some(CompactionTask::ByRunCount);\n        }\n        if status.l1_size_bytes &gt;= self.config.compaction.max_l1_size_bytes {\n            return Some(CompactionTask::BySize);\n        }\n        if status.oldest_l1_age &gt;= self.config.compaction.max_l1_age {\n            return Some(CompactionTask::ByAge);\n        }\n        None\n    }\n}\n</code></pre>"},{"location":"internals/api-gap-plan/#phase-3-write-throttling-backpressure","title":"Phase 3: Write Throttling (Backpressure)","text":"<p>Like RocksDB, slow down writes when compaction can't keep up:</p> <pre><code>pub struct WriteThrottleConfig {\n    /// L1 run count to start throttling (default: 8)\n    pub soft_limit: usize,\n\n    /// L1 run count to stop writes entirely (default: 16)\n    pub hard_limit: usize,\n\n    /// Base delay when throttling (default: 10ms)\n    pub base_delay: Duration,\n}\n\nimpl Writer {\n    async fn check_write_pressure(&amp;self) -&gt; Result&lt;()&gt; {\n        let l1_runs = self.storage.l1_run_count();\n\n        if l1_runs &gt;= self.config.throttle.hard_limit {\n            // Block until compaction catches up\n            log::warn!(\"Write stalled: L1 runs ({}) at hard limit\", l1_runs);\n            self.wait_for_compaction().await?;\n        } else if l1_runs &gt;= self.config.throttle.soft_limit {\n            // Progressive delay\n            let delay = self.calculate_backpressure_delay(l1_runs);\n            log::debug!(\"Write throttled: {}ms delay\", delay.as_millis());\n            tokio::time::sleep(delay).await;\n        }\n        Ok(())\n    }\n\n    fn calculate_backpressure_delay(&amp;self, l1_runs: usize) -&gt; Duration {\n        let excess = l1_runs - self.config.throttle.soft_limit;\n        let multiplier = 2_u32.pow(excess as u32);\n        self.config.throttle.base_delay * multiplier\n    }\n}\n</code></pre>"},{"location":"internals/api-gap-plan/#phase-4-public-api","title":"Phase 4: Public API","text":"<pre><code>impl Uni {\n    /// Trigger manual compaction (all labels, all edge types)\n    pub async fn compact(&amp;self) -&gt; Result&lt;CompactionStats&gt;;\n\n    /// Compact specific label\n    pub async fn compact_label(&amp;self, label: &amp;str) -&gt; Result&lt;CompactionStats&gt;;\n\n    /// Compact specific edge type\n    pub async fn compact_edge_type(&amp;self, edge_type: &amp;str) -&gt; Result&lt;CompactionStats&gt;;\n\n    /// Get compaction status\n    pub fn compaction_status(&amp;self) -&gt; CompactionStatus;\n\n    /// Wait for all pending compactions to complete\n    pub async fn wait_for_compaction(&amp;self) -&gt; Result&lt;()&gt;;\n}\n\npub struct CompactionStats {\n    pub files_compacted: usize,\n    pub bytes_before: u64,\n    pub bytes_after: u64,\n    pub duration: Duration,\n    pub crdt_merges: usize,\n}\n\npub struct CompactionStatus {\n    pub l1_runs: usize,\n    pub l1_size_bytes: u64,\n    pub oldest_l1_age: Duration,\n    pub compaction_in_progress: bool,\n    pub compaction_pending: usize,\n    pub last_compaction: Option&lt;SystemTime&gt;,\n    pub total_compactions: u64,\n    pub total_bytes_compacted: u64,\n}\n</code></pre>"},{"location":"internals/api-gap-plan/#cypher-procedures","title":"Cypher Procedures","text":"<pre><code>-- Trigger compaction\nCALL db.compact()\nYIELD filesCompacted, bytesBefore, bytesAfter, durationMs, crdtMerges\n\n-- Check status\nCALL db.compactionStatus()\nYIELD l1Runs, l1SizeBytes, compactionInProgress, lastCompaction\n</code></pre>"},{"location":"internals/api-gap-plan/#tasks","title":"Tasks","text":"Task Effort <code>CompactionConfig</code> struct 0.5 day Background compaction thread 1 day Compaction task picker/scheduler 1 day Write throttling/backpressure 1 day Public API (<code>compact()</code>, <code>compaction_status()</code>) 0.5 day Cypher procedures 0.5 day Tests 1 day <p>Total: 5-6 days</p>"},{"location":"internals/api-gap-plan/#2-s3gcs-storage-backend","title":"2. S3/GCS Storage Backend","text":""},{"location":"internals/api-gap-plan/#current-state_1","title":"Current State","text":"<p>Lance datasets support S3/GCS/Azure natively, but Uni's metadata operations use <code>std::fs</code>:</p> Component Blocking Code Challenge <code>UniBuilder.build()</code> <code>std::fs::create_dir_all()</code> Directory creation <code>SchemaManager</code> <code>fs::read_to_string()</code>, <code>fs::write()</code> File I/O <code>SnapshotManager</code> <code>fs::create_dir_all()</code>, <code>fs::write()</code> File I/O <code>WriteAheadLog</code> <code>File::open()</code>, append Append-only semantics <code>IdAllocator</code> <code>fs::rename()</code> Atomic rename"},{"location":"internals/api-gap-plan/#object-store-challenges","title":"Object Store Challenges","text":"Challenge Local FS S3/GCS Latency &lt;1ms 50-200ms Atomic rename \u2705 <code>fs::rename()</code> \u274c Copy + Delete Cost Free Per-operation cost Append \u2705 Native \u274c Rewrite entire object Concurrent writes File locks Requires coordination"},{"location":"internals/api-gap-plan/#proposed-solution-phased-approach","title":"Proposed Solution: Phased Approach","text":""},{"location":"internals/api-gap-plan/#phase-1-local-only-with-background-compaction-5-6-days","title":"Phase 1: Local-Only with Background Compaction (5-6 days)","text":"<p>Focus on compaction first (see above). This provides immediate value for all deployments.</p>"},{"location":"internals/api-gap-plan/#phase-2-hybrid-architecture-5-7-days","title":"Phase 2: Hybrid Architecture (5-7 days)","text":"<p>Recommended for most cloud deployments.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LOCAL (fast, atomic)                                        \u2502\n\u2502  \u251c\u2500\u2500 WAL (append-only log, needs low latency)               \u2502\n\u2502  \u251c\u2500\u2500 IdAllocator (atomic counter, needs atomicity)          \u2502\n\u2502  \u2514\u2500\u2500 L0 Buffer (in-memory, already local)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  OBJECT STORE (S3/GCS/Azure)                                \u2502\n\u2502  \u251c\u2500\u2500 Lance Datasets (vertices, edges, adjacency)            \u2502\n\u2502  \u251c\u2500\u2500 Schema (versioned JSON, infrequent writes)             \u2502\n\u2502  \u2514\u2500\u2500 Snapshots (manifest files, infrequent writes)          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Implementation:</p> <pre><code>pub struct HybridStorageConfig {\n    /// Local path for WAL and ID allocation\n    pub local_path: PathBuf,\n\n    /// Object store URL for data (s3://bucket/prefix)\n    pub data_url: String,\n\n    /// Object store credentials\n    pub credentials: Option&lt;ObjectStoreCredentials&gt;,\n}\n\nimpl UniBuilder {\n    /// Configure hybrid storage (local WAL + S3 data)\n    pub fn hybrid(\n        self,\n        local_path: impl AsRef&lt;Path&gt;,\n        data_url: &amp;str,\n    ) -&gt; Self;\n}\n\n// Usage\nlet db = Uni::hybrid(\"./local-wal\", \"s3://my-bucket/graphs/prod\")\n    .credentials(ObjectStoreCredentials::from_env())\n    .build()\n    .await?;\n</code></pre> <p>Tasks:</p> Task Effort <code>HybridStorageConfig</code> 0.5 day Refactor <code>SchemaManager</code> to use object_store 1 day Refactor <code>SnapshotManager</code> to use object_store 1 day Keep WAL and IdAllocator local 0 days (no change) <code>UniBuilder::hybrid()</code> configuration 0.5 day Lance dataset URL passthrough 0.5 day Integration tests with LocalStack/MinIO 1.5 days <p>Total Phase 2: 5-7 days</p>"},{"location":"internals/api-gap-plan/#phase-3-full-object-store-optional-5-7-days","title":"Phase 3: Full Object Store (Optional, 5-7 days)","text":"<p>For serverless/ephemeral compute where local storage isn't available.</p> <pre><code>pub struct FullObjectStoreConfig {\n    /// Object store URL for everything\n    pub url: String,\n\n    /// Credentials\n    pub credentials: ObjectStoreCredentials,\n\n    /// ID allocation strategy\n    pub id_strategy: IdAllocationStrategy,\n\n    /// WAL strategy\n    pub wal_strategy: WalStrategy,\n}\n\npub enum IdAllocationStrategy {\n    /// Use conditional writes with ETag (optimistic locking)\n    ConditionalWrite { batch_size: u64 },\n\n    /// Use external coordination service (DynamoDB, etcd)\n    External { endpoint: String },\n}\n\npub enum WalStrategy {\n    /// Buffer locally, flush segments to object store\n    BufferedSegments { segment_size: usize },\n\n    /// Disable WAL (data loss risk on crash)\n    Disabled,\n}\n</code></pre> <p>IdAllocator on S3 (conditional writes):</p> <pre><code>impl ObjectStoreIdAllocator {\n    async fn allocate_batch(&amp;self) -&gt; Result&lt;Range&lt;u64&gt;&gt; {\n        loop {\n            // Read current counter\n            let (current, etag) = self.read_counter_with_etag().await?;\n            let new = current + self.batch_size;\n\n            // Conditional write (fails if etag changed)\n            match self.conditional_write(new, &amp;etag).await {\n                Ok(_) =&gt; return Ok(current..new),\n                Err(PreconditionFailed) =&gt; continue, // Retry\n            }\n        }\n    }\n}\n</code></pre> <p>WAL on S3 (segment files):</p> <pre><code>impl ObjectStoreWal {\n    async fn append(&amp;mut self, entry: WalEntry) -&gt; Result&lt;()&gt; {\n        self.local_buffer.push(entry);\n\n        if self.local_buffer.len() &gt;= self.segment_size {\n            // Flush segment to S3\n            let segment_name = format!(\"wal/segment_{:016x}.bin\", self.next_segment_id);\n            self.store.put(&amp;segment_name, self.serialize_buffer()).await?;\n            self.local_buffer.clear();\n            self.next_segment_id += 1;\n        }\n        Ok(())\n    }\n}\n</code></pre> <p>Tasks:</p> Task Effort <code>ObjectStoreIdAllocator</code> with conditional writes 1.5 days <code>ObjectStoreWal</code> with segment flushing 2 days Recovery logic for WAL segments 1 day <code>UniBuilder::object_store()</code> configuration 0.5 day Integration tests 1.5 days <p>Total Phase 3: 5-7 days</p>"},{"location":"internals/api-gap-plan/#recommended-approach","title":"Recommended Approach","text":"Deployment Recommended Config Effort Local development <code>Uni::open(\"./data\")</code> Already works Cloud (EC2/GKE/AKS) <code>Uni::hybrid(\"./wal\", \"s3://...\")</code> Phase 2 Serverless (Lambda) <code>Uni::object_store(\"s3://...\")</code> Phase 3 <p>Start with Phase 2 (Hybrid) - covers 90% of cloud use cases with less complexity.</p>"},{"location":"internals/api-gap-plan/#3-full-text-search-queries","title":"3. Full-Text Search Queries","text":""},{"location":"internals/api-gap-plan/#current-state_2","title":"Current State","text":"<ul> <li>FTS indexes can be created via DDL: <code>CREATE FULLTEXT INDEX ... FOR (n:Label) ON EACH [n.prop]</code></li> <li>Index stored using Lance's <code>InvertedIndex</code></li> <li>No query support: Parser lacks <code>CONTAINS</code>, <code>STARTS WITH</code>, <code>ENDS WITH</code></li> <li>No procedure: No <code>db.idx.fts.query()</code> exists</li> </ul>"},{"location":"internals/api-gap-plan/#proposed-solution_1","title":"Proposed Solution","text":""},{"location":"internals/api-gap-plan/#option-a-cypher-string-predicates-recommended","title":"Option A: Cypher String Predicates (Recommended)","text":"<p>Add string predicates to the Cypher parser and predicate pushdown:</p> <pre><code>-- Target syntax\nMATCH (p:Person)\nWHERE p.bio CONTAINS 'machine learning'\nRETURN p\n\nMATCH (p:Person)\nWHERE p.name STARTS WITH 'John'\nRETURN p\n\nMATCH (p:Person)\nWHERE p.email ENDS WITH '@example.com'\nRETURN p\n</code></pre> <p>Implementation:</p> <ol> <li> <p>Add to <code>Operator</code> enum in <code>ast.rs</code>:    <pre><code>pub enum Operator {\n    // ... existing\n    Contains,\n    StartsWith,\n    EndsWith,\n}\n</code></pre></p> </li> <li> <p>Add parser support in <code>parser.rs</code></p> </li> <li> <p>Add to predicate pushdown in <code>pushdown.rs</code>:    <pre><code>// Convert to Lance SQL\nOperator::Contains =&gt; format!(\"{} LIKE '%{}%'\", col, escape_like(value)),\nOperator::StartsWith =&gt; format!(\"{} LIKE '{}%'\", col, escape_like(value)),\nOperator::EndsWith =&gt; format!(\"{} LIKE '%{}'\", col, escape_like(value)),\n</code></pre></p> </li> <li> <p>Lance will automatically use inverted index if available</p> </li> </ol>"},{"location":"internals/api-gap-plan/#option-b-explicit-fts-procedure","title":"Option B: Explicit FTS Procedure","text":"<p>Add a procedure similar to vector search:</p> <pre><code>CALL db.idx.fts.query('Person', 'bio', 'machine learning', 10)\nYIELD node, score\nRETURN node.name, score\nORDER BY score DESC\n</code></pre>"},{"location":"internals/api-gap-plan/#recommendation","title":"Recommendation","text":"<p>Start with Option A (string predicates) - simpler, more intuitive, follows Cypher standard.</p>"},{"location":"internals/api-gap-plan/#tasks_1","title":"Tasks","text":"Task Effort Add <code>Contains</code>/<code>StartsWith</code>/<code>EndsWith</code> to Operator enum 0.5 day Parser support for string predicates 1 day Predicate pushdown to Lance 1 day Unit tests 0.5 day Integration tests with FTS index 1 day <p>Total: 3-4 days</p>"},{"location":"internals/api-gap-plan/#4-snapshot-management","title":"4. Snapshot Management","text":""},{"location":"internals/api-gap-plan/#current-state_3","title":"Current State","text":"<ul> <li><code>SnapshotManager</code> exists internally</li> <li>Creates snapshots automatically on flush</li> <li>Snapshots stored as JSON manifests</li> <li>No public API to create/restore/list snapshots</li> <li>Feature-gated behind <code>snapshot-internals</code></li> </ul>"},{"location":"internals/api-gap-plan/#proposed-solution_2","title":"Proposed Solution","text":""},{"location":"internals/api-gap-plan/#rust-api","title":"Rust API","text":"<pre><code>impl Uni {\n    /// Create a named snapshot\n    pub async fn create_snapshot(&amp;self, name: &amp;str) -&gt; Result&lt;SnapshotId&gt;;\n\n    /// List all snapshots\n    pub async fn list_snapshots(&amp;self) -&gt; Result&lt;Vec&lt;SnapshotInfo&gt;&gt;;\n\n    /// Get snapshot details\n    pub async fn get_snapshot(&amp;self, id: &amp;SnapshotId) -&gt; Result&lt;SnapshotInfo&gt;;\n\n    /// Restore to a snapshot (creates new database state)\n    pub async fn restore_snapshot(&amp;self, id: &amp;SnapshotId) -&gt; Result&lt;()&gt;;\n\n    /// Delete a snapshot\n    pub async fn delete_snapshot(&amp;self, id: &amp;SnapshotId) -&gt; Result&lt;()&gt;;\n\n    /// Open database at specific snapshot (read-only)\n    pub fn at_snapshot(&amp;self, id: &amp;SnapshotId) -&gt; Result&lt;UniSnapshot&gt;;\n}\n\npub struct SnapshotInfo {\n    pub id: SnapshotId,\n    pub name: Option&lt;String&gt;,\n    pub created_at: SystemTime,\n    pub vertex_count: u64,\n    pub edge_count: u64,\n    pub size_bytes: u64,\n}\n\n/// Read-only view at a snapshot\npub struct UniSnapshot {\n    // ...\n}\n\nimpl UniSnapshot {\n    pub async fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n    // No mutation methods\n}\n</code></pre>"},{"location":"internals/api-gap-plan/#cypher-procedures_1","title":"Cypher Procedures","text":"<pre><code>-- Create snapshot\nCALL db.snapshot.create('before-migration')\nYIELD snapshotId, createdAt\n\n-- List snapshots\nCALL db.snapshot.list()\nYIELD snapshotId, name, createdAt, vertexCount, edgeCount\n\n-- Restore snapshot\nCALL db.snapshot.restore($snapshotId)\n</code></pre>"},{"location":"internals/api-gap-plan/#tasks_2","title":"Tasks","text":"Task Effort Expose <code>create_snapshot()</code> 0.5 day Expose <code>list_snapshots()</code> / <code>get_snapshot()</code> 0.5 day Implement <code>restore_snapshot()</code> 0.5 day Implement <code>at_snapshot()</code> read-only view 0.5 day Cypher procedures 0.5 day Tests 0.5 day <p>Total: 2-3 days</p>"},{"location":"internals/api-gap-plan/#implementation-roadmap","title":"Implementation Roadmap","text":""},{"location":"internals/api-gap-plan/#phase-1-foundation-week-1-2","title":"Phase 1: Foundation (Week 1-2)","text":"Feature Priority Effort Rationale Background Compaction P1 5-6 days Required for production use Manual Compact API P1 (included above) Operational control"},{"location":"internals/api-gap-plan/#phase-2-cloud-support-week-3-4","title":"Phase 2: Cloud Support (Week 3-4)","text":"Feature Priority Effort Rationale Hybrid S3/GCS (Phase 2) P1 5-7 days Enables cloud deployment FTS Queries P2 3-4 days Completes FTS feature"},{"location":"internals/api-gap-plan/#phase-3-advanced-week-5","title":"Phase 3: Advanced (Week 5+)","text":"Feature Priority Effort Rationale Full S3 Support (Phase 3) P3 5-7 days Serverless only Snapshot Management P3 2-3 days Backup/restore"},{"location":"internals/api-gap-plan/#total-effort","title":"Total Effort","text":"Phase Features Effort Phase 1 Background Compaction 5-6 days Phase 2 Hybrid S3 + FTS 8-11 days Phase 3 Full S3 + Snapshots 7-10 days Total All features 20-27 days"},{"location":"internals/api-gap-plan/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                APPLICATION                                    \u2502\n\u2502                                                                              \u2502\n\u2502   let db = Uni::hybrid(\"./wal\", \"s3://bucket/data\").build().await?;         \u2502\n\u2502                                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                               UNI                                             \u2502\n\u2502                                  \u2502                                            \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        RUNTIME LAYER                                    \u2502  \u2502\n\u2502  \u2502                                                                         \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502 L0 Buffer   \u2502  \u2502   Writer    \u2502  \u2502 Compaction  \u2502  \u2502  Adjacency   \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502 (in-memory) \u2502  \u2502             \u2502  \u2502  Scheduler  \u2502  \u2502    Cache     \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                          \u2502                \u2502                             \u2502  \u2502\n\u2502  \u2502                          \u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                 \u2502  \u2502\n\u2502  \u2502                          \u2502    \u2502  Background Thread    \u2502                 \u2502  \u2502\n\u2502  \u2502                          \u2502    \u2502  - Check every 30s    \u2502                 \u2502  \u2502\n\u2502  \u2502                          \u2502    \u2502  - Pick compaction    \u2502                 \u2502  \u2502\n\u2502  \u2502                          \u2502    \u2502  - Write throttling   \u2502                 \u2502  \u2502\n\u2502  \u2502                          \u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                 \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                             \u2502                                                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502                        STORAGE LAYER                                     \u2502  \u2502\n\u2502  \u2502                                                                          \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502  \u2502\n\u2502  \u2502  \u2502     LOCAL (./wal)           \u2502  \u2502     OBJECT STORE (s3://...)     \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502                             \u2502  \u2502                                  \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u251c\u2500\u2500 WAL (append-only)      \u2502  \u2502  \u251c\u2500\u2500 vertices_*/  (Lance)       \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u251c\u2500\u2500 IdAllocator (atomic)   \u2502  \u2502  \u251c\u2500\u2500 edges_*/     (Lance)       \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502  \u2514\u2500\u2500 L0 state (optional)    \u2502  \u2502  \u251c\u2500\u2500 adjacency_*/ (Lance)       \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502                             \u2502  \u2502  \u251c\u2500\u2500 schema.json                \u2502   \u2502  \u2502\n\u2502  \u2502  \u2502                             \u2502  \u2502  \u2514\u2500\u2500 snapshots/                 \u2502   \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502  \u2502\n\u2502  \u2502                                                                          \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/api-gap-plan/#success-criteria","title":"Success Criteria","text":"<ol> <li>\u2705 Background compaction runs automatically based on configurable policies</li> <li>\u2705 Write throttling prevents L1 from growing unbounded</li> <li>\u2705 <code>db.compact()</code> triggers manual compaction</li> <li>\u2705 <code>db.compaction_status()</code> returns current state</li> <li>\u2705 <code>Uni::hybrid(\"./wal\", \"s3://...\")</code> works for cloud deployments</li> <li>\u2705 <code>WHERE p.bio CONTAINS 'term'</code> uses FTS index automatically</li> <li>\u2705 <code>db.create_snapshot()</code> / <code>db.restore_snapshot()</code> work</li> <li>\u2705 All new APIs have tests and documentation</li> </ol>"},{"location":"internals/api-gap-plan/#references","title":"References","text":"<ul> <li>RocksDB Compaction Wiki</li> <li>LanceDB Data Management</li> <li>Lance Format Documentation</li> </ul>"},{"location":"internals/benchmarks/","title":"Benchmarks","text":"<p>This document presents comprehensive performance measurements for Uni across various workloads including ingestion, querying, graph traversal, and vector search. All benchmarks are reproducible using the included benchmark suite.</p>"},{"location":"internals/benchmarks/#executive-summary","title":"Executive Summary","text":"Workload Performance Context Ingestion 1.8M vertices/sec Batched L0 writes Point Lookup 2.9ms Indexed property access 1-Hop Traversal 4.7ms CSR adjacency cache Vector KNN (k=10) 1.8ms HNSW index Hybrid Query 215ms Vector + Graph + Filter"},{"location":"internals/benchmarks/#test-environment","title":"Test Environment","text":""},{"location":"internals/benchmarks/#hardware-configuration","title":"Hardware Configuration","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         BENCHMARK HARDWARE                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Development Machine:                                                      \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 CPU:     AMD Ryzen 9 5900X (12 cores, 24 threads)                    \u2502 \u2502\n\u2502   \u2502 Memory:  64 GB DDR4-3600                                              \u2502 \u2502\n\u2502   \u2502 Storage: Samsung 980 PRO NVMe (7,000 MB/s read)                       \u2502 \u2502\n\u2502   \u2502 OS:      Ubuntu 22.04, kernel 5.15                                    \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2502   Cloud VM (Comparable):                                                    \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 Instance: AWS c6i.4xlarge (16 vCPU, 32 GB RAM)                       \u2502 \u2502\n\u2502   \u2502 Storage:  gp3 EBS (16,000 IOPS, 1,000 MB/s)                          \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#dataset-characteristics","title":"Dataset Characteristics","text":"Dataset Vertices Edges Properties Vector Dim Small 10K 50K 5 per vertex 128 Medium 100K 500K 5 per vertex 384 Large 1M 5M 5 per vertex 768 XLarge 10M 50M 5 per vertex 768"},{"location":"internals/benchmarks/#ingestion-performance","title":"Ingestion Performance","text":""},{"location":"internals/benchmarks/#raw-write-throughput","title":"Raw Write Throughput","text":"<p>Measuring writes to the in-memory L0 buffer:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      INGESTION THROUGHPUT                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Batch Size: 1,000 vertices                                                \u2502\n\u2502                                                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502                                                                    \u2502   \u2502\n\u2502   \u2502   Time (\u00b5s)                                                        \u2502   \u2502\n\u2502   \u2502   800 \u2524                                                            \u2502   \u2502\n\u2502   \u2502       \u2502                                                            \u2502   \u2502\n\u2502   \u2502   600 \u2524    \u250c\u2500\u2500\u2500\u2510                                                   \u2502   \u2502\n\u2502   \u2502       \u2502    \u2502\u2588\u2588\u2588\u2502                                                   \u2502   \u2502\n\u2502   \u2502   400 \u2524    \u2502\u2588\u2588\u2588\u2502    \u250c\u2500\u2500\u2500\u2510                                          \u2502   \u2502\n\u2502   \u2502       \u2502    \u2502\u2588\u2588\u2588\u2502    \u2502\u2588\u2588\u2588\u2502                                          \u2502   \u2502\n\u2502   \u2502   200 \u2524    \u2502\u2588\u2588\u2588\u2502    \u2502\u2588\u2588\u2588\u2502    \u250c\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2510                        \u2502   \u2502\n\u2502   \u2502       \u2502    \u2502\u2588\u2588\u2588\u2502    \u2502\u2588\u2588\u2588\u2502    \u2502\u2588\u2588\u2588\u2502    \u2502\u2588\u2588\u2588\u2502                        \u2502   \u2502\n\u2502   \u2502     0 \u253c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500                    \u2502   \u2502\n\u2502   \u2502        Insert    Insert   Insert   Insert                          \u2502   \u2502\n\u2502   \u2502        (cold)    (warm)   (batch)  (batch+WAL)                     \u2502   \u2502\n\u2502   \u2502                                                                    \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2502   Results (1K vertices):                                                    \u2502\n\u2502   \u251c\u2500\u2500 Cold insert (first batch):     ~720 \u00b5s                               \u2502\n\u2502   \u251c\u2500\u2500 Warm insert (cached):          ~420 \u00b5s                               \u2502\n\u2502   \u251c\u2500\u2500 Batch insert (no WAL sync):    ~180 \u00b5s                               \u2502\n\u2502   \u2514\u2500\u2500 Batch insert (WAL sync):       ~550 \u00b5s                               \u2502\n\u2502                                                                             \u2502\n\u2502   Throughput: 1.8M vertices/sec (batch, no sync)                           \u2502\n\u2502               550K vertices/sec (batch, sync WAL)                          \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#flush-performance-l0-l1","title":"Flush Performance (L0 \u2192 L1)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         FLUSH LATENCY                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Flush 10K vertices to Lance:                                              \u2502\n\u2502                                                                             \u2502\n\u2502   Phase               Time (ms)     Percentage                              \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                              \u2502\n\u2502   Serialize           12.4          19.7%                                   \u2502\n\u2502   Arrow conversion    18.2          28.9%                                   \u2502\n\u2502   Lance write         28.1          44.6%                                   \u2502\n\u2502   Index update         4.3           6.8%                                   \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                              \u2502\n\u2502   Total               63.0 ms       100%                                    \u2502\n\u2502                                                                             \u2502\n\u2502   Throughput: ~160K vertices/sec (to persistent storage)                   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#scaling-with-data-size","title":"Scaling with Data Size","text":"Data Size L0 Insert L0\u2192L1 Flush L1\u2192L2 Compact 1K vertices 550 \u00b5s 6.3 ms N/A 10K vertices 5.2 ms 63 ms 180 ms 100K vertices 52 ms 640 ms 2.1 s 1M vertices 520 ms 6.4 s 25 s"},{"location":"internals/benchmarks/#query-performance","title":"Query Performance","text":""},{"location":"internals/benchmarks/#point-lookups","title":"Point Lookups","text":"<p>Single vertex retrieval by indexed property:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     POINT LOOKUP LATENCY                                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper {id: 'paper_12345'}) RETURN p                       \u2502\n\u2502                                                                             \u2502\n\u2502   Index Type          P50        P90        P99        P99.9                \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   Hash index          2.1 ms     2.8 ms     4.2 ms     8.1 ms               \u2502\n\u2502   BTree index         2.4 ms     3.1 ms     4.8 ms     9.3 ms               \u2502\n\u2502   No index (scan)     85 ms      120 ms     180 ms     250 ms               \u2502\n\u2502                                                                             \u2502\n\u2502   Dataset: 1M vertices                                                      \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#range-queries","title":"Range Queries","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      RANGE QUERY PERFORMANCE                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper) WHERE p.year &gt;= 2020 AND p.year &lt;= 2023            \u2502\n\u2502          RETURN p.title                                                     \u2502\n\u2502                                                                             \u2502\n\u2502   Selectivity    Rows Returned    Index Time    Scan Time    Speedup        \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500         \u2502\n\u2502   1% (10K)       10,000           12 ms         85 ms        7.1x           \u2502\n\u2502   5% (50K)       50,000           35 ms         95 ms        2.7x           \u2502\n\u2502   10% (100K)     100,000          58 ms         102 ms       1.8x           \u2502\n\u2502   50% (500K)     500,000          210 ms        180 ms       0.9x (scan wins)\u2502\n\u2502                                                                             \u2502\n\u2502   Dataset: 1M vertices                                                      \u2502\n\u2502   Takeaway: Index wins for selectivity &lt; 30%                                \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#aggregation-queries","title":"Aggregation Queries","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    AGGREGATION PERFORMANCE                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper) RETURN p.venue, COUNT(*) AS count                  \u2502\n\u2502          ORDER BY count DESC                                                \u2502\n\u2502                                                                             \u2502\n\u2502   Dataset Size    Groups    Aggregate    Sort       Total                   \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   100K            50        28 ms        2 ms       30 ms                   \u2502\n\u2502   1M              50        185 ms       3 ms       188 ms                  \u2502\n\u2502   1M              10K       320 ms       45 ms      365 ms                  \u2502\n\u2502   1M              100K      580 ms       120 ms     700 ms                  \u2502\n\u2502                                                                             \u2502\n\u2502   Takeaway: Hash aggregation scales linearly with input size                \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#graph-traversal-performance","title":"Graph Traversal Performance","text":""},{"location":"internals/benchmarks/#single-hop-traversal","title":"Single-Hop Traversal","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    1-HOP TRAVERSAL LATENCY                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper)-[:CITES]-&gt;(cited)                                  \u2502\n\u2502          WHERE p.id = 'paper_12345'                                         \u2502\n\u2502          RETURN cited.title                                                 \u2502\n\u2502                                                                             \u2502\n\u2502   Cache State        P50        P90        P99        Notes                 \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   Cold cache         8.2 ms     12.1 ms    18.5 ms    Load from Lance      \u2502\n\u2502   Warm cache         4.7 ms     5.8 ms     8.1 ms     CSR in memory        \u2502\n\u2502   Hot path           2.1 ms     2.8 ms     4.2 ms     Repeated query       \u2502\n\u2502                                                                             \u2502\n\u2502   Average degree: 5 edges per vertex                                        \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#multi-hop-traversal","title":"Multi-Hop Traversal","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   MULTI-HOP TRAVERSAL SCALING                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (start)-[:CITES*N]-&gt;(end) RETURN DISTINCT end                \u2502\n\u2502                                                                             \u2502\n\u2502   Latency (ms)                                                              \u2502\n\u2502   40 \u2524                                                   \u250c\u2500\u2500\u2500\u2510              \u2502\n\u2502      \u2502                                                   \u2502   \u2502              \u2502\n\u2502   35 \u2524                                                   \u2502   \u2502              \u2502\n\u2502      \u2502                                                   \u2502   \u2502              \u2502\n\u2502   30 \u2524                                                   \u2502   \u2502              \u2502\n\u2502      \u2502                                                   \u2502   \u2502              \u2502\n\u2502   25 \u2524                                                   \u2502   \u2502              \u2502\n\u2502      \u2502                                                   \u2502   \u2502              \u2502\n\u2502   20 \u2524                                          \u250c\u2500\u2500\u2500\u2510    \u2502   \u2502              \u2502\n\u2502      \u2502                                          \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502   15 \u2524                                 \u250c\u2500\u2500\u2500\u2510    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502      \u2502                                 \u2502   \u2502    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502   10 \u2524                        \u250c\u2500\u2500\u2500\u2510    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502      \u2502               \u250c\u2500\u2500\u2500\u2510    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502    5 \u2524      \u250c\u2500\u2500\u2500\u2510    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502      \u2502      \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502    \u2502   \u2502              \u2502\n\u2502    0 \u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500            \u2502\n\u2502          1-hop    2-hop    3-hop    4-hop    5-hop    6-hop                 \u2502\n\u2502                                                                             \u2502\n\u2502   Hops    Vertices Visited    Latency    Throughput                         \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2502\n\u2502   1       5                   4.7 ms     1.1K v/s                           \u2502\n\u2502   2       25                  6.7 ms     3.7K v/s                           \u2502\n\u2502   3       125                 9.0 ms     13.9K v/s                          \u2502\n\u2502   4       625                 15.2 ms    41.1K v/s                          \u2502\n\u2502   5       3,125               22.8 ms    137K v/s                           \u2502\n\u2502   6       15,625              38.5 ms    406K v/s                           \u2502\n\u2502                                                                             \u2502\n\u2502   Note: Assuming avg degree = 5, no duplicates                              \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#traversal-with-filters","title":"Traversal with Filters","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               FILTERED TRAVERSAL PERFORMANCE                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)                            \u2502\n\u2502          WHERE p.year &gt; 2020 AND cited.year &gt; 2018                          \u2502\n\u2502          RETURN cited.title                                                 \u2502\n\u2502                                                                             \u2502\n\u2502   Strategy                    Latency    Notes                              \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2502\n\u2502   Filter-then-traverse        12.5 ms    Filter p first, then traverse     \u2502\n\u2502   Traverse-then-filter        28.3 ms    Traverse all, filter cited        \u2502\n\u2502   Dual pushdown               8.2 ms     Push both filters down            \u2502\n\u2502                                                                             \u2502\n\u2502   Dataset: 1M papers, 5M citations                                          \u2502\n\u2502   Filter selectivity: p.year &gt; 2020 = 30%, cited.year &gt; 2018 = 60%         \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#vector-search-performance","title":"Vector Search Performance","text":""},{"location":"internals/benchmarks/#knn-search-hnsw","title":"KNN Search (HNSW)","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      VECTOR KNN LATENCY                                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: CALL db.idx.vector.query('Paper', 'embedding', $vec, 10)           \u2502\n\u2502                                                                             \u2502\n\u2502   Dataset: 1M vectors, 768 dimensions, HNSW index                           \u2502\n\u2502                                                                             \u2502\n\u2502   k       P50        P90        P99        Recall@k                         \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2502\n\u2502   10      1.8 ms     2.4 ms     3.8 ms     0.95                             \u2502\n\u2502   50      2.9 ms     3.8 ms     5.2 ms     0.94                             \u2502\n\u2502   100     4.2 ms     5.5 ms     7.8 ms     0.93                             \u2502\n\u2502   500     12.5 ms    16.2 ms    22.1 ms    0.91                             \u2502\n\u2502                                                                             \u2502\n\u2502   HNSW Parameters: M=32, ef_construction=200, ef_search=100                 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#hnsw-vs-ivf_pq","title":"HNSW vs IVF_PQ","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    INDEX COMPARISON (k=10)                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Dataset: 1M vectors, 768 dimensions                                       \u2502\n\u2502                                                                             \u2502\n\u2502   Index Type      Build Time    Memory     Latency    Recall                \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   HNSW            45 min        2.4 GB     1.8 ms     0.95                  \u2502\n\u2502   IVF_PQ          12 min        180 MB     3.2 ms     0.88                  \u2502\n\u2502   Brute Force     N/A           2.9 GB     85 ms      1.00                  \u2502\n\u2502                                                                             \u2502\n\u2502   Recommendation:                                                           \u2502\n\u2502   \u2022 HNSW: Best recall, moderate memory                                      \u2502\n\u2502   \u2022 IVF_PQ: Low memory, acceptable recall                                   \u2502\n\u2502   \u2022 Brute Force: Only for small datasets (&lt;100K)                           \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#vector-search-scaling","title":"Vector Search Scaling","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    SCALING WITH DATASET SIZE                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   HNSW Index, k=10, 768 dimensions                                          \u2502\n\u2502                                                                             \u2502\n\u2502   Dataset Size    Latency (P50)    Memory (Index)    Build Time             \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   100K            0.8 ms           240 MB            4 min                  \u2502\n\u2502   1M              1.8 ms           2.4 GB            45 min                 \u2502\n\u2502   10M             3.2 ms           24 GB             8 hours                \u2502\n\u2502                                                                             \u2502\n\u2502   Observation: Latency scales O(log n) due to HNSW structure               \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#hybrid-query-performance","title":"Hybrid Query Performance","text":""},{"location":"internals/benchmarks/#vector-graph-queries","title":"Vector + Graph Queries","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    HYBRID QUERY BREAKDOWN                                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: CALL db.idx.vector.query('Paper', 'embedding', $vec, 20)           \u2502\n\u2502          YIELD node AS paper                                                \u2502\n\u2502          MATCH (paper)-[:CITES]-&gt;(cited)                                    \u2502\n\u2502          WHERE cited.year &gt; 2020                                            \u2502\n\u2502          RETURN cited.title                                                 \u2502\n\u2502                                                                             \u2502\n\u2502   Phase               Time        Rows In    Rows Out                       \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                     \u2502\n\u2502   Vector Search       2.1 ms      1M         20                             \u2502\n\u2502   Traverse            45 ms       20         ~100                           \u2502\n\u2502   Filter              8 ms        ~100       ~60                            \u2502\n\u2502   Project             2 ms        ~60        ~60                            \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                     \u2502\n\u2502   Total               ~57 ms                                                \u2502\n\u2502                                                                             \u2502\n\u2502   Note: Traversal dominates due to cold cache for cited papers             \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#complex-hybrid-query","title":"Complex Hybrid Query","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   COMPLEX HYBRID QUERY                                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: // Find papers similar to query, get their authors' other papers   \u2502\n\u2502          CALL db.idx.vector.query('Paper', 'embedding', $vec, 10)           \u2502\n\u2502          YIELD node AS similar                                              \u2502\n\u2502          MATCH (similar)-[:AUTHORED_BY]-&gt;(author)                           \u2502\n\u2502          MATCH (author)&lt;-[:AUTHORED_BY]-(other:Paper)                       \u2502\n\u2502          WHERE other.year &gt; 2020                                            \u2502\n\u2502          RETURN DISTINCT other.title, author.name                           \u2502\n\u2502          LIMIT 50                                                           \u2502\n\u2502                                                                             \u2502\n\u2502   Execution Timeline:                                                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 0ms         50ms        100ms       150ms       200ms       250ms    \u2502 \u2502\n\u2502   \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524        \u2502 \u2502\n\u2502   \u2502 \u2502\u2593\u2593\u2593\u2502                                                 Vector (2ms)   \u2502 \u2502\n\u2502   \u2502    \u2502\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2502                                    Traverse1 (35ms)\u2502 \u2502\n\u2502   \u2502               \u2502\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2502          Traverse2 (120ms)\u2502\n\u2502   \u2502                                          \u2502\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2502  Filter (45ms)   \u2502 \u2502\n\u2502   \u2502                                                  \u2502\u2593\u2502 Project (8ms)   \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2502   Total: ~215 ms                                                            \u2502\n\u2502                                                                             \u2502\n\u2502   Bottleneck: Second traversal (author \u2192 other papers)                      \u2502\n\u2502   Optimization: Add LIMIT earlier, warm adjacency cache                     \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#concurrent-query-performance","title":"Concurrent Query Performance","text":""},{"location":"internals/benchmarks/#read-throughput","title":"Read Throughput","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   CONCURRENT READ THROUGHPUT                                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Query: MATCH (p:Paper) WHERE p.year = 2023 RETURN p.title LIMIT 10        \u2502\n\u2502   Dataset: 1M vertices                                                      \u2502\n\u2502                                                                             \u2502\n\u2502   QPS                                                                       \u2502\n\u2502   1200 \u2524                                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2502\n\u2502        \u2502                                    \u250c\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502   1000 \u2524                              \u250c\u2500\u2500\u2500\u2500\u2500\u2518                               \u2502\n\u2502        \u2502                        \u250c\u2500\u2500\u2500\u2500\u2500\u2518                                     \u2502\n\u2502    800 \u2524                  \u250c\u2500\u2500\u2500\u2500\u2500\u2518                                           \u2502\n\u2502        \u2502            \u250c\u2500\u2500\u2500\u2500\u2500\u2518                                                 \u2502\n\u2502    600 \u2524      \u250c\u2500\u2500\u2500\u2500\u2500\u2518                                                       \u2502\n\u2502        \u2502\u250c\u2500\u2500\u2500\u2500\u2500\u2518                                                             \u2502\n\u2502    400 \u2524\u2502                                                                   \u2502\n\u2502        \u2502\u2502                                                                   \u2502\n\u2502    200 \u2524\u2502                                                                   \u2502\n\u2502        \u2502\u2502                                                                   \u2502\n\u2502      0 \u253c\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500    \u2502\n\u2502         1    2    4    8   12   16   24   32  (concurrent readers)         \u2502\n\u2502                                                                             \u2502\n\u2502   Threads    QPS        Avg Latency    P99 Latency                         \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                         \u2502\n\u2502   1          180        5.5 ms         8.2 ms                               \u2502\n\u2502   4          650        6.1 ms         12.5 ms                              \u2502\n\u2502   8          920        8.7 ms         18.2 ms                              \u2502\n\u2502   16         1,050      15.2 ms        35.1 ms                              \u2502\n\u2502   32         1,120      28.5 ms        65.2 ms                              \u2502\n\u2502                                                                             \u2502\n\u2502   Note: Scales well up to ~16 readers, then contention increases           \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#write-impact-on-reads","title":"Write Impact on Reads","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 READ LATENCY UNDER WRITE LOAD                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Write Rate (vertices/sec)    Read P50    Read P99    Notes                \u2502\n\u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500                 \u2502\n\u2502   0 (no writes)                5.5 ms      8.2 ms      Baseline             \u2502\n\u2502   1,000                        5.6 ms      9.1 ms      Minimal impact       \u2502\n\u2502   10,000                       5.8 ms      11.5 ms     Slight increase      \u2502\n\u2502   50,000                       6.2 ms      15.2 ms     L0 buffer growing    \u2502\n\u2502   100,000                      7.5 ms      22.1 ms     Frequent flushes     \u2502\n\u2502                                                                             \u2502\n\u2502   Takeaway: Single-writer model ensures reads remain consistent            \u2502\n\u2502             L0 flushes cause brief latency spikes                          \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/benchmarks/#graph-algorithm-performance","title":"Graph Algorithm Performance","text":"<p>Uni includes native implementations of common graph algorithms, optimized for the CSR adjacency cache.</p> Algorithm Complexity Notes PageRank O(E) per iter Parallel execution WCC O(V + E) Union-Find with path compression Louvain O(E) per iter Multi-level community detection Label Propagation O(E) per iter Fast community detection Triangle Count O(E^1.5) SIMD-optimized set intersection Betweenness O(VE) Sampling-based approximation available"},{"location":"internals/benchmarks/#running-benchmarks","title":"Running Benchmarks","text":""},{"location":"internals/benchmarks/#built-in-benchmark-suite","title":"Built-in Benchmark Suite","text":"<pre><code># Run all benchmarks\ncargo bench\n\n# Run specific benchmark\ncargo bench -- ingestion\ncargo bench -- traversal\ncargo bench -- vector_search\n\n# Run with specific dataset size\nBENCH_SIZE=large cargo bench\n\n# Generate HTML report\ncargo bench -- --save-baseline main\nopen target/criterion/report/index.html\n</code></pre>"},{"location":"internals/benchmarks/#custom-benchmarks","title":"Custom Benchmarks","text":"<pre><code>use criterion::{criterion_group, criterion_main, Criterion, BenchmarkId};\nuse uni::prelude::*;\n\nfn benchmark_traversal(c: &amp;mut Criterion) {\n    let storage = setup_test_storage();\n\n    let mut group = c.benchmark_group(\"traversal\");\n\n    for hops in [1, 2, 3, 4, 5] {\n        group.bench_with_input(\n            BenchmarkId::new(\"multi_hop\", hops),\n            &amp;hops,\n            |b, &amp;hops| {\n                b.iter(|| {\n                    let query = format!(\n                        \"MATCH (p:Paper)-[:CITES*{}]-&gt;(end) \\\n                         WHERE p.id = 'seed_paper' \\\n                         RETURN DISTINCT end.id\",\n                        hops\n                    );\n                    executor.execute(&amp;query).unwrap()\n                })\n            },\n        );\n    }\n\n    group.finish();\n}\n\ncriterion_group!(benches, benchmark_traversal);\ncriterion_main!(benches);\n</code></pre>"},{"location":"internals/benchmarks/#profiling","title":"Profiling","text":"<pre><code># CPU profiling with perf\nperf record cargo bench -- vector_search\nperf report\n\n# Memory profiling\nRUST_BACKTRACE=1 cargo bench -- --profile-time 30\n\n# Flame graphs\ncargo flamegraph --bench storage_bench -- --bench\n</code></pre>"},{"location":"internals/benchmarks/#performance-recommendations","title":"Performance Recommendations","text":""},{"location":"internals/benchmarks/#query-optimization","title":"Query Optimization","text":"Scenario Current Optimized Improvement Missing index 85ms 2.9ms 29x Full projection 12ms 5ms 2.4x Late LIMIT 180ms 45ms 4x Cold cache 8.2ms 4.7ms 1.7x"},{"location":"internals/benchmarks/#configuration-tuning","title":"Configuration Tuning","text":"<pre><code>// Optimized for throughput\nlet config = StorageConfig {\n    batch_size: 8192,\n    adjacency_cache_size: 2_000_000,\n    property_cache_size: 500_000,\n    max_l0_size: 256 * 1024 * 1024,  // 256 MB\n    wal_sync_mode: WalSyncMode::Periodic { interval_ms: 100 },\n};\n\n// Optimized for latency\nlet config = StorageConfig {\n    batch_size: 2048,\n    adjacency_cache_size: 5_000_000,\n    property_cache_size: 1_000_000,\n    max_l0_size: 64 * 1024 * 1024,  // 64 MB\n    wal_sync_mode: WalSyncMode::Sync,\n};\n</code></pre>"},{"location":"internals/benchmarks/#next-steps","title":"Next Steps","text":"<ul> <li>Performance Tuning \u2014 Optimization strategies</li> <li>Vectorized Execution \u2014 Execution engine details</li> <li>Storage Engine \u2014 Storage layer internals</li> </ul>"},{"location":"internals/mutation_spec/","title":"Mutation Support Specification (DELETE, SET, MERGE)","text":"<p>This document outlines the design and implementation plan for adding <code>DELETE</code>, <code>SET</code>, and <code>MERGE</code> support to Uni's Cypher query engine.</p>"},{"location":"internals/mutation_spec/#1-overview","title":"1. Overview","text":"<p>Currently, Uni supports read-only queries via the vectorized execution engine. Write operations are limited to the <code>Writer</code> API and are not exposed via Cypher. This specification defines how to bridge this gap, enabling full CRUD capabilities.</p>"},{"location":"internals/mutation_spec/#2-grammar-parsing","title":"2. Grammar &amp; Parsing","text":"<p>We need to extend the <code>CypherParser</code> (using <code>open_cypher_grammar</code> or custom logic) to support the following clauses.</p>"},{"location":"internals/mutation_spec/#21-delete-detach-delete","title":"2.1 DELETE / DETACH DELETE","text":"<p><pre><code>MATCH (n:Person) WHERE n.name = 'DeleteMe'\nDELETE n\n</code></pre> - <code>DELETE</code>: Marks nodes/relationships for deletion. Fails if nodes still have relationships. - <code>DETACH DELETE</code>: Removes relationships attached to the node before deleting the node.</p>"},{"location":"internals/mutation_spec/#22-set-remove","title":"2.2 SET / REMOVE","text":"<p><pre><code>MATCH (n:Person {id: 1})\nSET n.email = 'new@example.com', n.updated_at = timestamp()\nREMOVE n.old_prop\n</code></pre> - <code>SET</code>: Updates or adds properties. - <code>REMOVE</code>: Removes properties (equivalent to <code>SET n.prop = null</code> in some systems, but distinct in Cypher).</p>"},{"location":"internals/mutation_spec/#23-merge","title":"2.3 MERGE","text":"<p><pre><code>MERGE (n:Person {email: 'user@example.com'})\nON CREATE SET n.created = timestamp()\nON MATCH SET n.last_login = timestamp()\nRETURN n\n</code></pre> - <code>MERGE</code>: \"Match or Create\". Requires existence check followed by conditional insert.</p>"},{"location":"internals/mutation_spec/#3-logical-plan","title":"3. Logical Plan","text":"<p>New logical operators will be added to <code>uni::query::logical_plan</code>.</p> <pre><code>pub enum LogicalOperator {\n    // ... existing ...\n    SetProperty {\n        input: Box&lt;LogicalPlan&gt;,\n        items: Vec&lt;SetItem&gt;, // (Var, Key, Expr)\n    },\n    Delete {\n        input: Box&lt;LogicalPlan&gt;,\n        node_vars: Vec&lt;Var&gt;,\n        edge_vars: Vec&lt;Var&gt;,\n        detach: bool,\n    },\n    // MERGE is a composite operation usually expanded during planning, \n    // but might need a dedicated operator for atomicity.\n}\n</code></pre>"},{"location":"internals/mutation_spec/#4-physical-plan-vectorized-execution","title":"4. Physical Plan (Vectorized Execution)","text":"<p>The <code>VectorizedExecution</code> engine will be extended with \"Side-Effect Operators\". Unlike <code>Project</code> or <code>Filter</code> which transform data, these operators consume batches and apply changes to the <code>Writer</code>.</p>"},{"location":"internals/mutation_spec/#41-vectorizedset","title":"4.1 VectorizedSet","text":"<p>Input: <code>VectorizedBatch</code> Action: 1. Evaluate expressions for the property values. 2. Group updates by VID/EID. 3. Call <code>Writer::insert_vertex(vid, props)</code> or <code>Writer::insert_edge(...)</code>.    - Note: <code>Writer::insert_vertex</code> in <code>L0Buffer</code> already implements merge semantics (patching properties), which matches <code>SET</code> behavior.    - For <code>REMOVE</code>, we might need a specific <code>Writer::remove_property</code> or pass a <code>Null</code> value if we decide <code>Null</code> means remove (standard Cypher treats Null property as non-existent).</p>"},{"location":"internals/mutation_spec/#42-vectorizeddelete","title":"4.2 VectorizedDelete","text":"<p>Input: <code>VectorizedBatch</code> Action: 1. Iterate over VIDs (for nodes) or EIDs (for relationships). 2. Call <code>Writer::delete_vertex(vid)</code> or <code>Writer::delete_edge(eid)</code>. 3. If <code>detach</code> is true, we must first look up all incident edges (using <code>AdjacencyCache</code> or <code>Storage</code>) and delete them. Optimization: This can be expensive; ideally, we push this to the storage layer or expand it in the logical plan.</p>"},{"location":"internals/mutation_spec/#5-execution-model-consistency","title":"5. Execution Model &amp; Consistency","text":""},{"location":"internals/mutation_spec/#51-single-writer","title":"5.1 Single-Writer","text":"<p>Uni is single-writer. The <code>Executor</code> currently holds a read view (<code>StorageManager</code>). For mutations: 1. The <code>Executor</code> must have access to the <code>Writer</code> (currently wrapped in <code>Arc&lt;Mutex&lt;Writer&gt;&gt;</code> or similar in the main app). 2. Mutations write to <code>L0Buffer</code>.</p>"},{"location":"internals/mutation_spec/#52-visibility-read-your-writes","title":"5.2 Visibility (Read-Your-Writes)","text":"<ul> <li>Standard Cypher: Changes made in a query are visible to subsequent clauses in the same query.</li> <li>Uni Implementation: </li> <li><code>L0Buffer</code> writes are immediate in memory.</li> <li>However, the <code>VectorizedEngine</code> processes data in pipeline streams.</li> <li>If a <code>MATCH</code> downstream needs to see a <code>SET</code> upstream, it must re-read from <code>L0</code>.</li> <li>MVP constraint: We will aim for \"Statement-level Atomicity\". Mutations are applied as the batch flows through. Downstream operators (like <code>RETURN</code>) usually just return the passed variables. If <code>RETURN n</code> fetches properties again, it might see the update. If it uses the already scanned batch, it won't.</li> <li>Proposed Semantics for Phase 1: Variables bound before the modification retain their old state in the batch. If re-matched, they see new state. This is consistent with many vectorized engines.</li> </ul>"},{"location":"internals/mutation_spec/#6-implementation-roadmap","title":"6. Implementation Roadmap","text":""},{"location":"internals/mutation_spec/#phase-11-parser-logical-plan","title":"Phase 1.1: Parser &amp; Logical Plan","text":"<ul> <li>Update <code>CypherParser</code> to handle <code>SET</code>, <code>DELETE</code>.</li> <li>Add <code>LogicalOperator::Set</code>, <code>LogicalOperator::Delete</code>.</li> <li>Update <code>QueryPlanner</code> to map AST to Logical Plan.</li> </ul>"},{"location":"internals/mutation_spec/#phase-12-physical-operators","title":"Phase 1.2: Physical Operators","text":"<ul> <li>Implement <code>VectorizedSet</code> operator.</li> <li>Implement <code>VectorizedDelete</code> operator.</li> <li>Integrate <code>Writer</code> into <code>ExecutionContext</code>.</li> </ul>"},{"location":"internals/mutation_spec/#phase-13-end-to-end-test","title":"Phase 1.3: End-to-End Test","text":"<ul> <li>Test: <code>CREATE (n {p:1}) SET n.p=2 RETURN n.p</code> -&gt; Expect 2.</li> <li>Test: <code>CREATE (n) DELETE n RETURN count(n)</code> -&gt; Expect 0 (or empty).</li> </ul>"},{"location":"internals/query-planning/","title":"Query Planning","text":"<p>This document describes how Uni transforms Cypher queries into optimized physical execution plans. The query planner is responsible for parsing, semantic analysis, optimization, and code generation.</p>"},{"location":"internals/query-planning/#planning-pipeline-overview","title":"Planning Pipeline Overview","text":"flowchart TB     Query[\"Cypher Query\"]     Parser[\"Parser&lt;br/&gt;&lt;i&gt;Cypher \u2192 AST&lt;/i&gt;\"]     Analyzer[\"Analyzer&lt;br/&gt;&lt;i&gt;AST \u2192 Logical Plan&lt;br/&gt;(with type resolution)&lt;/i&gt;\"]     Optimizer[\"Optimizer&lt;br/&gt;&lt;i&gt;Logical Plan \u2192 Optimized Logical Plan&lt;/i&gt;\"]     PhysicalPlanner[\"Physical Planner&lt;br/&gt;&lt;i&gt;Logical Plan \u2192 Physical Plan&lt;/i&gt;\"]     Executor[\"Executor&lt;br/&gt;&lt;i&gt;Physical Plan \u2192 Results&lt;/i&gt;\"]      Query --&gt; Parser --&gt; Analyzer --&gt; Optimizer --&gt; PhysicalPlanner --&gt; Executor"},{"location":"internals/query-planning/#phase-1-parsing","title":"Phase 1: Parsing","text":"<p>The parser transforms Cypher text into an Abstract Syntax Tree (AST).</p>"},{"location":"internals/query-planning/#parser-architecture","title":"Parser Architecture","text":"<p>Uni's parser is built on <code>sqlparser-rs</code> with Cypher-specific extensions:</p> <pre><code>pub struct CypherParser {\n    /// Token stream\n    lexer: Lexer,\n\n    /// Current token\n    current: Token,\n\n    /// Lookahead token\n    peek: Token,\n}\n\nimpl CypherParser {\n    pub fn parse(&amp;mut self) -&gt; Result&lt;Statement&gt; {\n        match self.current {\n            Token::Match =&gt; self.parse_match_clause(),\n            Token::Create =&gt; self.parse_create_clause(),\n            Token::Call =&gt; self.parse_call_clause(),\n            Token::Return =&gt; self.parse_return_clause(),\n            _ =&gt; Err(UnexpectedToken(self.current)),\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#ast-structure","title":"AST Structure","text":"<pre><code>pub enum Statement {\n    /// READ queries\n    Query(QueryStatement),\n\n    /// WRITE queries\n    Create(CreateStatement),\n\n    /// DDL\n    CreateIndex(CreateIndexStatement),\n    DropIndex(String),\n\n    /// Procedures\n    Call(CallStatement),\n}\n\npub struct QueryStatement {\n    pub match_clause: Option&lt;MatchClause&gt;,\n    pub where_clause: Option&lt;Expression&gt;,\n    pub with_clause: Option&lt;WithClause&gt;,\n    pub return_clause: ReturnClause,\n    pub order_by: Option&lt;Vec&lt;OrderByItem&gt;&gt;,\n    pub skip: Option&lt;Expression&gt;,\n    pub limit: Option&lt;Expression&gt;,\n}\n\npub struct MatchClause {\n    pub patterns: Vec&lt;Pattern&gt;,\n    pub optional: bool,\n}\n\npub struct Pattern {\n    pub elements: Vec&lt;PatternElement&gt;,\n}\n\npub enum PatternElement {\n    Node(NodePattern),\n    Relationship(RelationshipPattern),\n}\n\npub struct NodePattern {\n    pub variable: Option&lt;String&gt;,\n    pub labels: Vec&lt;String&gt;,\n    pub properties: Option&lt;HashMap&lt;String, Expression&gt;&gt;,\n}\n\npub struct RelationshipPattern {\n    pub variable: Option&lt;String&gt;,\n    pub types: Vec&lt;String&gt;,\n    pub direction: Direction,\n    pub properties: Option&lt;HashMap&lt;String, Expression&gt;&gt;,\n    pub length: Option&lt;PathLength&gt;,\n}\n</code></pre>"},{"location":"internals/query-planning/#example-parse","title":"Example Parse","text":"<pre><code>MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\nWHERE p.year &gt; 2020\nRETURN p.title, cited.title\n</code></pre> <p>Parses to:</p> <pre><code>QueryStatement {\n  match_clause: MatchClause {\n    patterns: [\n      Pattern {\n        elements: [\n          Node { variable: \"p\", labels: [\"Paper\"], properties: None },\n          Relationship { variable: None, types: [\"CITES\"], direction: Outgoing },\n          Node { variable: \"cited\", labels: [\"Paper\"], properties: None }\n        ]\n      }\n    ]\n  },\n  where_clause: BinaryOp {\n    left: PropertyAccess { variable: \"p\", property: \"year\" },\n    op: GreaterThan,\n    right: Literal(2020)\n  },\n  return_clause: ReturnClause {\n    items: [\n      PropertyAccess { variable: \"p\", property: \"title\" },\n      PropertyAccess { variable: \"cited\", property: \"title\" }\n    ]\n  }\n}\n</code></pre>"},{"location":"internals/query-planning/#phase-2-semantic-analysis","title":"Phase 2: Semantic Analysis","text":"<p>The analyzer resolves types, validates schemas, and builds a logical plan.</p>"},{"location":"internals/query-planning/#scope-management","title":"Scope Management","text":"<pre><code>pub struct Analyzer {\n    /// Schema for type resolution\n    schema: Arc&lt;SchemaManager&gt;,\n\n    /// Variable scope stack\n    scopes: Vec&lt;Scope&gt;,\n}\n\npub struct Scope {\n    /// Variables in scope: name \u2192 (type, label/edge_type)\n    variables: HashMap&lt;String, VariableBinding&gt;,\n}\n\npub struct VariableBinding {\n    /// Variable type (Node, Relationship, Property)\n    var_type: VariableType,\n\n    /// Label ID (for nodes) or edge type ID (for relationships)\n    type_id: Option&lt;TypeId&gt;,\n\n    /// Property schema\n    properties: Option&lt;Arc&lt;PropertySchema&gt;&gt;,\n}\n\nimpl Analyzer {\n    fn analyze_node_pattern(&amp;mut self, pattern: &amp;NodePattern) -&gt; Result&lt;LogicalNode&gt; {\n        // Resolve label to schema\n        let label_id = if let Some(label) = pattern.labels.first() {\n            Some(self.schema.get_label_id(label)?)\n        } else {\n            None\n        };\n\n        // Register variable in scope\n        if let Some(var) = &amp;pattern.variable {\n            self.current_scope().bind_variable(\n                var.clone(),\n                VariableBinding {\n                    var_type: VariableType::Node,\n                    type_id: label_id.map(TypeId::Label),\n                    properties: label_id.and_then(|id| self.schema.get_properties(id)),\n                }\n            );\n        }\n\n        Ok(LogicalNode { label_id, variable: pattern.variable.clone() })\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#type-inference","title":"Type Inference","text":"<pre><code>impl Analyzer {\n    fn infer_expression_type(&amp;self, expr: &amp;Expression) -&gt; Result&lt;DataType&gt; {\n        match expr {\n            Expression::Literal(lit) =&gt; Ok(lit.data_type()),\n\n            Expression::PropertyAccess { variable, property } =&gt; {\n                let binding = self.resolve_variable(variable)?;\n                let prop_schema = binding.properties\n                    .ok_or(UnknownProperty(property.clone()))?;\n                prop_schema.get_type(property)\n                    .ok_or(UnknownProperty(property.clone()))\n            }\n\n            Expression::BinaryOp { left, op, right } =&gt; {\n                let left_type = self.infer_expression_type(left)?;\n                let right_type = self.infer_expression_type(right)?;\n\n                match op {\n                    // Comparison operators return boolean\n                    Op::Eq | Op::Lt | Op::Gt | Op::Lte | Op::Gte | Op::Neq =&gt; {\n                        Ok(DataType::Boolean)\n                    }\n                    // Arithmetic operators preserve type\n                    Op::Add | Op::Sub | Op::Mul | Op::Div =&gt; {\n                        self.common_numeric_type(&amp;left_type, &amp;right_type)\n                    }\n                    // Boolean operators require boolean\n                    Op::And | Op::Or =&gt; {\n                        if left_type == DataType::Boolean &amp;&amp; right_type == DataType::Boolean {\n                            Ok(DataType::Boolean)\n                        } else {\n                            Err(TypeMismatch(\"boolean\", left_type))\n                        }\n                    }\n                }\n            }\n\n            Expression::FunctionCall { name, args } =&gt; {\n                self.infer_function_return_type(name, args)\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#phase-3-logical-plan","title":"Phase 3: Logical Plan","text":"<p>The logical plan represents the query as a tree of relational-style operators.</p>"},{"location":"internals/query-planning/#logical-operators","title":"Logical Operators","text":"<pre><code>pub enum LogicalPlan {\n    /// Scan vertices of a label\n    Scan {\n        label_id: LabelId,\n        alias: String,\n        filter: Option&lt;LogicalExpr&gt;,\n    },\n\n    /// Traverse edges\n    Traverse {\n        input: Box&lt;LogicalPlan&gt;,\n        edge_type: EdgeTypeId,\n        direction: Direction,\n        src_alias: String,\n        dst_alias: String,\n        edge_alias: Option&lt;String&gt;,\n    },\n\n    /// Filter rows\n    Filter {\n        input: Box&lt;LogicalPlan&gt;,\n        predicate: LogicalExpr,\n    },\n\n    /// Project columns\n    Project {\n        input: Box&lt;LogicalPlan&gt;,\n        expressions: Vec&lt;(LogicalExpr, String)&gt;,\n    },\n\n    /// Aggregate\n    Aggregate {\n        input: Box&lt;LogicalPlan&gt;,\n        group_by: Vec&lt;LogicalExpr&gt;,\n        aggregates: Vec&lt;(AggregateFunction, String)&gt;,\n    },\n\n    /// Sort\n    Sort {\n        input: Box&lt;LogicalPlan&gt;,\n        order_by: Vec&lt;(LogicalExpr, SortOrder)&gt;,\n    },\n\n    /// Limit/Skip\n    Limit {\n        input: Box&lt;LogicalPlan&gt;,\n        skip: Option&lt;usize&gt;,\n        limit: Option&lt;usize&gt;,\n    },\n\n    /// Vector search\n    VectorSearch {\n        label_id: LabelId,\n        property: String,\n        query_vector: Vec&lt;f32&gt;,\n        k: usize,\n        alias: String,\n    },\n\n    /// Cross product (for multiple MATCH patterns)\n    CrossProduct {\n        left: Box&lt;LogicalPlan&gt;,\n        right: Box&lt;LogicalPlan&gt;,\n    },\n}\n</code></pre>"},{"location":"internals/query-planning/#example-logical-plan","title":"Example Logical Plan","text":"<p>Query: <pre><code>MATCH (p:Paper)-[:CITES]-&gt;(cited:Paper)\nWHERE p.year &gt; 2020\nRETURN p.title, COUNT(cited) AS citation_count\nORDER BY citation_count DESC\nLIMIT 10\n</code></pre></p> <p>Logical Plan: <pre><code>Limit(10)\n  \u2514\u2500\u2500 Sort(citation_count DESC)\n        \u2514\u2500\u2500 Aggregate(GROUP BY p, COUNT(cited))\n              \u2514\u2500\u2500 Filter(p.year &gt; 2020)\n                    \u2514\u2500\u2500 Traverse(CITES, OUT, p \u2192 cited)\n                          \u2514\u2500\u2500 Scan(:Paper AS p)\n</code></pre></p>"},{"location":"internals/query-planning/#phase-4-query-optimization","title":"Phase 4: Query Optimization","text":"<p>The optimizer applies transformation rules to improve query performance.</p>"},{"location":"internals/query-planning/#optimization-rules","title":"Optimization Rules","text":"<pre><code>pub trait OptimizationRule {\n    /// Rule name for debugging\n    fn name(&amp;self) -&gt; &amp;str;\n\n    /// Check if rule applies to this plan\n    fn matches(&amp;self, plan: &amp;LogicalPlan) -&gt; bool;\n\n    /// Transform the plan\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan;\n}\n</code></pre>"},{"location":"internals/query-planning/#rule-1-predicate-pushdown","title":"Rule 1: Predicate Pushdown","text":"<p>Push filters as close to the data source as possible:</p> <pre><code>pub struct PredicatePushdown;\n\nimpl OptimizationRule for PredicatePushdown {\n    fn name(&amp;self) -&gt; &amp;str { \"predicate_pushdown\" }\n\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        match plan {\n            // Push filter past project\n            LogicalPlan::Filter { input, predicate } =&gt; {\n                match *input {\n                    LogicalPlan::Project { input: proj_input, expressions } =&gt; {\n                        // Check if predicate only references projected columns\n                        if can_push_past_project(&amp;predicate, &amp;expressions) {\n                            LogicalPlan::Project {\n                                input: Box::new(LogicalPlan::Filter {\n                                    input: proj_input,\n                                    predicate,\n                                }),\n                                expressions,\n                            }\n                        } else {\n                            // Can't push, keep original\n                            LogicalPlan::Filter {\n                                input: Box::new(LogicalPlan::Project {\n                                    input: proj_input,\n                                    expressions,\n                                }),\n                                predicate,\n                            }\n                        }\n                    }\n\n                    // Push filter past traverse (for source-side predicates)\n                    LogicalPlan::Traverse { input, edge_type, direction, src_alias, dst_alias, edge_alias } =&gt; {\n                        let (src_predicates, other_predicates) = split_predicates(&amp;predicate, &amp;src_alias);\n\n                        let new_input = if !src_predicates.is_empty() {\n                            Box::new(LogicalPlan::Filter {\n                                input,\n                                predicate: conjoin(src_predicates),\n                            })\n                        } else {\n                            input\n                        };\n\n                        let traverse = LogicalPlan::Traverse {\n                            input: new_input,\n                            edge_type, direction, src_alias, dst_alias, edge_alias,\n                        };\n\n                        if !other_predicates.is_empty() {\n                            LogicalPlan::Filter {\n                                input: Box::new(traverse),\n                                predicate: conjoin(other_predicates),\n                            }\n                        } else {\n                            traverse\n                        }\n                    }\n\n                    _ =&gt; LogicalPlan::Filter { input, predicate }\n                }\n            }\n            _ =&gt; plan\n        }\n    }\n}\n</code></pre> <p>Before: <pre><code>Filter(p.year &gt; 2020 AND cited.venue = 'NeurIPS')\n  \u2514\u2500\u2500 Traverse(CITES, p \u2192 cited)\n        \u2514\u2500\u2500 Scan(:Paper AS p)\n</code></pre></p> <p>After: <pre><code>Filter(cited.venue = 'NeurIPS')\n  \u2514\u2500\u2500 Traverse(CITES, p \u2192 cited)\n        \u2514\u2500\u2500 Filter(p.year &gt; 2020)\n              \u2514\u2500\u2500 Scan(:Paper AS p)\n</code></pre></p>"},{"location":"internals/query-planning/#rule-2-projection-pushdown","title":"Rule 2: Projection Pushdown","text":"<p>Only load columns that are actually used:</p> <pre><code>pub struct ProjectionPushdown;\n\nimpl OptimizationRule for ProjectionPushdown {\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        // Collect all referenced columns\n        let required_columns = collect_required_columns(&amp;plan);\n\n        // Push minimal projections to scans\n        self.push_projections(plan, &amp;required_columns)\n    }\n\n    fn push_projections(&amp;self, plan: LogicalPlan, required: &amp;HashSet&lt;Column&gt;) -&gt; LogicalPlan {\n        match plan {\n            LogicalPlan::Scan { label_id, alias, filter } =&gt; {\n                // Only scan required columns + filter columns\n                let scan_columns: Vec&lt;String&gt; = required\n                    .iter()\n                    .filter(|c| c.table == alias)\n                    .map(|c| c.column.clone())\n                    .collect();\n\n                LogicalPlan::Scan {\n                    label_id,\n                    alias,\n                    filter,\n                    columns: Some(scan_columns),  // Add projection\n                }\n            }\n            // ... recurse through other operators\n            _ =&gt; plan\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#rule-3-scan-to-index","title":"Rule 3: Scan-to-Index","text":"<p>Replace scans with index lookups when possible:</p> <pre><code>pub struct ScanToIndex {\n    index_catalog: Arc&lt;IndexCatalog&gt;,\n}\n\nimpl OptimizationRule for ScanToIndex {\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        match plan {\n            LogicalPlan::Filter { input, predicate } =&gt; {\n                if let LogicalPlan::Scan { label_id, alias, .. } = *input {\n                    // Check if predicate can use an index\n                    if let Some(index) = self.find_applicable_index(label_id, &amp;predicate) {\n                        return LogicalPlan::IndexScan {\n                            label_id,\n                            alias,\n                            index_id: index.id,\n                            bounds: self.extract_bounds(&amp;predicate, &amp;index),\n                        };\n                    }\n                }\n\n                LogicalPlan::Filter { input, predicate }\n            }\n            _ =&gt; plan\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#rule-4-limit-pushdown","title":"Rule 4: Limit Pushdown","text":"<p>Push LIMIT to reduce work early:</p> <pre><code>pub struct LimitPushdown;\n\nimpl OptimizationRule for LimitPushdown {\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        match plan {\n            // Push limit past filter (filter doesn't increase rows)\n            LogicalPlan::Limit { input, skip, limit } =&gt; {\n                match *input {\n                    LogicalPlan::Filter { input: filter_input, predicate } =&gt; {\n                        LogicalPlan::Filter {\n                            input: Box::new(LogicalPlan::Limit {\n                                input: filter_input,\n                                skip,\n                                limit: limit.map(|l| l * 2), // Over-fetch for safety\n                            }),\n                            predicate,\n                        }\n                    }\n                    _ =&gt; LogicalPlan::Limit { input, skip, limit }\n                }\n            }\n            _ =&gt; plan\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#rule-5-join-reordering","title":"Rule 5: Join Reordering","text":"<p>For multiple MATCH patterns, choose optimal join order:</p> <pre><code>pub struct JoinReorder;\n\nimpl OptimizationRule for JoinReorder {\n    fn apply(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        match plan {\n            LogicalPlan::CrossProduct { left, right } =&gt; {\n                // Estimate cardinalities\n                let left_card = self.estimate_cardinality(&amp;left);\n                let right_card = self.estimate_cardinality(&amp;right);\n\n                // Smaller relation on left (build side for hash join)\n                if left_card &gt; right_card {\n                    LogicalPlan::CrossProduct {\n                        left: right,\n                        right: left,\n                    }\n                } else {\n                    LogicalPlan::CrossProduct { left, right }\n                }\n            }\n            _ =&gt; plan\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#optimizer-pipeline","title":"Optimizer Pipeline","text":"<pre><code>pub struct QueryOptimizer {\n    rules: Vec&lt;Box&lt;dyn OptimizationRule&gt;&gt;,\n}\n\nimpl QueryOptimizer {\n    pub fn new() -&gt; Self {\n        Self {\n            rules: vec![\n                Box::new(PredicatePushdown),\n                Box::new(ProjectionPushdown),\n                Box::new(ScanToIndex::new()),\n                Box::new(LimitPushdown),\n                Box::new(JoinReorder),\n            ],\n        }\n    }\n\n    pub fn optimize(&amp;self, plan: LogicalPlan) -&gt; LogicalPlan {\n        let mut current = plan;\n\n        // Fixed-point iteration\n        loop {\n            let mut changed = false;\n\n            for rule in &amp;self.rules {\n                let new_plan = self.apply_rule_recursive(rule.as_ref(), current.clone());\n                if new_plan != current {\n                    changed = true;\n                    current = new_plan;\n                }\n            }\n\n            if !changed {\n                break;\n            }\n        }\n\n        current\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#phase-5-physical-planning","title":"Phase 5: Physical Planning","text":"<p>Convert logical operators to physical operators with specific algorithms.</p>"},{"location":"internals/query-planning/#physical-operators","title":"Physical Operators","text":"<pre><code>pub enum PhysicalPlan {\n    /// Scan from Lance with pushdown\n    LanceScan {\n        dataset_id: DatasetId,\n        projection: Vec&lt;String&gt;,\n        filter: Option&lt;LanceFilter&gt;,\n        batch_size: usize,\n    },\n\n    /// Index-based scan\n    IndexScan {\n        index_id: IndexId,\n        bounds: IndexBounds,\n        projection: Vec&lt;String&gt;,\n    },\n\n    /// Vector similarity search\n    VectorScan {\n        index_id: IndexId,\n        query_vector: Vec&lt;f32&gt;,\n        k: usize,\n        ef_search: usize,\n    },\n\n    /// Traverse using adjacency cache\n    CsrTraverse {\n        input: Box&lt;PhysicalPlan&gt;,\n        edge_type: EdgeTypeId,\n        direction: Direction,\n        cache: Arc&lt;AdjacencyCache&gt;,\n    },\n\n    /// Filter with vectorized predicate\n    VectorizedFilter {\n        input: Box&lt;PhysicalPlan&gt;,\n        predicate: PhysicalExpr,\n    },\n\n    /// Hash-based aggregation\n    HashAggregate {\n        input: Box&lt;PhysicalPlan&gt;,\n        group_by: Vec&lt;PhysicalExpr&gt;,\n        aggregates: Vec&lt;PhysicalAggregateExpr&gt;,\n    },\n\n    /// External merge sort\n    MergeSort {\n        input: Box&lt;PhysicalPlan&gt;,\n        order_by: Vec&lt;(PhysicalExpr, SortOrder)&gt;,\n        memory_limit: usize,\n    },\n\n    /// Stream limit\n    StreamLimit {\n        input: Box&lt;PhysicalPlan&gt;,\n        skip: usize,\n        limit: usize,\n    },\n\n    /// Late property materialization\n    LateMaterialize {\n        input: Box&lt;PhysicalPlan&gt;,\n        columns: Vec&lt;String&gt;,\n        prop_manager: Arc&lt;PropertyManager&gt;,\n    },\n\n    /// Exchange for parallelism\n    Exchange {\n        input: Box&lt;PhysicalPlan&gt;,\n        partitioning: Partitioning,\n    },\n}\n</code></pre>"},{"location":"internals/query-planning/#physical-planning-decisions","title":"Physical Planning Decisions","text":"<pre><code>pub struct PhysicalPlanner {\n    storage: Arc&lt;StorageManager&gt;,\n    config: PlannerConfig,\n}\n\nimpl PhysicalPlanner {\n    pub fn plan(&amp;self, logical: LogicalPlan) -&gt; PhysicalPlan {\n        match logical {\n            LogicalPlan::Scan { label_id, alias, filter, columns } =&gt; {\n                let dataset_id = self.storage.dataset_for_label(label_id);\n\n                // Decide: full scan vs index scan\n                if let Some(index) = self.find_best_index(&amp;filter) {\n                    PhysicalPlan::IndexScan {\n                        index_id: index.id,\n                        bounds: self.extract_bounds(&amp;filter, &amp;index),\n                        projection: columns.unwrap_or_default(),\n                    }\n                } else {\n                    PhysicalPlan::LanceScan {\n                        dataset_id,\n                        projection: columns.unwrap_or_default(),\n                        filter: filter.map(|f| self.to_lance_filter(f)),\n                        batch_size: self.config.batch_size,\n                    }\n                }\n            }\n\n            LogicalPlan::Traverse { input, edge_type, direction, .. } =&gt; {\n                PhysicalPlan::CsrTraverse {\n                    input: Box::new(self.plan(*input)),\n                    edge_type,\n                    direction,\n                    cache: self.storage.adjacency_cache(),\n                }\n            }\n\n            LogicalPlan::Aggregate { input, group_by, aggregates } =&gt; {\n                // Estimate input cardinality for algorithm selection\n                let input_card = self.estimate_cardinality(&amp;input);\n                let group_card = self.estimate_group_cardinality(&amp;group_by, input_card);\n\n                if group_card &lt; self.config.hash_agg_threshold {\n                    // In-memory hash aggregation\n                    PhysicalPlan::HashAggregate {\n                        input: Box::new(self.plan(*input)),\n                        group_by: group_by.into_iter().map(|e| self.to_physical(e)).collect(),\n                        aggregates: aggregates.into_iter().map(|a| self.to_physical_agg(a)).collect(),\n                    }\n                } else {\n                    // Sort-based aggregation for large groups\n                    PhysicalPlan::SortAggregate {\n                        input: Box::new(PhysicalPlan::MergeSort {\n                            input: Box::new(self.plan(*input)),\n                            order_by: group_by.iter().map(|e| (self.to_physical(e.clone()), SortOrder::Asc)).collect(),\n                            memory_limit: self.config.sort_memory_limit,\n                        }),\n                        group_by: group_by.into_iter().map(|e| self.to_physical(e)).collect(),\n                        aggregates: aggregates.into_iter().map(|a| self.to_physical_agg(a)).collect(),\n                    }\n                }\n            }\n\n            LogicalPlan::Sort { input, order_by } =&gt; {\n                let input_plan = self.plan(*input);\n\n                // Check if input is already sorted\n                if self.is_sorted(&amp;input_plan, &amp;order_by) {\n                    input_plan\n                } else {\n                    PhysicalPlan::MergeSort {\n                        input: Box::new(input_plan),\n                        order_by: order_by.into_iter()\n                            .map(|(e, ord)| (self.to_physical(e), ord))\n                            .collect(),\n                        memory_limit: self.config.sort_memory_limit,\n                    }\n                }\n            }\n\n            // ... other operators\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#cost-estimation","title":"Cost Estimation","text":"<p>The optimizer uses cost estimates to choose between plans.</p>"},{"location":"internals/query-planning/#statistics","title":"Statistics","text":"<pre><code>pub struct TableStatistics {\n    /// Total row count\n    pub row_count: u64,\n\n    /// Size in bytes\n    pub size_bytes: u64,\n\n    /// Per-column statistics\n    pub column_stats: HashMap&lt;String, ColumnStatistics&gt;,\n}\n\npub struct ColumnStatistics {\n    /// Distinct value count\n    pub distinct_count: u64,\n\n    /// Null count\n    pub null_count: u64,\n\n    /// Min/max values (if orderable)\n    pub min: Option&lt;ScalarValue&gt;,\n    pub max: Option&lt;ScalarValue&gt;,\n\n    /// Histogram buckets (optional)\n    pub histogram: Option&lt;Histogram&gt;,\n}\n</code></pre>"},{"location":"internals/query-planning/#cost-model","title":"Cost Model","text":"<pre><code>pub struct CostEstimator {\n    stats_cache: Arc&lt;StatisticsCache&gt;,\n}\n\nimpl CostEstimator {\n    pub fn estimate_cost(&amp;self, plan: &amp;LogicalPlan) -&gt; Cost {\n        match plan {\n            LogicalPlan::Scan { label_id, filter, .. } =&gt; {\n                let stats = self.stats_cache.get_table_stats(*label_id);\n                let selectivity = filter\n                    .as_ref()\n                    .map(|f| self.estimate_selectivity(f, &amp;stats))\n                    .unwrap_or(1.0);\n\n                Cost {\n                    rows: (stats.row_count as f64 * selectivity) as u64,\n                    cpu: stats.row_count,  // CPU cost proportional to rows scanned\n                    io: stats.size_bytes,  // I/O cost = bytes read\n                }\n            }\n\n            LogicalPlan::IndexScan { index_id, bounds, .. } =&gt; {\n                let index_stats = self.stats_cache.get_index_stats(*index_id);\n                let selectivity = self.estimate_range_selectivity(bounds, &amp;index_stats);\n\n                Cost {\n                    rows: (index_stats.total_rows as f64 * selectivity) as u64,\n                    cpu: 100,  // Index lookup is cheap\n                    io: 1000,  // Small I/O for index\n                }\n            }\n\n            LogicalPlan::Traverse { input, edge_type, .. } =&gt; {\n                let input_cost = self.estimate_cost(input);\n                let avg_degree = self.stats_cache.get_avg_degree(*edge_type);\n\n                Cost {\n                    rows: input_cost.rows * avg_degree as u64,\n                    cpu: input_cost.cpu + input_cost.rows * 10,  // Adjacency lookup\n                    io: input_cost.io,  // Adjacency is cached\n                }\n            }\n\n            LogicalPlan::HashAggregate { input, group_by, .. } =&gt; {\n                let input_cost = self.estimate_cost(input);\n                let group_card = self.estimate_group_cardinality(group_by, input_cost.rows);\n\n                Cost {\n                    rows: group_card,\n                    cpu: input_cost.cpu + input_cost.rows * 50,  // Hash + aggregate\n                    io: input_cost.io,\n                }\n            }\n\n            // ... other operators\n        }\n    }\n\n    fn estimate_selectivity(&amp;self, predicate: &amp;LogicalExpr, stats: &amp;TableStatistics) -&gt; f64 {\n        match predicate {\n            LogicalExpr::Comparison { left, op, right } =&gt; {\n                if let LogicalExpr::Column(col) = left.as_ref() {\n                    if let Some(col_stats) = stats.column_stats.get(col) {\n                        match op {\n                            Op::Eq =&gt; 1.0 / col_stats.distinct_count as f64,\n                            Op::Lt | Op::Gt =&gt; 0.3,  // Assume 30% selectivity\n                            Op::Lte | Op::Gte =&gt; 0.33,\n                            Op::Neq =&gt; 1.0 - (1.0 / col_stats.distinct_count as f64),\n                        }\n                    } else {\n                        0.5  // Default\n                    }\n                } else {\n                    0.5\n                }\n            }\n\n            LogicalExpr::And(left, right) =&gt; {\n                self.estimate_selectivity(left, stats) * self.estimate_selectivity(right, stats)\n            }\n\n            LogicalExpr::Or(left, right) =&gt; {\n                let s1 = self.estimate_selectivity(left, stats);\n                let s2 = self.estimate_selectivity(right, stats);\n                s1 + s2 - (s1 * s2)  // Union formula\n            }\n\n            _ =&gt; 0.5\n        }\n    }\n}\n</code></pre>"},{"location":"internals/query-planning/#explain-output","title":"EXPLAIN Output","text":"<p>Use EXPLAIN to view query plans:</p> <pre><code>uni query \"EXPLAIN MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN p.title\" --path ./storage\n</code></pre> <p>Output: <pre><code>Query Plan:\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n\nLogical Plan:\n\u251c\u2500\u2500 Project [p.title]\n\u2502     \u2514\u2500\u2500 Filter [p.year &gt; 2020]\n\u2502           \u2514\u2500\u2500 Scan [:Paper AS p]\n\nPhysical Plan:\n\u251c\u2500\u2500 VectorizedProject [p.title]\n\u2502     \u2514\u2500\u2500 LateMaterialize [title]\n\u2502           \u2514\u2500\u2500 LanceScan [:Paper]\n\u2502                 \u251c\u2500\u2500 Projection: [_vid, year]\n\u2502                 \u251c\u2500\u2500 Pushdown: year &gt; 2020\n\u2502                 \u2514\u2500\u2500 Index: paper_year (BTree)\n\nStatistics:\n\u251c\u2500\u2500 Estimated rows: 5,000 (50% selectivity)\n\u251c\u2500\u2500 Estimated I/O: 2.5 MB\n\u2514\u2500\u2500 Index usage: paper_year\n\n\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\n</code></pre></p>"},{"location":"internals/query-planning/#configuration","title":"Configuration","text":"<pre><code>pub struct PlannerConfig {\n    /// Batch size for vectorized execution\n    pub batch_size: usize,  // Default: 4096\n\n    /// Memory limit for sort operators\n    pub sort_memory_limit: usize,  // Default: 256 MB\n\n    /// Threshold for hash vs sort aggregation\n    pub hash_agg_threshold: u64,  // Default: 1_000_000\n\n    /// Enable predicate pushdown\n    pub enable_pushdown: bool,  // Default: true\n\n    /// Enable late materialization\n    pub enable_late_materialize: bool,  // Default: true\n\n    /// Maximum optimization iterations\n    pub max_optimization_rounds: usize,  // Default: 10\n}\n</code></pre>"},{"location":"internals/query-planning/#next-steps","title":"Next Steps","text":"<ul> <li>Vectorized Execution \u2014 How physical plans execute</li> <li>Storage Engine \u2014 Data persistence layer</li> <li>Benchmarks \u2014 Query performance measurements</li> </ul>"},{"location":"internals/storage-engine/","title":"Storage Engine Internals","text":"<p>Uni's storage engine is architected for high-throughput ingestion and low-latency analytics, leveraging a tiered LSM-tree-like structure backed by Lance columnar format. This design enables both OLTP-style writes and OLAP-style analytical queries on the same data.</p>"},{"location":"internals/storage-engine/#architecture-overview","title":"Architecture Overview","text":"flowchart TB     Writes[\"Writes\"]      subgraph L0[\"L0: Memory\"]         gryf[\"gryf&lt;br/&gt;(graph)\"]         WAL[\"WAL&lt;br/&gt;(log)\"]         PropBuf[\"Property Buffer&lt;br/&gt;(columnar)\"]     end      subgraph L1[\"L1: Sorted Runs\"]         Run1[\"Run 1&lt;br/&gt;(Lance)\"]         Run2[\"Run 2&lt;br/&gt;(Lance)\"]         Run3[\"Run 3&lt;br/&gt;(Lance)\"]         Run4[\"Run 4&lt;br/&gt;(Lance)\"]     end      subgraph L2[\"L2: Base Layer\"]         Compacted[\"Compacted Lance Dataset&lt;br/&gt;\u2022 Full indexes (Vector, Scalar)&lt;br/&gt;\u2022 Optimized row groups&lt;br/&gt;\u2022 Statistics per column\"]     end      Reads[\"Reads \u2192 Merge View:&lt;br/&gt;L0 \u222a L1 \u222a L2&lt;br/&gt;(VID-based deduplication)\"]      Writes --&gt; L0     L0 --&gt;|flush| L1     L1 --&gt;|compact| L2     L2 --&gt; Reads"},{"location":"internals/storage-engine/#tiered-storage-model","title":"Tiered Storage Model","text":""},{"location":"internals/storage-engine/#l0-memory-buffer","title":"L0: Memory Buffer","text":"<p>The L0 layer handles all incoming writes with maximum throughput.</p> <pre><code>pub struct L0Buffer {\n    /// In-memory graph structure (vertices + edges)\n    graph: gryf::Graph&lt;VertexData, EdgeData&gt;,\n\n    /// Property storage (columnar)\n    properties: HashMap&lt;LabelId, ArrowPropertyBuffer&gt;,\n\n    /// Write-ahead log reference\n    wal: Arc&lt;Wal&gt;,\n\n    /// Mutation counter for flush triggering\n    mutation_count: AtomicUsize,\n\n    /// Size estimate in bytes\n    estimated_size: AtomicUsize,\n}\n\npub struct ArrowPropertyBuffer {\n    /// Schema for this label's properties\n    schema: Arc&lt;Schema&gt;,\n\n    /// Column builders (one per property)\n    builders: Vec&lt;Box&lt;dyn ArrayBuilder&gt;&gt;,\n\n    /// VID to row index mapping\n    vid_to_row: HashMap&lt;Vid, usize&gt;,\n}\n</code></pre> <p>Characteristics:</p> Property Value Notes Format gryf + Arrow builders Row-oriented for inserts Durability WAL-backed Survives crashes Latency ~550\u00b5s per 1K writes Memory-speed Capacity Configurable (default 128MB) Auto-flush when full <p>Write Path:</p> <pre><code>1. Acquire write lock (single-writer)\n2. Append to WAL (sync or async based on config)\n3. Insert into gryf graph (vertex/edge)\n4. Append properties to Arrow builders\n5. Increment mutation counter\n6. If threshold reached \u2192 trigger async flush\n</code></pre>"},{"location":"internals/storage-engine/#l1-sorted-runs","title":"L1: Sorted Runs","text":"<p>When L0 fills up, it flushes to L1 as an immutable Lance dataset.</p> <pre><code>pub struct L1Run {\n    /// Lance dataset for this run\n    dataset: Dataset,\n\n    /// VID range covered\n    vid_range: Range&lt;Vid&gt;,\n\n    /// Creation timestamp\n    created_at: Timestamp,\n\n    /// Run sequence number\n    sequence: u64,\n}\n\npub struct L1Manager {\n    /// Active runs (newest first)\n    runs: Vec&lt;L1Run&gt;,\n\n    /// Maximum runs before compaction\n    max_runs: usize,\n\n    /// Compaction threshold (bytes)\n    compaction_threshold: usize,\n}\n</code></pre> <p>Flush Process:</p> flowchart TB     S1[\"1. SNAPSHOT L0&lt;br/&gt;Create consistent snapshot&lt;br/&gt;of graph + properties\"]     S2[\"2. CONVERT TO COLUMNAR&lt;br/&gt;\u2022 Sort vertices by VID&lt;br/&gt;\u2022 Build Arrow RecordBatches&lt;br/&gt;\u2022 Compute column statistics\"]     S3[\"3. WRITE LANCE DATASET&lt;br/&gt;\u2022 Write vertex dataset (per label)&lt;br/&gt;\u2022 Write edge dataset (per type)&lt;br/&gt;\u2022 Write adjacency dataset\"]     S4[\"4. UPDATE MANIFEST&lt;br/&gt;Add new L1 run to manifest\"]     S5[\"5. CLEAR L0&lt;br/&gt;\u2022 Truncate WAL&lt;br/&gt;\u2022 Reset in-memory buffers\"]      S1 --&gt; S2 --&gt; S3 --&gt; S4 --&gt; S5"},{"location":"internals/storage-engine/#l2-base-layer","title":"L2: Base Layer","text":"<p>The L2 layer contains fully compacted, indexed data.</p> <pre><code>pub struct L2Layer {\n    /// Main vertex dataset (per label)\n    vertex_datasets: HashMap&lt;LabelId, Dataset&gt;,\n\n    /// Main edge dataset (per type)\n    edge_datasets: HashMap&lt;EdgeTypeId, Dataset&gt;,\n\n    /// Adjacency datasets (per edge type + direction)\n    adjacency_datasets: HashMap&lt;(EdgeTypeId, Direction), Dataset&gt;,\n\n    /// Vector indexes\n    vector_indexes: HashMap&lt;IndexId, VectorIndex&gt;,\n\n    /// Scalar indexes\n    scalar_indexes: HashMap&lt;IndexId, ScalarIndex&gt;,\n}\n</code></pre> <p>Compaction Process:</p> flowchart TB     C1[\"1. SELECT RUNS&lt;br/&gt;Choose L1 runs for compaction&lt;br/&gt;(size/age based)\"]     C2[\"2. MERGE-SORT&lt;br/&gt;\u2022 Open all selected runs&lt;br/&gt;\u2022 Merge by VID (newest wins)&lt;br/&gt;\u2022 Apply tombstones\"]     C3[\"3. REBUILD INDEXES&lt;br/&gt;\u2022 Vector index: Rebuild HNSW/IVF_PQ&lt;br/&gt;\u2022 Scalar indexes: Rebuild B-tree/Hash&lt;br/&gt;\u2022 Compute new statistics\"]     C4[\"4. WRITE NEW L2&lt;br/&gt;Write as single optimized&lt;br/&gt;Lance dataset\"]     C5[\"5. CLEANUP&lt;br/&gt;Delete compacted L1 runs\"]      C1 --&gt; C2 --&gt; C3 --&gt; C4 --&gt; C5"},{"location":"internals/storage-engine/#lance-integration","title":"Lance Integration","text":"<p>Uni uses Lance as its core columnar format.</p>"},{"location":"internals/storage-engine/#why-lance","title":"Why Lance?","text":"Feature Benefit Native Vector Support Built-in HNSW, IVF_PQ indexes Versioning Time-travel, ACID transactions Fast Random Access O(1) row lookup by index Columnar Scans Efficient analytical queries Object Store Native S3/GCS support built-in Zero-Copy Arrow-compatible memory layout"},{"location":"internals/storage-engine/#lance-file-format","title":"Lance File Format","text":"<pre><code>Lance Dataset Structure:\n\ndata/\n\u251c\u2500\u2500 _versions/                    # Version metadata\n\u2502   \u251c\u2500\u2500 1.manifest               # Version 1 manifest\n\u2502   \u251c\u2500\u2500 2.manifest               # Version 2 manifest\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 _indices/                     # Index data\n\u2502   \u251c\u2500\u2500 vector_idx_001/          # Vector index\n\u2502   \u2502   \u251c\u2500\u2500 index.idx\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 scalar_idx_002/          # Scalar index\n\u2514\u2500\u2500 data/                         # Column data\n    \u251c\u2500\u2500 part-0.lance              # Data fragment\n    \u251c\u2500\u2500 part-1.lance\n    \u2514\u2500\u2500 ...\n</code></pre>"},{"location":"internals/storage-engine/#data-fragment-structure","title":"Data Fragment Structure","text":"<pre><code>pub struct LanceFragment {\n    /// Fragment ID\n    id: u64,\n\n    /// Row range in this fragment\n    row_range: Range&lt;u64&gt;,\n\n    /// Physical files for each column\n    columns: HashMap&lt;String, ColumnFiles&gt;,\n\n    /// Fragment-level statistics\n    stats: FragmentStatistics,\n}\n\npub struct FragmentStatistics {\n    /// Row count\n    num_rows: u64,\n\n    /// Per-column statistics\n    column_stats: HashMap&lt;String, ColumnStats&gt;,\n}\n\npub struct ColumnStats {\n    null_count: u64,\n    min_value: Option&lt;ScalarValue&gt;,\n    max_value: Option&lt;ScalarValue&gt;,\n    distinct_count: Option&lt;u64&gt;,\n}\n</code></pre>"},{"location":"internals/storage-engine/#dataset-organization","title":"Dataset Organization","text":""},{"location":"internals/storage-engine/#vertex-datasets","title":"Vertex Datasets","text":"<p>One Lance dataset per vertex label:</p> <pre><code>storage/\n\u251c\u2500\u2500 vertices/\n\u2502   \u251c\u2500\u2500 Paper/                    # :Paper vertices\n\u2502   \u2502   \u251c\u2500\u2500 _versions/\n\u2502   \u2502   \u251c\u2500\u2500 _indices/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 embedding_hnsw/   # Vector index\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 year_btree/       # Scalar index\n\u2502   \u2502   \u2514\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 Author/                   # :Author vertices\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 Venue/                    # :Venue vertices\n\u2502       \u2514\u2500\u2500 ...\n</code></pre> <p>Vertex Schema:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                           VERTEX DATASET SCHEMA                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   System Columns:                                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 Column   \u2502 Type     \u2502 Description                                    \u2502 \u2502\n\u2502   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502   \u2502 _vid     \u2502 UInt64   \u2502 Internal vertex ID (label &lt;&lt; 48 | offset)     \u2502 \u2502\n\u2502   \u2502 _uid     \u2502 Binary   \u2502 UniId (32-byte SHA3-256) - optional        \u2502 \u2502\n\u2502   \u2502 _ext_id  \u2502 String   \u2502 External ID from source system                \u2502 \u2502\n\u2502   \u2502 _deleted \u2502 Bool     \u2502 Tombstone marker (soft delete)                \u2502 \u2502\n\u2502   \u2502 _version \u2502 UInt64   \u2502 Last modified version                         \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2502   User Properties (schema-defined):                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 title    \u2502 String   \u2502 Paper title                                    \u2502 \u2502\n\u2502   \u2502 year     \u2502 Int32    \u2502 Publication year                               \u2502 \u2502\n\u2502   \u2502 abstract \u2502 String   \u2502 Paper abstract (nullable)                      \u2502 \u2502\n\u2502   \u2502 embedding\u2502 Vector   \u2502 768-dimensional embedding                      \u2502 \u2502\n\u2502   \u2502 _doc     \u2502 Json     \u2502 Document mode flexible fields                  \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/storage-engine/#edge-datasets","title":"Edge Datasets","text":"<p>One Lance dataset per edge type:</p> <pre><code>storage/\n\u251c\u2500\u2500 edges/\n\u2502   \u251c\u2500\u2500 CITES/                    # :CITES edges\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 AUTHORED_BY/              # :AUTHORED_BY edges\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 PUBLISHED_IN/\n\u2502       \u2514\u2500\u2500 ...\n</code></pre> <p>Edge Schema:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            EDGE DATASET SCHEMA                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   System Columns:                                                           \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 Column   \u2502 Type     \u2502 Description                                    \u2502 \u2502\n\u2502   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502\n\u2502   \u2502 _eid     \u2502 UInt64   \u2502 Internal edge ID (type &lt;&lt; 48 | offset)        \u2502 \u2502\n\u2502   \u2502 _src_vid \u2502 UInt64   \u2502 Source vertex VID                              \u2502 \u2502\n\u2502   \u2502 _dst_vid \u2502 UInt64   \u2502 Destination vertex VID                         \u2502 \u2502\n\u2502   \u2502 _deleted \u2502 Bool     \u2502 Tombstone marker                               \u2502 \u2502\n\u2502   \u2502 _version \u2502 UInt64   \u2502 Last modified version                          \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2502   Edge Properties (schema-defined):                                         \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 weight   \u2502 Float64  \u2502 Edge weight/score                              \u2502 \u2502\n\u2502   \u2502 position \u2502 Int32    \u2502 Author position (for AUTHORED_BY)              \u2502 \u2502\n\u2502   \u2502 timestamp\u2502 Timestamp\u2502 When the edge was created                      \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/storage-engine/#adjacency-datasets","title":"Adjacency Datasets","text":"<p>Optimized for graph traversal (CSR-style):</p> <pre><code>storage/\n\u251c\u2500\u2500 adjacency/\n\u2502   \u251c\u2500\u2500 CITES_OUT/                # Outgoing CITES edges\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 CITES_IN/                 # Incoming CITES edges (reverse)\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2514\u2500\u2500 ...\n</code></pre> <p>Adjacency Schema:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         ADJACENCY DATASET SCHEMA                             \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Chunked CSR Format (one row per chunk of vertices):                       \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502   \u2502 Column      \u2502 Type         \u2502 Description                            \u2502  \u2502\n\u2502   \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  \u2502\n\u2502   \u2502 chunk_id    \u2502 UInt64       \u2502 Chunk identifier                       \u2502  \u2502\n\u2502   \u2502 vid_start   \u2502 UInt64       \u2502 First VID in chunk                     \u2502  \u2502\n\u2502   \u2502 vid_end     \u2502 UInt64       \u2502 Last VID in chunk (exclusive)          \u2502  \u2502\n\u2502   \u2502 offsets     \u2502 List&lt;UInt64&gt; \u2502 CSR offsets (chunk_size + 1 elements)  \u2502  \u2502\n\u2502   \u2502 neighbors   \u2502 List&lt;UInt64&gt; \u2502 Neighbor VIDs (flattened)              \u2502  \u2502\n\u2502   \u2502 edge_ids    \u2502 List&lt;UInt64&gt; \u2502 Edge IDs (parallel to neighbors)       \u2502  \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                                             \u2502\n\u2502   Example (chunk_size=1000):                                                \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502 chunk_id: 0                                                         \u2502   \u2502\n\u2502   \u2502 vid_start: 0, vid_end: 1000                                         \u2502   \u2502\n\u2502   \u2502 offsets: [0, 3, 3, 7, 10, ...]  (1001 elements)                     \u2502   \u2502\n\u2502   \u2502 neighbors: [v5, v12, v99, v4, v6, v8, v42, ...]                     \u2502   \u2502\n\u2502   \u2502 edge_ids: [e1, e2, e3, e4, e5, e6, e7, ...]                         \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/storage-engine/#write-ahead-log-wal","title":"Write-Ahead Log (WAL)","text":"<p>The WAL ensures durability for uncommitted L0 data.</p>"},{"location":"internals/storage-engine/#wal-structure","title":"WAL Structure","text":"<pre><code>pub struct Wal {\n    /// Active segment being written\n    active_segment: Mutex&lt;WalSegment&gt;,\n\n    /// Completed segments awaiting flush\n    sealed_segments: Vec&lt;WalSegment&gt;,\n\n    /// Configuration\n    config: WalConfig,\n}\n\npub struct WalSegment {\n    /// Segment file\n    file: File,\n\n    /// Segment sequence number\n    sequence: u64,\n\n    /// Current size\n    size: usize,\n}\n\npub struct WalConfig {\n    /// Segment size before rotation\n    max_segment_size: usize,  // Default: 64 MB\n\n    /// Sync mode\n    sync_mode: WalSyncMode,\n\n    /// Directory for WAL files\n    wal_dir: PathBuf,\n}\n\npub enum WalSyncMode {\n    /// fsync after every write (safest, slowest)\n    Sync,\n\n    /// fsync periodically (balanced)\n    Periodic { interval_ms: u64 },\n\n    /// OS-managed sync (fastest, risk of data loss)\n    Async,\n}\n</code></pre>"},{"location":"internals/storage-engine/#wal-entry-format","title":"WAL Entry Format","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                            WAL ENTRY FORMAT                                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502   \u2502  Length  \u2502   CRC    \u2502   Type   \u2502  Flags   \u2502        Payload         \u2502   \u2502\n\u2502   \u2502  4 bytes \u2502  4 bytes \u2502  1 byte  \u2502  1 byte  \u2502      variable          \u2502   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2502                                                                             \u2502\n\u2502   Entry Types:                                                              \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502   \u2502 0x01     \u2502 InsertVertex { vid, label_id, properties }                \u2502 \u2502\n\u2502   \u2502 0x02     \u2502 InsertEdge { eid, src_vid, dst_vid, type_id, properties } \u2502 \u2502\n\u2502   \u2502 0x03     \u2502 DeleteVertex { vid }                                      \u2502 \u2502\n\u2502   \u2502 0x04     \u2502 DeleteEdge { eid }                                        \u2502 \u2502\n\u2502   \u2502 0x05     \u2502 UpdateProperties { vid, properties }                      \u2502 \u2502\n\u2502   \u2502 0xFF     \u2502 Checkpoint { sequence, timestamp }                        \u2502 \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/storage-engine/#recovery-process","title":"Recovery Process","text":"<pre><code>impl Wal {\n    pub async fn recover(&amp;self, l0: &amp;mut L0Buffer) -&gt; Result&lt;()&gt; {\n        // Find all WAL segments\n        let segments = self.list_segments()?;\n\n        for segment in segments {\n            let reader = WalReader::open(&amp;segment)?;\n\n            while let Some(entry) = reader.next_entry()? {\n                // Verify CRC\n                if !entry.verify_crc() {\n                    // Truncate at corruption point\n                    break;\n                }\n\n                // Replay entry\n                match entry.entry_type {\n                    EntryType::InsertVertex { vid, label_id, props } =&gt; {\n                        l0.insert_vertex(vid, label_id, props)?;\n                    }\n                    EntryType::InsertEdge { eid, src, dst, type_id, props } =&gt; {\n                        l0.insert_edge(eid, src, dst, type_id, props)?;\n                    }\n                    // ... handle other types\n                }\n            }\n        }\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#snapshot-management","title":"Snapshot Management","text":"<p>Snapshots provide consistent point-in-time views.</p>"},{"location":"internals/storage-engine/#manifest-structure","title":"Manifest Structure","text":"<pre><code>{\n  \"version\": 42,\n  \"timestamp\": \"2024-01-15T10:30:00Z\",\n  \"schema_version\": 1,\n\n  \"vertex_datasets\": {\n    \"Paper\": {\n      \"lance_version\": 15,\n      \"row_count\": 1000000,\n      \"size_bytes\": 524288000\n    },\n    \"Author\": {\n      \"lance_version\": 8,\n      \"row_count\": 250000,\n      \"size_bytes\": 62500000\n    }\n  },\n\n  \"edge_datasets\": {\n    \"CITES\": {\n      \"lance_version\": 12,\n      \"row_count\": 5000000,\n      \"size_bytes\": 200000000\n    }\n  },\n\n  \"adjacency_datasets\": {\n    \"CITES_OUT\": { \"lance_version\": 12 },\n    \"CITES_IN\": { \"lance_version\": 12 }\n  },\n\n  \"l1_runs\": [\n    { \"sequence\": 100, \"created_at\": \"2024-01-15T10:25:00Z\" },\n    { \"sequence\": 101, \"created_at\": \"2024-01-15T10:28:00Z\" }\n  ],\n\n  \"indexes\": {\n    \"paper_embeddings\": {\n      \"type\": \"hnsw\",\n      \"version\": 5,\n      \"row_count\": 1000000\n    },\n    \"paper_year\": {\n      \"type\": \"btree\",\n      \"version\": 3\n    }\n  }\n}\n</code></pre>"},{"location":"internals/storage-engine/#snapshot-operations","title":"Snapshot Operations","text":"<pre><code>impl StorageManager {\n    /// Create a new snapshot (after flush)\n    pub async fn create_snapshot(&amp;self) -&gt; Result&lt;Snapshot&gt; {\n        let manifest = Manifest {\n            version: self.next_version(),\n            timestamp: Utc::now(),\n            vertex_datasets: self.collect_vertex_versions(),\n            edge_datasets: self.collect_edge_versions(),\n            adjacency_datasets: self.collect_adjacency_versions(),\n            l1_runs: self.l1_manager.list_runs(),\n            indexes: self.collect_index_versions(),\n        };\n\n        // Write manifest atomically\n        self.write_manifest(&amp;manifest).await?;\n\n        Ok(Snapshot::new(manifest))\n    }\n\n    /// Open a specific snapshot for reading\n    pub async fn open_snapshot(&amp;self, version: u64) -&gt; Result&lt;SnapshotReader&gt; {\n        let manifest = self.read_manifest(version).await?;\n\n        Ok(SnapshotReader {\n            manifest,\n            vertex_readers: self.open_vertex_readers(&amp;manifest).await?,\n            edge_readers: self.open_edge_readers(&amp;manifest).await?,\n            adjacency_cache: self.load_adjacency(&amp;manifest).await?,\n        })\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#index-storage","title":"Index Storage","text":""},{"location":"internals/storage-engine/#vector-index-storage","title":"Vector Index Storage","text":"<p>Vector indexes (HNSW, IVF_PQ) are stored within Lance datasets:</p> <pre><code>pub struct VectorIndexStorage {\n    /// Lance dataset with index\n    dataset: Dataset,\n\n    /// Index configuration\n    config: VectorIndexConfig,\n}\n\nimpl VectorIndexStorage {\n    pub async fn create_index(\n        dataset: &amp;mut Dataset,\n        column: &amp;str,\n        config: VectorIndexConfig,\n    ) -&gt; Result&lt;()&gt; {\n        match config.index_type {\n            IndexType::Hnsw =&gt; {\n                dataset.create_index()\n                    .column(column)\n                    .index_type(\"IVF_HNSW_SQ\")\n                    .metric_type(config.metric.to_lance())\n                    .build()\n                    .await?;\n            }\n            IndexType::IvfPq =&gt; {\n                dataset.create_index()\n                    .column(column)\n                    .index_type(\"IVF_PQ\")\n                    .metric_type(config.metric.to_lance())\n                    .num_partitions(config.num_partitions)\n                    .num_sub_vectors(config.num_sub_vectors)\n                    .build()\n                    .await?;\n            }\n        }\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#scalar-index-storage","title":"Scalar Index Storage","text":"<p>Scalar indexes use Lance's built-in index support:</p> <pre><code>pub struct ScalarIndexStorage {\n    /// Index metadata\n    metadata: ScalarIndexMetadata,\n}\n\nimpl ScalarIndexStorage {\n    pub async fn create_index(\n        dataset: &amp;mut Dataset,\n        column: &amp;str,\n        index_type: ScalarIndexType,\n    ) -&gt; Result&lt;()&gt; {\n        dataset.create_index()\n            .column(column)\n            .index_type(match index_type {\n                ScalarIndexType::BTree =&gt; \"BTREE\",\n                ScalarIndexType::Hash =&gt; \"HASH\",\n                ScalarIndexType::Bitmap =&gt; \"BITMAP\",\n            })\n            .build()\n            .await?;\n\n        Ok(())\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#object-store-integration","title":"Object Store Integration","text":"<p>Uni supports multiple storage backends through <code>object_store</code>:</p>"},{"location":"internals/storage-engine/#supported-backends","title":"Supported Backends","text":"Backend URI Scheme Notes Local filesystem <code>file://</code> Default, development Amazon S3 <code>s3://</code> Production, scalable Google Cloud Storage <code>gs://</code> Production, scalable Azure Blob Storage <code>az://</code> Production Memory <code>memory://</code> Testing only"},{"location":"internals/storage-engine/#configuration","title":"Configuration","text":"<pre><code>pub struct ObjectStoreConfig {\n    /// Base URI (e.g., \"s3://bucket/path\")\n    uri: String,\n\n    /// AWS/GCP credentials\n    credentials: Option&lt;Credentials&gt;,\n\n    /// Connection settings\n    max_connections: usize,\n    connect_timeout: Duration,\n    read_timeout: Duration,\n\n    /// Retry configuration\n    retry_config: RetryConfig,\n}\n\nimpl StorageManager {\n    pub fn new_with_object_store(\n        uri: &amp;str,\n        schema_manager: Arc&lt;SchemaManager&gt;,\n        config: ObjectStoreConfig,\n    ) -&gt; Result&lt;Self&gt; {\n        let object_store = match uri {\n            s if s.starts_with(\"s3://\") =&gt; {\n                AmazonS3Builder::from_env()\n                    .with_url(uri)\n                    .with_max_connections(config.max_connections)\n                    .build()?\n            }\n            s if s.starts_with(\"gs://\") =&gt; {\n                GoogleCloudStorageBuilder::from_env()\n                    .with_url(uri)\n                    .build()?\n            }\n            s if s.starts_with(\"file://\") || !s.contains(\"://\") =&gt; {\n                LocalFileSystem::new_with_prefix(uri)?\n            }\n            _ =&gt; return Err(UnsupportedBackend(uri.to_string())),\n        };\n\n        // Initialize Lance with object store\n        let lance_config = LanceConfig::new(object_store);\n\n        Ok(Self::new_with_lance(lance_config, schema_manager))\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#local-caching","title":"Local Caching","text":"<p>For remote object stores, local caching improves performance:</p> <pre><code>pub struct CachedObjectStore {\n    /// Remote object store\n    remote: Arc&lt;dyn ObjectStore&gt;,\n\n    /// Local cache directory\n    cache_dir: PathBuf,\n\n    /// Maximum cache size\n    max_size: usize,\n\n    /// LRU eviction\n    lru: LruCache&lt;Path, CacheEntry&gt;,\n}\n\nimpl CachedObjectStore {\n    pub async fn get(&amp;self, path: &amp;Path) -&gt; Result&lt;Bytes&gt; {\n        // Check local cache first\n        if let Some(entry) = self.lru.get(path) {\n            return Ok(entry.data.clone());\n        }\n\n        // Fetch from remote\n        let data = self.remote.get(path).await?.bytes().await?;\n\n        // Cache locally\n        self.cache_locally(path, &amp;data).await?;\n\n        Ok(data)\n    }\n}\n</code></pre>"},{"location":"internals/storage-engine/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"internals/storage-engine/#write-performance","title":"Write Performance","text":"Operation Latency Throughput Notes L0 insert (vertex) ~50\u00b5s ~20K/sec Memory only L0 insert (edge) ~30\u00b5s ~33K/sec Memory only L0 batch insert (1K) ~550\u00b5s ~1.8M/sec Amortized L0 \u2192 L1 flush ~6ms/1K - Lance write L1 \u2192 L2 compact ~1s/100K - Background"},{"location":"internals/storage-engine/#read-performance","title":"Read Performance","text":"Operation Latency Notes Point lookup (indexed) ~2.9ms Hash index Range scan (indexed) ~5ms + 0.1ms/row B-tree index Full scan ~50ms/100K rows Columnar Vector KNN (k=10) ~1.8ms HNSW index"},{"location":"internals/storage-engine/#storage-efficiency","title":"Storage Efficiency","text":"Data Type Compression Ratio Integers Dictionary + RLE 5-20x Strings Dictionary + LZ4 3-10x Vectors No compression 1x Booleans Bitmap 8x"},{"location":"internals/storage-engine/#configuration-reference","title":"Configuration Reference","text":"<pre><code>pub struct StorageConfig {\n    // L0 Configuration\n    /// Maximum L0 size before flush (bytes)\n    pub max_l0_size: usize,  // Default: 128 MB\n\n    /// Maximum mutations before flush\n    pub max_mutations_before_flush: usize,  // Default: 10_000\n\n    /// Auto-flush enabled\n    pub auto_flush: bool,  // Default: true\n\n    // L1 Configuration\n    /// Maximum L1 runs before compaction\n    pub max_l1_runs: usize,  // Default: 4\n\n    /// L1 run size threshold for compaction\n    pub l1_compaction_threshold: usize,  // Default: 256 MB\n\n    // WAL Configuration\n    /// WAL sync mode\n    pub wal_sync_mode: WalSyncMode,  // Default: Periodic(100ms)\n\n    /// WAL segment size\n    pub wal_segment_size: usize,  // Default: 64 MB\n\n    // Cache Configuration\n    /// Adjacency cache size (vertices)\n    pub adjacency_cache_size: usize,  // Default: 1_000_000\n\n    /// Property cache size (entries)\n    pub property_cache_size: usize,  // Default: 100_000\n\n    // Object Store Configuration\n    /// Read-ahead size for sequential scans\n    pub read_ahead_size: usize,  // Default: 64 MB\n\n    /// Prefetch enabled\n    pub prefetch_enabled: bool,  // Default: true\n}\n</code></pre>"},{"location":"internals/storage-engine/#next-steps","title":"Next Steps","text":"<ul> <li>Vectorized Execution \u2014 Query execution engine</li> <li>Query Planning \u2014 From Cypher to physical plan</li> <li>Benchmarks \u2014 Performance measurements</li> </ul>"},{"location":"internals/vectorized-execution/","title":"Vectorized Execution Engine","text":"<p>Uni's query engine uses vectorized execution inspired by systems like DuckDB, Velox, and KuzuDB. Instead of the traditional tuple-at-a-time (Volcano) model, the engine processes data in batches (vectors), achieving significant performance gains through reduced interpretation overhead and improved CPU cache utilization.</p>"},{"location":"internals/vectorized-execution/#why-vectorized-execution","title":"Why Vectorized Execution?","text":"<p>Traditional row-at-a-time execution has severe performance limitations:</p> <pre><code>Traditional Volcano Model:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   for each row:                                                              \u2502\n\u2502     \u2022 Virtual function call to get next tuple                                \u2502\n\u2502     \u2022 Interpret each operator                                                \u2502\n\u2502     \u2022 Branch mispredictions per tuple                                        \u2502\n\u2502     \u2022 Poor cache locality                                                    \u2502\n\u2502     \u2022 ~100 cycles overhead per tuple                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nVectorized Model:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   for each batch (1024-4096 rows):                                           \u2502\n\u2502     \u2022 Single virtual function call                                           \u2502\n\u2502     \u2022 Amortized interpretation                                               \u2502\n\u2502     \u2022 Predictable branches                                                   \u2502\n\u2502     \u2022 Cache-friendly columnar access                                         \u2502\n\u2502     \u2022 ~5-10 cycles overhead per tuple                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Performance Gains: - 10-100x reduction in interpretation overhead - 2-4x improvement from SIMD utilization - 2-3x improvement from cache locality</p>"},{"location":"internals/vectorized-execution/#core-data-structures","title":"Core Data Structures","text":""},{"location":"internals/vectorized-execution/#vectorizedbatch","title":"VectorizedBatch","text":"<p>The fundamental unit of data in Uni's execution engine:</p> <pre><code>pub struct VectorizedBatch {\n    /// Underlying columnar data (Apache Arrow RecordBatch)\n    data: RecordBatch,\n\n    /// Selection vector for filtered rows (avoids data copying)\n    selection: Option&lt;SelectionVector&gt;,\n\n    /// Number of active (non-filtered) rows\n    cardinality: usize,\n}\n\npub struct SelectionVector {\n    /// Indices of selected rows\n    indices: Vec&lt;u32&gt;,\n\n    /// Original batch size\n    original_size: usize,\n}\n</code></pre> <p>Key Properties:</p> Property Description Columnar Wraps Apache Arrow RecordBatch for zero-copy Selection Vector Filters rows without physical deletion Morsel-Sized 1024-4096 rows to fit L1/L2 cache Type-Safe Arrow schema enforces column types"},{"location":"internals/vectorized-execution/#selection-vector-optimization","title":"Selection Vector Optimization","text":"<p>Instead of physically removing filtered rows (expensive copying), we maintain a selection vector:</p> <pre><code>Original Batch:        Selection Vector:        Effective View:\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510              \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 VID \u2502 Year\u2502Title\u2502   \u2502 [0,2] \u2502   \u2500\u2500\u2500\u2500\u2500\u2500\u25b6    \u2502 v1  \u2502 2023\u2502 \"A\" \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2524   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518              \u2502 v3  \u2502 2021\u2502 \"C\" \u2502\n\u2502 v1  \u2502 2023\u2502 \"A\" \u2502                          \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n\u2502 v2  \u2502 2018\u2502 \"B\" \u2502  (rows 0,2 selected)\n\u2502 v3  \u2502 2021\u2502 \"C\" \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Benefits: - No memory allocation for filtering - Multiple filters compose by ANDing selection vectors - Original data preserved for backtracking</p>"},{"location":"internals/vectorized-execution/#physical-operators","title":"Physical Operators","text":""},{"location":"internals/vectorized-execution/#operator-pipeline-architecture","title":"Operator Pipeline Architecture","text":"flowchart LR     Scan[\"Scan&lt;br/&gt;&lt;i&gt;[RecordBatch]&lt;/i&gt;\"]     Filter[\"Filter&lt;br/&gt;&lt;i&gt;[Selection]&lt;/i&gt;\"]     Traverse[\"Traverse&lt;br/&gt;&lt;i&gt;[Expanded]&lt;/i&gt;\"]     Project[\"Project&lt;br/&gt;&lt;i&gt;[Projected]&lt;/i&gt;\"]     Results[\"Results\"]      Scan --&gt; Filter --&gt; Traverse --&gt; Project --&gt; Results"},{"location":"internals/vectorized-execution/#scan-operator","title":"Scan Operator","text":"<p>Reads data from Lance datasets in batches:</p> <pre><code>pub struct ScanOperator {\n    /// Lance dataset reader\n    dataset: Arc&lt;Dataset&gt;,\n\n    /// Columns to read\n    projection: Vec&lt;String&gt;,\n\n    /// Pushed-down predicates\n    filter: Option&lt;Expr&gt;,\n\n    /// Batch configuration\n    batch_size: usize,\n}\n\nimpl ScanOperator {\n    async fn next_batch(&amp;mut self) -&gt; Option&lt;VectorizedBatch&gt; {\n        // Lance handles predicate pushdown natively\n        let batch = self.dataset\n            .scan()\n            .filter(self.filter.clone())\n            .project(&amp;self.projection)\n            .batch_size(self.batch_size)\n            .next_batch()\n            .await?;\n\n        Some(VectorizedBatch::new(batch))\n    }\n}\n</code></pre> <p>Optimizations: - Predicate Pushdown: Filters pushed to Lance skip entire row groups - Column Pruning: Only requested columns loaded from disk - Batch Prefetching: Next batch loaded while current processes</p>"},{"location":"internals/vectorized-execution/#filter-operator","title":"Filter Operator","text":"<p>Evaluates predicates using SIMD-accelerated Arrow compute kernels:</p> <pre><code>pub struct FilterOperator {\n    /// Child operator\n    child: Box&lt;dyn PhysicalOperator&gt;,\n\n    /// Predicate expression\n    predicate: PhysicalExpr,\n}\n\nimpl FilterOperator {\n    fn filter_batch(&amp;self, batch: VectorizedBatch) -&gt; VectorizedBatch {\n        // Evaluate predicate to boolean array\n        let mask = self.predicate.evaluate(&amp;batch.data);\n\n        // Combine with existing selection\n        let new_selection = match batch.selection {\n            Some(sel) =&gt; sel.and(&amp;mask),\n            None =&gt; SelectionVector::from_boolean(&amp;mask),\n        };\n\n        batch.with_selection(new_selection)\n    }\n}\n</code></pre> <p>SIMD Acceleration:</p> Operation Implementation Speedup <code>=</code>, <code>&lt;&gt;</code> <code>arrow::compute::eq/neq</code> 8-16x <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code> <code>arrow::compute::lt/gt/...</code> 8-16x <code>AND</code>, <code>OR</code> <code>arrow::compute::and/or</code> 16-32x <code>IS NULL</code> <code>arrow::compute::is_null</code> 16-32x"},{"location":"internals/vectorized-execution/#traverse-operator","title":"Traverse Operator","text":"<p>The heart of graph query execution\u2014batch adjacency lookups:</p> <pre><code>pub struct TraverseOperator {\n    /// Child operator (source vertices)\n    child: Box&lt;dyn PhysicalOperator&gt;,\n\n    /// Edge type to traverse\n    edge_type: EdgeTypeId,\n\n    /// Direction (outgoing, incoming, both)\n    direction: Direction,\n\n    /// Adjacency cache reference\n    adjacency_cache: Arc&lt;AdjacencyCache&gt;,\n}\n\nimpl TraverseOperator {\n    fn traverse_batch(&amp;self, batch: VectorizedBatch) -&gt; VectorizedBatch {\n        // Extract source VIDs\n        let src_vids = batch.column::&lt;VidArray&gt;(\"_vid\");\n\n        // Batch lookup neighbors for ALL source vertices\n        let (dst_vids, src_indices) = self.adjacency_cache\n            .batch_neighbors(src_vids, self.edge_type, self.direction);\n\n        // Build expanded batch: each (src, dst) pair becomes a row\n        self.build_expanded_batch(batch, dst_vids, src_indices)\n    }\n}\n</code></pre> <p>Expansion Semantics:</p> <pre><code>Input Batch:               After Traverse:\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 VID \u2502  Title  \u2502          \u2502 src \u2502src_title\u2502 dst \u2502dst_title\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524          \u251c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 v1  \u2502 \"Paper1\"\u2502   \u2500\u2500\u25b6    \u2502 v1  \u2502\"Paper1\" \u2502 v3  \u2502   ?     \u2502\n\u2502 v2  \u2502 \"Paper2\"\u2502          \u2502 v1  \u2502\"Paper1\" \u2502 v4  \u2502   ?     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502 v2  \u2502\"Paper2\" \u2502 v5  \u2502   ?     \u2502\n                           \u2502 v2  \u2502\"Paper2\" \u2502 v6  \u2502   ?     \u2502\n                           \u2502 v2  \u2502\"Paper2\" \u2502 v7  \u2502   ?     \u2502\n                           \u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/vectorized-execution/#project-operator","title":"Project Operator","text":"<p>Computes output expressions:</p> <pre><code>pub struct ProjectOperator {\n    /// Child operator\n    child: Box&lt;dyn PhysicalOperator&gt;,\n\n    /// Output expressions\n    projections: Vec&lt;(PhysicalExpr, String)&gt;,\n}\n\nimpl ProjectOperator {\n    fn project_batch(&amp;self, batch: VectorizedBatch) -&gt; VectorizedBatch {\n        let columns: Vec&lt;ArrayRef&gt; = self.projections\n            .iter()\n            .map(|(expr, _)| expr.evaluate(&amp;batch.data))\n            .collect();\n\n        let schema = Schema::new(\n            self.projections.iter()\n                .map(|(_, name)| Field::new(name, ...))\n                .collect()\n        );\n\n        VectorizedBatch::new(RecordBatch::try_new(schema, columns))\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#aggregate-operator","title":"Aggregate Operator","text":"<p>Hash-based aggregation with vectorized execution:</p> <pre><code>pub struct HashAggregateOperator {\n    /// Group-by expressions\n    group_by: Vec&lt;PhysicalExpr&gt;,\n\n    /// Aggregate functions\n    aggregates: Vec&lt;AggregateExpr&gt;,\n\n    /// Hash table for grouping\n    hash_table: HashMap&lt;GroupKey, AccumulatorState&gt;,\n}\n\nimpl HashAggregateOperator {\n    fn aggregate_batch(&amp;mut self, batch: VectorizedBatch) {\n        // Compute group keys for all rows\n        let keys = self.compute_group_keys(&amp;batch);\n\n        // Vectorized hash computation\n        let hashes = self.hash_keys(&amp;keys);\n\n        // Update accumulators in batch\n        for (row_idx, hash) in hashes.iter().enumerate() {\n            let state = self.hash_table\n                .entry(keys[row_idx].clone())\n                .or_insert_with(|| self.init_accumulators());\n\n            self.update_accumulators(state, &amp;batch, row_idx);\n        }\n    }\n}\n</code></pre> <p>Supported Aggregates:</p> Function Accumulator Vectorized <code>COUNT(*)</code> Counter Yes <code>COUNT(x)</code> Non-null counter Yes <code>SUM(x)</code> Running sum Yes <code>AVG(x)</code> Sum + count Yes <code>MIN(x)</code> Running min Yes <code>MAX(x)</code> Running max Yes <code>COLLECT(x)</code> List builder Yes"},{"location":"internals/vectorized-execution/#adjacency-cache-csr","title":"Adjacency Cache (CSR)","text":"<p>The Compressed Sparse Row (CSR) cache is critical for graph traversal performance.</p>"},{"location":"internals/vectorized-execution/#csr-structure","title":"CSR Structure","text":"<pre><code>Adjacency List Representation:\n\nVertex 0: [1, 2, 3]\nVertex 1: [0, 4]\nVertex 2: [0, 5, 6, 7]\nVertex 3: []\nVertex 4: [1, 2]\n\nCSR Representation:\n\noffsets:  [0,    3,    5,         9,    9,    11]\n          \u2502     \u2502     \u2502          \u2502     \u2502     \u2502\n          \u25bc     \u25bc     \u25bc          \u25bc     \u25bc     \u25bc\ntargets:  [1, 2, 3, 0, 4, 0, 5, 6, 7, -, 1, 2]\n          \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u251c\u2500\u2500\u2500\u2500\u2524\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u251c\u2500\u2500\u2500\u2500\u2500\u2524\n          v0 adj   v1    v2 neighbors   v4 adj\n\nneighbors(v) = targets[offsets[v]..offsets[v+1]]\n</code></pre>"},{"location":"internals/vectorized-execution/#cache-architecture","title":"Cache Architecture","text":"<pre><code>pub struct AdjacencyCache {\n    /// Per edge-type, per-direction CSR structures\n    csr_maps: HashMap&lt;(EdgeTypeId, Direction), CsrGraph&gt;,\n\n    /// LRU eviction for memory management\n    lru: LruCache&lt;CacheKey, CsrChunk&gt;,\n\n    /// Maximum cache size in bytes\n    max_size: usize,\n\n    /// Statistics\n    stats: CacheStats,\n}\n\npub struct CsrGraph {\n    /// Vertex count\n    num_vertices: usize,\n\n    /// Offset array (num_vertices + 1 elements)\n    offsets: Vec&lt;u64&gt;,\n\n    /// Target vertex IDs\n    targets: Vec&lt;Vid&gt;,\n\n    /// Edge IDs (parallel to targets)\n    edge_ids: Vec&lt;Eid&gt;,\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#batch-neighbor-lookup","title":"Batch Neighbor Lookup","text":"<pre><code>impl AdjacencyCache {\n    pub fn batch_neighbors(\n        &amp;self,\n        src_vids: &amp;[Vid],\n        edge_type: EdgeTypeId,\n        direction: Direction,\n    ) -&gt; (Vec&lt;Vid&gt;, Vec&lt;u32&gt;) {\n        let csr = self.get_or_load_csr(edge_type, direction);\n\n        let mut dst_vids = Vec::new();\n        let mut src_indices = Vec::new();\n\n        for (idx, &amp;vid) in src_vids.iter().enumerate() {\n            let start = csr.offsets[vid.local_offset() as usize];\n            let end = csr.offsets[vid.local_offset() as usize + 1];\n\n            for i in start..end {\n                dst_vids.push(csr.targets[i as usize]);\n                src_indices.push(idx as u32);  // Track which src produced this dst\n            }\n        }\n\n        (dst_vids, src_indices)\n    }\n}\n</code></pre> <p>Performance Characteristics:</p> Operation Complexity Notes Single neighbor lookup O(degree) Direct array access Batch lookup (n vertices) O(\u03a3 degrees) Cache-friendly sequential scan Cache miss O(chunk_size) Load from Lance"},{"location":"internals/vectorized-execution/#cache-warming","title":"Cache Warming","text":"<pre><code>// Warm cache for frequently accessed vertices\ncache.warm(&amp;high_degree_vertices).await;\n\n// Warm for specific traversal pattern\ncache.warm_for_query(&amp;query_plan).await;\n</code></pre>"},{"location":"internals/vectorized-execution/#morsel-driven-parallelism","title":"Morsel-Driven Parallelism","text":"<p>Uni uses morsel-driven parallelism for multi-core utilization.</p>"},{"location":"internals/vectorized-execution/#parallel-execution-model","title":"Parallel Execution Model","text":"flowchart TB     Source[\"Source Data\"]     Split[\"Split Morsels\"]      subgraph Queue[\"Morsel Queue\"]         M1[\"M1\"]         M2[\"M2\"]         M3[\"M3\"]         M4[\"M4\"]         M5[\"M5\"]         M6[\"M6\"]         M7[\"M7\"]         M8[\"M8\"]     end      subgraph Workers[\"Worker Threads\"]         W1[\"W1\"]         W2[\"W2\"]         W3[\"W3\"]         W4[\"W4\"]     end      Merge[\"Merge Results\"]      Source --&gt; Split --&gt; Queue     M1 &amp; M5 --&gt; W1     M2 &amp; M6 --&gt; W2     M3 &amp; M7 --&gt; W3     M4 &amp; M8 --&gt; W4     Workers --&gt; Merge"},{"location":"internals/vectorized-execution/#pipeline-breakers","title":"Pipeline Breakers","text":"<p>Some operators require all input before producing output:</p> Operator Type Reason Scan, Filter, Project Pipeline Streaming, no buffering Traverse Pipeline Per-batch expansion Sort Breaker Needs all data for global sort Aggregate Breaker Needs all groups Limit Pipeline Early termination"},{"location":"internals/vectorized-execution/#exchange-operators","title":"Exchange Operators","text":"<p>For parallel pipelines, exchange operators redistribute data:</p> <pre><code>pub enum Exchange {\n    /// Round-robin distribution\n    RoundRobin { parallelism: usize },\n\n    /// Hash-based partitioning (for joins/aggregates)\n    Hash { key_columns: Vec&lt;usize&gt;, parallelism: usize },\n\n    /// Merge multiple streams\n    Merge { input_streams: usize },\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#late-materialization","title":"Late Materialization","text":"<p>A key optimization to reduce I/O for wide tables.</p>"},{"location":"internals/vectorized-execution/#materialization-strategy","title":"Materialization Strategy","text":"<pre><code>Query: MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN p.title, p.abstract\n\nTraditional (Early Materialization):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Scan ALL columns \u2192 Filter \u2192 Project                                         \u2502\n\u2502 I/O: title + abstract + year + embedding + ... (all columns)               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nLate Materialization:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. Scan(_vid, year) \u2192 Filter(year &gt; 2020) \u2192 [1000 \u2192 50 rows]              \u2502\n\u2502 2. Materialize(title, abstract) for 50 surviving VIDs                      \u2502\n\u2502 3. Project                                                                  \u2502\n\u2502 I/O: year (1000 rows) + title,abstract (50 rows) = 95% reduction          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"internals/vectorized-execution/#implementation","title":"Implementation","text":"<pre><code>pub struct LateMaterializeOperator {\n    /// Child produces VIDs and filter columns\n    child: Box&lt;dyn PhysicalOperator&gt;,\n\n    /// Columns to materialize late\n    late_columns: Vec&lt;String&gt;,\n\n    /// Property manager for lookups\n    prop_manager: Arc&lt;PropertyManager&gt;,\n}\n\nimpl LateMaterializeOperator {\n    async fn materialize(&amp;self, batch: VectorizedBatch) -&gt; VectorizedBatch {\n        // Get surviving VIDs\n        let vids = batch.selected_vids();\n\n        // Batch-load properties for these VIDs only\n        let properties = self.prop_manager\n            .batch_load(&amp;vids, &amp;self.late_columns)\n            .await;\n\n        // Join properties back to batch\n        batch.append_columns(properties)\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#when-to-use","title":"When to Use","text":"Scenario Materialization Rationale High selectivity filter Late Few rows survive Low selectivity filter Early Most rows survive, avoid second scan LIMIT without ORDER BY Late Only materialize LIMIT rows Aggregation only Avoid Don't load unused columns"},{"location":"internals/vectorized-execution/#expression-evaluation","title":"Expression Evaluation","text":""},{"location":"internals/vectorized-execution/#physical-expression-types","title":"Physical Expression Types","text":"<pre><code>pub enum PhysicalExpr {\n    /// Column reference\n    Column { index: usize, name: String },\n\n    /// Literal value\n    Literal { value: ScalarValue },\n\n    /// Binary operation\n    BinaryExpr { left: Box&lt;Self&gt;, op: BinaryOp, right: Box&lt;Self&gt; },\n\n    /// Function call\n    Function { name: String, args: Vec&lt;Self&gt; },\n\n    /// CASE expression\n    Case { when_then: Vec&lt;(Self, Self)&gt;, else_expr: Option&lt;Box&lt;Self&gt;&gt; },\n}\n\nimpl PhysicalExpr {\n    pub fn evaluate(&amp;self, batch: &amp;RecordBatch) -&gt; ArrayRef {\n        match self {\n            PhysicalExpr::Column { index, .. } =&gt; {\n                batch.column(*index).clone()\n            }\n            PhysicalExpr::BinaryExpr { left, op, right } =&gt; {\n                let l = left.evaluate(batch);\n                let r = right.evaluate(batch);\n                apply_binary_op(&amp;l, op, &amp;r)  // SIMD kernels\n            }\n            // ...\n        }\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#vectorized-kernels","title":"Vectorized Kernels","text":"<pre><code>fn apply_binary_op(left: &amp;ArrayRef, op: &amp;BinaryOp, right: &amp;ArrayRef) -&gt; ArrayRef {\n    match op {\n        BinaryOp::Eq =&gt; arrow::compute::eq(left, right),\n        BinaryOp::Lt =&gt; arrow::compute::lt(left, right),\n        BinaryOp::Add =&gt; arrow::compute::add(left, right),\n        BinaryOp::And =&gt; arrow::compute::and(\n            left.as_boolean(),\n            right.as_boolean()\n        ),\n        // ... SIMD-accelerated for all operations\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#memory-management","title":"Memory Management","text":""},{"location":"internals/vectorized-execution/#batch-memory-lifecycle","title":"Batch Memory Lifecycle","text":"<pre><code>pub struct MemoryPool {\n    /// Current allocated bytes\n    allocated: AtomicUsize,\n\n    /// Maximum allowed bytes\n    limit: usize,\n\n    /// Spill directory for overflow\n    spill_dir: PathBuf,\n}\n\nimpl MemoryPool {\n    pub fn allocate(&amp;self, size: usize) -&gt; Result&lt;MemoryReservation&gt; {\n        let current = self.allocated.fetch_add(size, Ordering::SeqCst);\n\n        if current + size &gt; self.limit {\n            self.allocated.fetch_sub(size, Ordering::SeqCst);\n            return Err(MemoryExhausted);\n        }\n\n        Ok(MemoryReservation { pool: self, size })\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#spilling","title":"Spilling","text":"<p>When memory is exhausted, operators spill to disk:</p> <pre><code>impl HashAggregateOperator {\n    fn handle_memory_pressure(&amp;mut self) {\n        // Partition hash table\n        let partitions = self.hash_table.partition(16);\n\n        // Spill cold partitions to disk\n        for (idx, partition) in partitions.iter().enumerate() {\n            if !partition.is_hot() {\n                self.spill_to_disk(idx, partition);\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"internals/vectorized-execution/#performance-tuning","title":"Performance Tuning","text":""},{"location":"internals/vectorized-execution/#batch-size-selection","title":"Batch Size Selection","text":"Scenario Recommended Size Rationale Simple scans 8192 Maximize throughput Complex expressions 2048 Fit intermediate results in L2 High selectivity 4096 Balance filtering overhead Aggregations 4096 Good hash table locality"},{"location":"internals/vectorized-execution/#parallelism-configuration","title":"Parallelism Configuration","text":"<pre><code>let config = ExecutorConfig {\n    // Match CPU core count\n    worker_threads: num_cpus::get(),\n\n    // Rows per morsel (smaller = better load balancing)\n    morsel_size: 4096,\n\n    // Concurrent I/O operations\n    max_concurrent_io: 16,\n\n    // Memory limit per query\n    memory_limit: 4 * 1024 * 1024 * 1024,  // 4 GB\n};\n</code></pre>"},{"location":"internals/vectorized-execution/#next-steps","title":"Next Steps","text":"<ul> <li>Storage Engine \u2014 Underlying data persistence</li> <li>Query Planning \u2014 From Cypher to physical plan</li> <li>Benchmarks \u2014 Performance measurements</li> </ul>"},{"location":"reference/","title":"Reference","text":"<p>Complete reference documentation for Uni.</p>   ### [Rust API](rust-api.md) Programmatic access to Uni from Rust applications.     ### [REST API](rest-api.md) HTTP API reference for remote query execution and monitoring.     ### [Configuration](configuration.md) All configuration options for storage, runtime, and queries.     ### [Troubleshooting](troubleshooting.md) Common issues, error messages, and solutions.     ### [Glossary](glossary.md) Terminology and abbreviations used in Uni documentation."},{"location":"reference/#quick-reference","title":"Quick Reference","text":""},{"location":"reference/#common-configuration","title":"Common Configuration","text":"<pre><code>let config = StorageConfig {\n    path: \"./storage\".into(),\n    adjacency_cache_size: 1_000_000,\n    property_cache_size: 100_000,\n    max_l0_size: 64 * 1024 * 1024,  // 64 MB\n    ..Default::default()\n};\n</code></pre>"},{"location":"reference/#supported-data-types","title":"Supported Data Types","text":"Type Description Example <code>String</code> UTF-8 text <code>\"hello\"</code> <code>Int32</code> 32-bit integer <code>42</code> <code>Int64</code> 64-bit integer <code>9223372036854775807</code> <code>Float32</code> 32-bit float <code>3.14</code> <code>Float64</code> 64-bit float <code>3.141592653589793</code> <code>Boolean</code> True/false <code>true</code> <code>Vector[N]</code> N-dimensional float vector <code>[0.1, 0.2, 0.3]</code> <code>Json</code> Nested JSON document <code>{\"key\": \"value\"}</code>"},{"location":"reference/#environment-variables","title":"Environment Variables","text":"Variable Description <code>RUST_LOG</code> Log level (<code>uni=debug</code>, <code>uni::storage=trace</code>) <code>UNI_STORAGE_PATH</code> Default storage path <code>UNI_CACHE_DIR</code> Local cache directory"},{"location":"reference/#next-steps","title":"Next Steps","text":"<ul> <li>For API details, see Rust API</li> <li>For tuning options, see Configuration</li> <li>Having issues? Check Troubleshooting</li> </ul>"},{"location":"reference/configuration/","title":"Configuration Reference","text":"<p>This document provides a comprehensive reference for all Uni configuration options, environment variables, and tuning parameters.</p>"},{"location":"reference/configuration/#configuration-overview","title":"Configuration Overview","text":"<p>Uni can be configured through: 1. Rust API \u2014 <code>StorageConfig</code>, <code>ExecutorConfig</code>, etc. 2. Environment Variables \u2014 Runtime overrides 3. Configuration File \u2014 <code>uni.toml</code> or JSON</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       CONFIGURATION HIERARCHY                                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                                                             \u2502\n\u2502   Defaults (Code)                                                           \u2502\n\u2502       \u2193 overridden by                                                       \u2502\n\u2502   Configuration File (uni.toml)                                             \u2502\n\u2502       \u2193 overridden by                                                       \u2502\n\u2502   Environment Variables (UNI_*)                                             \u2502\n\u2502       \u2193 overridden by                                                       \u2502\n\u2502   Programmatic Config (Rust API)                                            \u2502\n\u2502                                                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"reference/configuration/#storage-configuration","title":"Storage Configuration","text":""},{"location":"reference/configuration/#storageconfig","title":"StorageConfig","text":"<pre><code>pub struct StorageConfig {\n    // L0 Buffer Configuration\n    pub max_l0_size: usize,\n    pub max_mutations_before_flush: usize,\n    pub auto_flush: bool,\n\n    // L1 Configuration\n    pub max_l1_runs: usize,\n    pub l1_compaction_threshold: usize,\n\n    // WAL Configuration\n    pub wal_sync_mode: WalSyncMode,\n    pub wal_segment_size: usize,\n    pub wal_dir: Option&lt;PathBuf&gt;,\n\n    // Cache Configuration\n    pub adjacency_cache_size: usize,\n    pub adjacency_cache_ttl: Duration,\n    pub property_cache_size: usize,\n\n    // I/O Configuration\n    pub read_ahead_size: usize,\n    pub prefetch_enabled: bool,\n    pub max_open_files: usize,\n\n    // Memory Configuration\n    pub memory_limit: Option&lt;usize&gt;,\n    pub enable_memory_tracking: bool,\n}\n</code></pre>"},{"location":"reference/configuration/#parameter-reference","title":"Parameter Reference","text":"Parameter Type Default Description <code>max_l0_size</code> bytes 128 MB Maximum L0 buffer size before flush <code>max_mutations_before_flush</code> count 10,000 Mutations triggering auto-flush <code>auto_flush</code> bool true Enable automatic flushing <code>max_l1_runs</code> count 4 L1 runs before compaction <code>l1_compaction_threshold</code> bytes 256 MB Size threshold for L1\u2192L2 compaction <code>wal_sync_mode</code> enum Periodic(100ms) WAL durability mode <code>wal_segment_size</code> bytes 64 MB WAL segment rotation size <code>adjacency_cache_size</code> vertices 1,000,000 Maximum cached vertices <code>adjacency_cache_ttl</code> duration 1 hour Cache entry TTL <code>property_cache_size</code> entries 100,000 Property cache capacity <code>read_ahead_size</code> bytes 64 MB Sequential read prefetch size <code>prefetch_enabled</code> bool true Enable I/O prefetching <code>max_open_files</code> count 1,000 Maximum open file handles <code>memory_limit</code> bytes None Per-process memory limit"},{"location":"reference/configuration/#wal-sync-modes","title":"WAL Sync Modes","text":"<pre><code>pub enum WalSyncMode {\n    /// fsync after every write\n    /// Safest, ~50% slower writes\n    Sync,\n\n    /// fsync at regular intervals\n    /// Balanced durability/performance\n    Periodic { interval_ms: u64 },\n\n    /// OS-managed sync\n    /// Fastest, risk of data loss on crash\n    Async,\n}\n</code></pre> <p>Recommendations:</p> Use Case Mode Rationale Production (critical data) <code>Sync</code> Maximum durability Production (balanced) <code>Periodic(100)</code> Good balance Development <code>Async</code> Maximum speed Batch import <code>Async</code> Speed, re-import on failure"},{"location":"reference/configuration/#example-configuration","title":"Example Configuration","text":"<pre><code>let config = StorageConfig {\n    // Large buffer for batch workloads\n    max_l0_size: 256 * 1024 * 1024,  // 256 MB\n    max_mutations_before_flush: 50_000,\n    auto_flush: true,\n\n    // Faster compaction trigger\n    max_l1_runs: 2,\n    l1_compaction_threshold: 128 * 1024 * 1024,\n\n    // Balanced WAL\n    wal_sync_mode: WalSyncMode::Periodic { interval_ms: 50 },\n    wal_segment_size: 32 * 1024 * 1024,\n\n    // Large cache for traversal-heavy workloads\n    adjacency_cache_size: 5_000_000,\n    property_cache_size: 500_000,\n\n    ..Default::default()\n};\n</code></pre>"},{"location":"reference/configuration/#executor-configuration","title":"Executor Configuration","text":""},{"location":"reference/configuration/#executorconfig","title":"ExecutorConfig","text":"<pre><code>pub struct ExecutorConfig {\n    // Parallelism\n    pub worker_threads: usize,\n    pub morsel_size: usize,\n    pub max_concurrent_io: usize,\n\n    // Resource Limits\n    pub memory_limit: usize,\n    pub timeout: Duration,\n\n    // Optimization\n    pub enable_pushdown: bool,\n    pub enable_late_materialize: bool,\n    pub batch_size: usize,\n\n    // Planner\n    pub max_optimization_rounds: usize,\n    pub cost_model: CostModel,\n}\n</code></pre>"},{"location":"reference/configuration/#parameter-reference_1","title":"Parameter Reference","text":"Parameter Type Default Description <code>worker_threads</code> count CPU cores Parallel worker count <code>morsel_size</code> rows 4,096 Rows per morsel <code>max_concurrent_io</code> count 16 Parallel I/O operations <code>memory_limit</code> bytes 4 GB Per-query memory limit <code>timeout</code> duration 5 min Query timeout <code>enable_pushdown</code> bool true Enable predicate pushdown <code>enable_late_materialize</code> bool true Enable late materialization <code>batch_size</code> rows 4,096 Vectorized batch size <code>max_optimization_rounds</code> count 10 Optimizer iterations"},{"location":"reference/configuration/#tuning-guidelines","title":"Tuning Guidelines","text":"Workload worker_threads morsel_size batch_size OLTP (simple queries) 4 1,024 1,024 OLAP (complex analytics) CPU cores 4,096 8,192 Mixed CPU cores / 2 2,048 4,096 Memory constrained 2-4 1,024 2,048"},{"location":"reference/configuration/#index-configuration","title":"Index Configuration","text":""},{"location":"reference/configuration/#vector-index-options","title":"Vector Index Options","text":"<pre><code>pub struct VectorIndexConfig {\n    pub name: String,\n    pub index_type: VectorIndexType,\n    pub metric: DistanceMetric,\n\n    // HNSW parameters\n    pub m: Option&lt;usize&gt;,              // Default: 32\n    pub ef_construction: Option&lt;usize&gt;, // Default: 200\n    pub ef_search: Option&lt;usize&gt;,       // Default: 100\n\n    // IVF_PQ parameters\n    pub num_partitions: Option&lt;usize&gt;,  // Default: sqrt(n)\n    pub num_sub_vectors: Option&lt;usize&gt;, // Default: dimensions/8\n    pub num_probes: Option&lt;usize&gt;,      // Default: 20\n}\n</code></pre>"},{"location":"reference/configuration/#hnsw-tuning","title":"HNSW Tuning","text":"Parameter Low Latency Balanced High Recall <code>m</code> 16 32 48-64 <code>ef_construction</code> 100 200 400-500 <code>ef_search</code> 50 100 200-300 <p>Trade-offs: - Higher <code>m</code> \u2192 Better recall, more memory, slower build - Higher <code>ef_construction</code> \u2192 Better index quality, slower build - Higher <code>ef_search</code> \u2192 Better recall at query time, slower queries</p>"},{"location":"reference/configuration/#ivf_pq-tuning","title":"IVF_PQ Tuning","text":"Parameter Memory Optimized Balanced Recall Optimized <code>num_partitions</code> 1024 512 256 <code>num_sub_vectors</code> 8 16 32-48 <code>num_probes</code> 10 20 50 <p>Trade-offs: - More partitions \u2192 Smaller clusters, less memory, potentially lower recall - More sub-vectors \u2192 Better recall, more memory per vector - More probes \u2192 Better recall at query time, slower queries</p>"},{"location":"reference/configuration/#scalar-index-options","title":"Scalar Index Options","text":"<pre><code>pub struct ScalarIndexConfig {\n    pub name: String,\n    pub index_type: ScalarIndexType,\n}\n\npub enum ScalarIndexType {\n    /// B-tree for range queries\n    BTree,\n\n    /// Hash for equality lookups\n    Hash,\n\n    /// Bitmap for low-cardinality columns\n    Bitmap,\n}\n</code></pre> Index Type Best For Query Types BTree Range queries, sorting <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>BETWEEN</code> Hash Exact match, high cardinality <code>=</code>, <code>IN</code> Bitmap Low cardinality (&lt;1000 distinct) <code>=</code>, <code>IN</code>, <code>AND</code>/<code>OR</code>"},{"location":"reference/configuration/#environment-variables","title":"Environment Variables","text":"<p>All environment variables use the <code>UNI_</code> prefix.</p>"},{"location":"reference/configuration/#storage-variables","title":"Storage Variables","text":"Variable Type Default Description <code>UNI_STORAGE_PATH</code> path <code>./storage</code> Default storage path <code>UNI_MAX_L0_SIZE_MB</code> integer 128 L0 buffer size in MB <code>UNI_WAL_SYNC_MODE</code> string <code>periodic</code> WAL mode: <code>sync</code>, <code>periodic</code>, <code>async</code> <code>UNI_WAL_SYNC_INTERVAL_MS</code> integer 100 Periodic sync interval <code>UNI_ADJACENCY_CACHE_SIZE</code> integer 1000000 Cache size in vertices <code>UNI_PROPERTY_CACHE_SIZE</code> integer 100000 Cache size in entries"},{"location":"reference/configuration/#executor-variables","title":"Executor Variables","text":"Variable Type Default Description <code>UNI_WORKER_THREADS</code> integer CPU cores Parallel workers <code>UNI_MORSEL_SIZE</code> integer 4096 Rows per morsel <code>UNI_MAX_MEMORY_MB</code> integer 4096 Memory limit in MB <code>UNI_QUERY_TIMEOUT_SECS</code> integer 300 Query timeout <code>UNI_ENABLE_PUSHDOWN</code> bool true Predicate pushdown"},{"location":"reference/configuration/#logging-variables","title":"Logging Variables","text":"Variable Type Default Description <code>RUST_LOG</code> string <code>warn</code> Log level filter <code>UNI_LOG_FORMAT</code> string <code>pretty</code> Log format: <code>pretty</code>, <code>json</code>, <code>compact</code> <code>UNI_LOG_FILE</code> path None Log to file"},{"location":"reference/configuration/#object-store-variables","title":"Object Store Variables","text":"Variable Type Default Description <code>AWS_ACCESS_KEY_ID</code> string - S3 access key <code>AWS_SECRET_ACCESS_KEY</code> string - S3 secret key <code>AWS_REGION</code> string <code>us-east-1</code> S3 region <code>AWS_ENDPOINT_URL</code> string - Custom S3 endpoint <code>GOOGLE_APPLICATION_CREDENTIALS</code> path - GCS service account"},{"location":"reference/configuration/#example","title":"Example","text":"<pre><code># Production configuration\nexport UNI_STORAGE_PATH=/data/uni\nexport UNI_MAX_L0_SIZE_MB=256\nexport UNI_WAL_SYNC_MODE=periodic\nexport UNI_WAL_SYNC_INTERVAL_MS=50\nexport UNI_ADJACENCY_CACHE_SIZE=5000000\nexport UNI_WORKER_THREADS=16\nexport UNI_MAX_MEMORY_MB=8192\nexport RUST_LOG=uni=info,lance=warn\n</code></pre>"},{"location":"reference/configuration/#configuration-file","title":"Configuration File","text":"<p>Uni supports TOML configuration files.</p>"},{"location":"reference/configuration/#location","title":"Location","text":"<p>Uni searches for configuration in order: 1. Path specified with <code>--config</code> 2. <code>./uni.toml</code> 3. <code>~/.config/uni/config.toml</code> 4. <code>/etc/uni/config.toml</code></p>"},{"location":"reference/configuration/#full-example","title":"Full Example","text":"<pre><code># uni.toml - Uni Configuration\n\n[storage]\npath = \"/data/uni\"\nmax_l0_size_mb = 256\nmax_mutations_before_flush = 50000\nauto_flush = true\nmax_l1_runs = 4\nl1_compaction_threshold_mb = 256\n\n[storage.wal]\nsync_mode = \"periodic\"  # sync, periodic, async\nsync_interval_ms = 100\nsegment_size_mb = 64\n\n[storage.cache]\nadjacency_size = 2000000\nadjacency_ttl_secs = 3600\nproperty_size = 200000\n\n[storage.io]\nread_ahead_mb = 64\nprefetch = true\nmax_open_files = 1000\n\n[executor]\nworker_threads = 8  # 0 = auto-detect\nmorsel_size = 4096\nmax_concurrent_io = 16\nmemory_limit_mb = 4096\ntimeout_secs = 300\n\n[executor.optimization]\nenable_pushdown = true\nenable_late_materialize = true\nbatch_size = 4096\nmax_optimization_rounds = 10\n\n[index.vector.defaults]\nindex_type = \"hnsw\"\nmetric = \"cosine\"\nm = 32\nef_construction = 200\nef_search = 100\n\n[index.scalar.defaults]\nindex_type = \"btree\"\n\n[logging]\nlevel = \"info\"  # trace, debug, info, warn, error\nformat = \"pretty\"  # pretty, json, compact\nfile = \"/var/log/uni/uni.log\"\n\n[server]\nhost = \"127.0.0.1\"\nport = 8080\nmax_connections = 100\n\n[object_store.s3]\nbucket = \"my-bucket\"\nregion = \"us-west-2\"\n# Credentials from environment or IAM role\n</code></pre>"},{"location":"reference/configuration/#schema-configuration","title":"Schema Configuration","text":""},{"location":"reference/configuration/#schema-json-format","title":"Schema JSON Format","text":"<p>Important: The schema JSON format used by <code>uni</code> requires internal metadata fields (<code>created_at</code>, <code>state</code>, <code>added_in</code>) for correct deserialization, even though they are often managed automatically by the system. When manually creating a schema file, you must include these fields.</p> <pre><code>{\n  \"schema_version\": 1,\n\n  \"labels\": {\n    \"Paper\": {\n      \"id\": 1,\n      \"is_document\": false,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"Active\"\n    },\n    \"Author\": {\n      \"id\": 2,\n      \"is_document\": false,\n      \"created_at\": \"2024-01-01T00:00:00Z\",\n      \"state\": \"Active\"\n    }\n  },\n\n  \"edge_types\": {\n    \"CITES\": {\n      \"id\": 1,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Paper\"],\n      \"state\": \"Active\"\n    },\n    \"AUTHORED_BY\": {\n      \"id\": 2,\n      \"src_labels\": [\"Paper\"],\n      \"dst_labels\": [\"Author\"],\n      \"state\": \"Active\"\n    }\n  },\n\n  \"properties\": {\n    \"Paper\": {\n      \"title\": {\n        \"type\": \"String\",\n        \"nullable\": false,\n        \"added_in\": 1,\n        \"state\": \"Active\"\n      },\n      \"year\": {\n        \"type\": \"Int32\",\n        \"nullable\": true,\n        \"added_in\": 1,\n        \"state\": \"Active\"\n      },\n      \"embedding\": {\n        \"type\": \"Vector\",\n        \"dimensions\": 768,\n        \"nullable\": true,\n        \"added_in\": 1,\n        \"state\": \"Active\"\n      }\n    },\n    \"Author\": {\n      \"name\": {\n        \"type\": \"String\",\n        \"nullable\": false,\n        \"added_in\": 1,\n        \"state\": \"Active\"\n      }\n    }\n  },\n\n  \"indexes\": [\n    {\n      \"type\": \"Vector\",\n      \"name\": \"paper_embeddings\",\n      \"label\": \"Paper\",\n      \"property\": \"embedding\",\n      \"index_type\": {\n        \"Hnsw\": {\n          \"m\": 32,\n          \"ef_construction\": 200,\n          \"ef_search\": 100\n        }\n      },\n      \"metric\": \"Cosine\"\n    },\n    {\n      \"type\": \"Scalar\",\n      \"name\": \"paper_year\",\n      \"label\": \"Paper\",\n      \"properties\": [\"year\"],\n      \"index_type\": \"BTree\"\n    },\n    {\n      \"type\": \"Scalar\",\n      \"name\": \"composite_venue_year\",\n      \"label\": \"Paper\",\n      \"properties\": [\"venue\", \"year\"],\n      \"index_type\": \"BTree\"\n    }\n  ]\n}\n</code></pre> <p>Note on Case Sensitivity: The JSON schema parser is generally case-sensitive for enum values. Use PascalCase for types (e.g., <code>Vector</code>, <code>Scalar</code>, <code>BTree</code>, <code>Hnsw</code>, <code>Active</code>) as shown in the example above.</p>"},{"location":"reference/configuration/#data-types","title":"Data Types","text":"Type JSON Name Description Boolean <code>Bool</code> true/false 32-bit integer <code>Int32</code> -2\u00b3\u00b9 to 2\u00b3\u00b9-1 64-bit integer <code>Int64</code> -2\u2076\u00b3 to 2\u2076\u00b3-1 64-bit float <code>Float64</code> IEEE 754 double String <code>String</code> UTF-8 text Binary <code>Bytes</code> Raw bytes Vector <code>Vector</code> Float32 array (requires <code>dimensions</code>) Timestamp <code>Timestamp</code> UTC datetime JSON <code>Json</code> Semi-structured data"},{"location":"reference/configuration/#performance-profiles","title":"Performance Profiles","text":""},{"location":"reference/configuration/#high-throughput-batch-processing","title":"High Throughput (Batch Processing)","text":"<pre><code>let storage_config = StorageConfig {\n    max_l0_size: 512 * 1024 * 1024,  // 512 MB\n    max_mutations_before_flush: 100_000,\n    wal_sync_mode: WalSyncMode::Async,\n    adjacency_cache_size: 10_000_000,\n    ..Default::default()\n};\n\nlet executor_config = ExecutorConfig {\n    worker_threads: num_cpus::get(),\n    morsel_size: 8192,\n    batch_size: 8192,\n    memory_limit: 16 * 1024 * 1024 * 1024,\n    ..Default::default()\n};\n</code></pre>"},{"location":"reference/configuration/#low-latency-interactive","title":"Low Latency (Interactive)","text":"<pre><code>let storage_config = StorageConfig {\n    max_l0_size: 32 * 1024 * 1024,  // 32 MB\n    max_mutations_before_flush: 1_000,\n    wal_sync_mode: WalSyncMode::Sync,\n    adjacency_cache_size: 5_000_000,\n    property_cache_size: 500_000,\n    ..Default::default()\n};\n\nlet executor_config = ExecutorConfig {\n    worker_threads: 4,\n    morsel_size: 1024,\n    batch_size: 2048,\n    timeout: Duration::from_secs(30),\n    ..Default::default()\n};\n</code></pre>"},{"location":"reference/configuration/#memory-constrained","title":"Memory Constrained","text":"<pre><code>let storage_config = StorageConfig {\n    max_l0_size: 16 * 1024 * 1024,  // 16 MB\n    adjacency_cache_size: 100_000,\n    property_cache_size: 10_000,\n    ..Default::default()\n};\n\nlet executor_config = ExecutorConfig {\n    worker_threads: 2,\n    morsel_size: 512,\n    batch_size: 1024,\n    memory_limit: 512 * 1024 * 1024,  // 512 MB\n    ..Default::default()\n};\n</code></pre>"},{"location":"reference/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Rust API Reference \u2014 Complete API documentation</li> <li>Troubleshooting \u2014 Common issues and solutions</li> <li>Performance Tuning \u2014 Optimization strategies</li> </ul>"},{"location":"reference/glossary/","title":"Glossary","text":"<p>A comprehensive glossary of terms used throughout the Uni documentation.</p>"},{"location":"reference/glossary/#a","title":"A","text":""},{"location":"reference/glossary/#adjacency-cache","title":"Adjacency Cache","text":"<p>An in-memory cache storing graph topology in Compressed Sparse Row (CSR) format. Enables O(1) neighbor lookups for fast graph traversal. See Vectorized Execution.</p>"},{"location":"reference/glossary/#aggregation","title":"Aggregation","text":"<p>A Cypher operation that combines multiple rows into summary values. Supported functions include <code>COUNT</code>, <code>SUM</code>, <code>AVG</code>, <code>MIN</code>, <code>MAX</code>, and <code>COLLECT</code>. See Cypher Querying.</p>"},{"location":"reference/glossary/#ann-approximate-nearest-neighbor","title":"ANN (Approximate Nearest Neighbor)","text":"<p>A class of algorithms that find vectors similar to a query vector without exhaustive comparison. Uni supports HNSW and IVF_PQ for ANN search. See Vector Search.</p>"},{"location":"reference/glossary/#apache-arrow","title":"Apache Arrow","text":"<p>A columnar memory format for flat and hierarchical data. Uni uses Arrow internally for zero-copy data processing and SIMD-accelerated operations. See Architecture.</p>"},{"location":"reference/glossary/#b","title":"B","text":""},{"location":"reference/glossary/#batch","title":"Batch","text":"<p>A group of rows processed together in vectorized execution. Typical batch sizes are 1024-8192 rows, chosen to fit in CPU cache. See Vectorized Execution.</p>"},{"location":"reference/glossary/#b-tree-index","title":"B-Tree Index","text":"<p>A balanced tree data structure for ordered data. Used for range queries (<code>&lt;</code>, <code>&gt;</code>, <code>BETWEEN</code>). See Indexing.</p>"},{"location":"reference/glossary/#c","title":"C","text":""},{"location":"reference/glossary/#compaction","title":"Compaction","text":"<p>The process of merging multiple data files into fewer, larger files. In Uni, L1 runs are compacted into L2. See Storage Engine.</p>"},{"location":"reference/glossary/#csr-compressed-sparse-row","title":"CSR (Compressed Sparse Row)","text":"<p>A compact representation of sparse matrices (graphs). Stores vertex neighbors in contiguous arrays with offset pointers. Used in the adjacency cache for efficient traversal.</p>"},{"location":"reference/glossary/#cypher","title":"Cypher","text":"<p>A declarative graph query language using ASCII-art patterns. Originally developed for Neo4j, now standardized as OpenCypher. Uni implements a substantial subset. See Cypher Querying.</p>"},{"location":"reference/glossary/#d","title":"D","text":""},{"location":"reference/glossary/#datafusion","title":"DataFusion","text":"<p>An Apache Arrow-native query engine. Uni uses DataFusion for columnar processing, aggregations, and some query operations.</p>"},{"location":"reference/glossary/#direction","title":"Direction","text":"<p>The orientation of an edge traversal: - Outgoing (<code>-[r]-&gt;</code>): From source to target - Incoming (<code>&lt;-[r]-</code>): From target to source - Both** (<code>-[r]-</code>): Either direction</p>"},{"location":"reference/glossary/#document-mode","title":"Document Mode","text":"<p>A schema option (<code>is_document: true</code>) that enables flexible, semi-structured data storage. Vertices in document mode can have a <code>_doc</code> field containing arbitrary JSON.</p>"},{"location":"reference/glossary/#e","title":"E","text":""},{"location":"reference/glossary/#edge","title":"Edge","text":"<p>A connection between two vertices in a graph. In Uni, edges have: - Type: Category of relationship (e.g., <code>CITES</code>, <code>AUTHORED_BY</code>) - Direction: From source to destination - Properties: Optional key-value attributes</p>"},{"location":"reference/glossary/#eid-edge-id","title":"EID (Edge ID)","text":"<p>A 64-bit identifier for edges. Encoded as <code>edge_type_id (16 bits) | local_offset (48 bits)</code>. See Identity Model.</p>"},{"location":"reference/glossary/#embedding","title":"Embedding","text":"<p>A dense vector representation of data (text, images, etc.) in a high-dimensional space. Similar items have embeddings close together. See Vector Search.</p>"},{"location":"reference/glossary/#explain","title":"EXPLAIN","text":"<p>A Cypher command prefix that shows the query plan without executing the query. Useful for understanding how queries will be processed.</p>"},{"location":"reference/glossary/#f","title":"F","text":""},{"location":"reference/glossary/#fastembed","title":"FastEmbed","text":"<p>A Rust library for generating text embeddings locally. Uni integrates FastEmbed for on-device embedding generation without external API calls. See Vector Search.</p>"},{"location":"reference/glossary/#flush","title":"Flush","text":"<p>The process of writing in-memory data (L0) to persistent storage (L1). Triggered by size thresholds or explicit calls.</p>"},{"location":"reference/glossary/#g","title":"G","text":""},{"location":"reference/glossary/#graph-database","title":"Graph Database","text":"<p>A database optimized for storing and querying connected data. Models data as vertices (nodes) and edges (relationships) rather than tables and rows.</p>"},{"location":"reference/glossary/#gryf","title":"gryf","text":"<p>A Rust graph library providing in-memory graph structures and algorithms. Uni uses gryf for the L0 buffer and working graphs.</p>"},{"location":"reference/glossary/#h","title":"H","text":""},{"location":"reference/glossary/#hash-index","title":"Hash Index","text":"<p>An index structure using hash tables for O(1) equality lookups. Best for exact match queries on high-cardinality columns.</p>"},{"location":"reference/glossary/#hnsw-hierarchical-navigable-small-world","title":"HNSW (Hierarchical Navigable Small World)","text":"<p>A graph-based algorithm for approximate nearest neighbor search. Provides high recall and fast queries at the cost of memory. See Indexing.</p>"},{"location":"reference/glossary/#i","title":"I","text":""},{"location":"reference/glossary/#ivf_pq-inverted-file-with-product-quantization","title":"IVF_PQ (Inverted File with Product Quantization)","text":"<p>A vector index that partitions vectors into clusters and compresses them. Lower memory than HNSW but typically lower recall.</p>"},{"location":"reference/glossary/#j","title":"J","text":""},{"location":"reference/glossary/#jsonl-json-lines","title":"JSONL (JSON Lines)","text":"<p>A text format with one JSON object per line. Uni's primary format for bulk data import.</p>"},{"location":"reference/glossary/#k","title":"K","text":""},{"location":"reference/glossary/#knn-k-nearest-neighbors","title":"KNN (K-Nearest Neighbors)","text":"<p>Finding the K vectors most similar to a query vector. Uni's vector search returns KNN results ordered by distance.</p>"},{"location":"reference/glossary/#l","title":"L","text":""},{"location":"reference/glossary/#l0-buffer","title":"L0 Buffer","text":"<p>The in-memory write buffer that accepts all incoming mutations. Contains a gryf graph for topology and Arrow builders for properties. See Storage Engine.</p>"},{"location":"reference/glossary/#l1-layer","title":"L1 Layer","text":"<p>Immutable Lance datasets created by flushing L0. Contains sorted runs of data not yet compacted into L2.</p>"},{"location":"reference/glossary/#l2-layer","title":"L2 Layer","text":"<p>The base storage layer containing fully compacted, indexed data. Most data resides here after compaction.</p>"},{"location":"reference/glossary/#label","title":"Label","text":"<p>A type classifier for vertices (e.g., <code>Paper</code>, <code>Author</code>). Similar to a table name in relational databases. Encoded in the VID.</p>"},{"location":"reference/glossary/#lance","title":"Lance","text":"<p>A columnar data format optimized for ML workloads. Features native vector indexing, versioning, and cloud storage support. Uni uses Lance as its primary storage format. See Storage Engine.</p>"},{"location":"reference/glossary/#late-materialization","title":"Late Materialization","text":"<p>An optimization that delays loading heavy properties until after filtering. Reduces I/O by only loading data for rows that survive filters. See Vectorized Execution.</p>"},{"location":"reference/glossary/#lsm-tree-log-structured-merge-tree","title":"LSM Tree (Log-Structured Merge Tree)","text":"<p>A storage architecture with tiered levels (L0, L1, L2). Writes go to memory first, then flush to immutable files that are periodically compacted.</p>"},{"location":"reference/glossary/#m","title":"M","text":""},{"location":"reference/glossary/#manifest","title":"Manifest","text":"<p>A JSON file describing the state of storage at a point in time. Contains dataset versions, index metadata, and L1 run information. Enables snapshot isolation.</p>"},{"location":"reference/glossary/#match","title":"MATCH","text":"<p>The primary Cypher clause for specifying graph patterns to find. Uses ASCII-art syntax like <code>(a)-[r]-&gt;(b)</code>.</p>"},{"location":"reference/glossary/#morsel","title":"Morsel","text":"<p>A work unit in parallel execution. Source data is divided into morsels that workers process independently. See Vectorized Execution.</p>"},{"location":"reference/glossary/#n","title":"N","text":""},{"location":"reference/glossary/#node","title":"Node","text":"<p>See Vertex.</p>"},{"location":"reference/glossary/#o","title":"O","text":""},{"location":"reference/glossary/#opencypher","title":"OpenCypher","text":"<p>An open standard for the Cypher query language. Uni implements a substantial subset of OpenCypher.</p>"},{"location":"reference/glossary/#p","title":"P","text":""},{"location":"reference/glossary/#predicate-pushdown","title":"Predicate Pushdown","text":"<p>An optimization that pushes filter conditions down to the storage layer. Reduces I/O by filtering at scan time rather than after loading. See Query Planning.</p>"},{"location":"reference/glossary/#profile","title":"Profile","text":"<p>A Cypher command prefix that executes the query and shows detailed timing for each operation. More informative than EXPLAIN.</p>"},{"location":"reference/glossary/#property","title":"Property","text":"<p>A key-value attribute on a vertex or edge. Properties have defined types (String, Int32, Vector, etc.) in the schema.</p>"},{"location":"reference/glossary/#property-graph","title":"Property Graph","text":"<p>A data model where vertices and edges can have arbitrary properties. More flexible than simple labeled graphs.</p>"},{"location":"reference/glossary/#q","title":"Q","text":""},{"location":"reference/glossary/#query-plan","title":"Query Plan","text":"<p>The sequence of operations that will execute a query. Includes logical plan (what to do) and physical plan (how to do it).</p>"},{"location":"reference/glossary/#r","title":"R","text":""},{"location":"reference/glossary/#recordbatch","title":"RecordBatch","text":"<p>An Apache Arrow data structure containing a batch of columnar data with a shared schema. The fundamental data unit in vectorized execution.</p>"},{"location":"reference/glossary/#relationship","title":"Relationship","text":"<p>See Edge.</p>"},{"location":"reference/glossary/#s","title":"S","text":""},{"location":"reference/glossary/#schema","title":"Schema","text":"<p>The structure definition for a graph, including: - Labels and their properties - Edge types and constraints - Vector dimensions - Indexes</p>"},{"location":"reference/glossary/#selection-vector","title":"Selection Vector","text":"<p>A bitmap or index array marking which rows in a batch are \"active\" after filtering. Avoids copying data when filtering.</p>"},{"location":"reference/glossary/#simd-single-instruction-multiple-data","title":"SIMD (Single Instruction, Multiple Data)","text":"<p>CPU instructions that operate on multiple data elements simultaneously. Arrow compute kernels use SIMD for fast filtering and arithmetic.</p>"},{"location":"reference/glossary/#snapshot","title":"Snapshot","text":"<p>A consistent point-in-time view of the database. Readers see a stable snapshot even as writes occur.</p>"},{"location":"reference/glossary/#snapshot-isolation","title":"Snapshot Isolation","text":"<p>A concurrency model where each reader sees a consistent snapshot. Readers don't block writers and vice versa.</p>"},{"location":"reference/glossary/#t","title":"T","text":""},{"location":"reference/glossary/#tombstone","title":"Tombstone","text":"<p>A marker indicating deleted data. Soft deletes mark rows as deleted; compaction removes tombstoned data.</p>"},{"location":"reference/glossary/#traversal","title":"Traversal","text":"<p>Following edges from vertices to discover connected vertices. A fundamental graph operation.</p>"},{"location":"reference/glossary/#u","title":"U","text":""},{"location":"reference/glossary/#unwind","title":"UNWIND","text":"<p>A Cypher clause that expands a list into multiple rows. Useful for batch operations and working with array properties.</p>"},{"location":"reference/glossary/#v","title":"V","text":""},{"location":"reference/glossary/#vector-index","title":"Vector Index","text":"<p>A data structure enabling fast similarity search on high-dimensional vectors. Uni supports HNSW and IVF_PQ vector indexes.</p>"},{"location":"reference/glossary/#vectorized-execution","title":"Vectorized Execution","text":"<p>A query processing model that operates on batches of rows rather than one row at a time. Improves performance through better cache utilization and SIMD operations. See Vectorized Execution.</p>"},{"location":"reference/glossary/#vertex","title":"Vertex","text":"<p>A node in the graph representing an entity. In Uni, vertices have: - VID: Unique identifier - Label: Type classification - Properties: Key-value attributes</p>"},{"location":"reference/glossary/#vid-vertex-id","title":"VID (Vertex ID)","text":"<p>A 64-bit identifier for vertices. Encoded as <code>label_id (16 bits) | local_offset (48 bits)</code>. See Identity Model.</p>"},{"location":"reference/glossary/#w","title":"W","text":""},{"location":"reference/glossary/#wal-write-ahead-log","title":"WAL (Write-Ahead Log)","text":"<p>A durability mechanism that logs mutations before applying them. Enables recovery after crashes.</p>"},{"location":"reference/glossary/#uniid","title":"UniId","text":"<p>A content-addressed identifier using SHA3-256 hash (32 bytes). Used for provenance tracking and distributed synchronization with CRDT systems. See Identity Model.</p>"},{"location":"reference/glossary/#with","title":"WITH","text":"<p>A Cypher clause that pipes results from one query part to another. Enables subquery-like behavior and intermediate aggregations.</p>"},{"location":"reference/glossary/#working-graph","title":"Working Graph","text":"<p>An in-memory graph materialized from storage for query execution. Backed by gryf.</p>"},{"location":"reference/glossary/#y","title":"Y","text":""},{"location":"reference/glossary/#yield","title":"YIELD","text":"<p>A Cypher clause used with CALL to specify which columns to return from a procedure. Used with vector search and other built-in procedures.</p>"},{"location":"reference/glossary/#common-abbreviations","title":"Common Abbreviations","text":"Abbreviation Meaning ANN Approximate Nearest Neighbor CSR Compressed Sparse Row EID Edge ID HNSW Hierarchical Navigable Small World IVF Inverted File KNN K-Nearest Neighbors L0/L1/L2 Storage layer levels LSM Log-Structured Merge PQ Product Quantization SIMD Single Instruction Multiple Data VID Vertex ID WAL Write-Ahead Log"},{"location":"reference/glossary/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture \u2014 System overview</li> <li>Rust API Reference \u2014 Complete API documentation</li> <li>Configuration Reference \u2014 All configuration options</li> </ul>"},{"location":"reference/python-api/","title":"Python API Reference","text":"<p>Uni provides full-featured Python bindings with type hints and comprehensive documentation.</p>"},{"location":"reference/python-api/#installation","title":"Installation","text":"<pre><code>pip install uni\n</code></pre> <p>Or build from source:</p> <pre><code>cd bindings/python\npip install maturin\nmaturin develop --release\n</code></pre>"},{"location":"reference/python-api/#quick-start","title":"Quick Start","text":"<pre><code>import uni\n\n# Open or create a database\ndb = uni.Database(\"/path/to/db\")\n\n# Or use the builder pattern\ndb = uni.DatabaseBuilder.open(\"/path/to/db\").build()\n\n# Create schema\ndb.create_label(\"Person\")\ndb.add_property(\"Person\", \"name\", \"string\", False)\ndb.add_property(\"Person\", \"age\", \"int\", False)\n\n# Insert data\ndb.query(\"CREATE (n:Person {name: 'Alice', age: 30})\")\ndb.query(\"CREATE (n:Person {name: 'Bob', age: 25})\")\n\n# Query data\nresults = db.query(\"MATCH (n:Person) WHERE n.age &gt; 20 RETURN n.name AS name\")\nfor row in results:\n    print(row[\"name\"])\n</code></pre>"},{"location":"reference/python-api/#core-classes","title":"Core Classes","text":""},{"location":"reference/python-api/#database","title":"Database","text":"<p>The main database interface. Create using <code>Database(path)</code> or <code>DatabaseBuilder</code>.</p> <pre><code>db = uni.Database(\"/path/to/db\")\n\n# Execute queries\nresults = db.query(\"MATCH (n) RETURN n LIMIT 10\")\naffected = db.execute(\"CREATE (n:Person {name: 'Alice'})\")\n\n# Parameterized queries\nresults = db.query(\n    \"MATCH (n:Person) WHERE n.name = $name RETURN n\",\n    {\"name\": \"Alice\"}\n)\n\n# Or use QueryBuilder\nbuilder = db.query_with(\"MATCH (n:Person) WHERE n.age &gt; $min RETURN n\")\nbuilder.param(\"min\", 21)\nresults = builder.fetch_all()\n</code></pre>"},{"location":"reference/python-api/#databasebuilder","title":"DatabaseBuilder","text":"<p>Fluent builder for database configuration:</p> <pre><code># Create new database (fails if exists)\ndb = uni.DatabaseBuilder.create(\"/path/to/db\").build()\n\n# Open existing (fails if doesn't exist)\ndb = uni.DatabaseBuilder.open_existing(\"/path/to/db\").build()\n\n# Open or create\ndb = uni.DatabaseBuilder.open(\"/path/to/db\").build()\n\n# Temporary in-memory database\ndb = uni.DatabaseBuilder.temporary().build()\n\n# With configuration\ndb = (\n    uni.DatabaseBuilder.open(\"/path/to/db\")\n    .cache_size(1024 * 1024 * 100)  # 100 MB\n    .parallelism(4)\n    .build()\n)\n</code></pre>"},{"location":"reference/python-api/#schemabuilder","title":"SchemaBuilder","text":"<p>Fluent API for schema definition:</p> <pre><code>schema = db.schema()\nschema = schema.label(\"Person\").property(\"name\", \"string\").property(\"age\", \"int\").done()\nschema = schema.label(\"Company\").property(\"name\", \"string\").done()\nschema = schema.edge_type(\"WORKS_AT\", [\"Person\"], [\"Company\"]).property(\"since\", \"int\").done()\nschema.apply()\n</code></pre>"},{"location":"reference/python-api/#transaction","title":"Transaction","text":"<p>ACID transactions:</p> <pre><code>tx = db.begin()\ntry:\n    tx.query(\"CREATE (n:Person {name: 'Alice'})\")\n    tx.query(\"CREATE (n:Person {name: 'Bob'})\")\n    tx.commit()\nexcept Exception:\n    tx.rollback()\n</code></pre>"},{"location":"reference/python-api/#session","title":"Session","text":"<p>Scoped sessions with variables:</p> <pre><code>session = db.session().set(\"user_id\", 123).build()\nresults = session.query(\"MATCH (n:Person) RETURN n\")\nuser_id = session.get(\"user_id\")\n</code></pre>"},{"location":"reference/python-api/#bulkwriter","title":"BulkWriter","text":"<p>High-performance bulk loading:</p> <pre><code>writer = db.bulk_writer().batch_size(10000).build()\n\n# Insert vertices\nvids = writer.insert_vertices(\"Person\", [\n    {\"name\": \"Alice\", \"age\": 30},\n    {\"name\": \"Bob\", \"age\": 25},\n])\n\n# Insert edges\nwriter.insert_edges(\"KNOWS\", [\n    (vids[0], vids[1], {\"since\": 2020}),\n])\n\n# Commit and build indexes\nstats = writer.commit()\nprint(f\"Inserted {stats.vertices_inserted} vertices\")\n</code></pre>"},{"location":"reference/python-api/#vectorsearch","title":"VectorSearch","text":"<p>Vector similarity search:</p> <pre><code># Create vector index\ndb.add_property(\"Document\", \"embedding\", \"vector:128\", False)\ndb.create_vector_index(\"Document\", \"embedding\", \"cosine\")\n\n# Search\nquery_vec = [0.1, 0.2, ...]  # 128 dimensions\nmatches = db.vector_search(\"Document\", \"embedding\", query_vec, k=10)\n\nfor match in matches:\n    print(f\"VID: {match.vid}, Distance: {match.distance}\")\n\n# Builder pattern with threshold\nmatches = (\n    db.vector_search_with(\"Document\", \"embedding\", query_vec)\n    .k(10)\n    .threshold(0.5)\n    .search()\n)\n</code></pre>"},{"location":"reference/python-api/#data-types","title":"Data Types","text":"<p>Supported property data types:</p> Type Python Description <code>string</code> <code>str</code> UTF-8 string <code>int</code> <code>int</code> 64-bit integer <code>float</code> <code>float</code> 64-bit float <code>bool</code> <code>bool</code> Boolean <code>vector:N</code> <code>list[float]</code> N-dimensional vector"},{"location":"reference/python-api/#query-results","title":"Query Results","text":"<p>Query results are returned as <code>list[dict[str, Any]]</code>:</p> <pre><code>results = db.query(\"MATCH (n:Person) RETURN n.name AS name, n.age AS age\")\nfor row in results:\n    print(f\"Name: {row['name']}, Age: {row['age']}\")\n</code></pre>"},{"location":"reference/python-api/#explain-and-profile","title":"EXPLAIN and PROFILE","text":"<p>Analyze query execution:</p> <pre><code># Get query plan without executing\nplan = db.explain(\"MATCH (n:Person) RETURN n\")\nprint(plan[\"plan_text\"])\nprint(plan[\"cost_estimates\"])\n\n# Execute with profiling\nresults, profile = db.profile(\"MATCH (n:Person) RETURN n\")\nprint(f\"Total time: {profile['total_time_ms']}ms\")\nprint(f\"Peak memory: {profile['peak_memory_bytes']} bytes\")\n</code></pre>"},{"location":"reference/python-api/#snapshots","title":"Snapshots","text":"<p>Point-in-time snapshots:</p> <pre><code># Create snapshot\nsnapshot_id = db.create_snapshot(\"before_migration\")\n\n# List snapshots\nfor snap in db.list_snapshots():\n    print(f\"{snap.snapshot_id}: {snap.name} ({snap.vertex_count} vertices)\")\n\n# Open read-only view at snapshot\nold_db = db.at_snapshot(snapshot_id)\nresults = old_db.query(\"MATCH (n) RETURN count(n)\")\n\n# Restore to snapshot\ndb.restore_snapshot(snapshot_id)\n</code></pre>"},{"location":"reference/python-api/#error-handling","title":"Error Handling","text":"<p>The library raises standard Python exceptions:</p> <ul> <li><code>RuntimeError</code>: Query execution errors</li> <li><code>ValueError</code>: Invalid parameters</li> <li><code>OSError</code>: Database I/O errors</li> </ul> <pre><code>try:\n    db.query(\"INVALID CYPHER\")\nexcept RuntimeError as e:\n    print(f\"Query error: {e}\")\n</code></pre>"},{"location":"reference/python-api/#full-api-documentation","title":"Full API Documentation","text":"<p>See the auto-generated pdoc documentation for complete API details.</p>"},{"location":"reference/rest-api/","title":"REST API Reference","text":"<p>Uni provides a lightweight HTTP API for remote query execution and monitoring. The server is optional and can be started via the CLI or embedded in your application.</p>"},{"location":"reference/rest-api/#overview","title":"Overview","text":"<ul> <li>Base URL: <code>http://&lt;host&gt;:&lt;port&gt;</code> (Default: <code>http://127.0.0.1:8080</code>)</li> <li>Version: <code>v1</code></li> <li>Content-Type: <code>application/json</code></li> </ul>"},{"location":"reference/rest-api/#endpoints","title":"Endpoints","text":""},{"location":"reference/rest-api/#execute-query","title":"Execute Query","text":"<p>Execute a Cypher query against the database.</p> <p>Endpoint: <code>POST /api/v1/query</code></p>"},{"location":"reference/rest-api/#request-body","title":"Request Body","text":"Field Type Required Description <code>query</code> string Yes The Cypher query string to execute. <code>params</code> object No A map of parameter names to values (for <code>$param</code> usage). <p>Example Request:</p> <pre><code>{\n  \"query\": \"MATCH (n:Person) WHERE n.age &gt; $min_age RETURN n.name, n.age LIMIT 5\",\n  \"params\": {\n    \"min_age\": 30\n  }\n}\n</code></pre>"},{"location":"reference/rest-api/#response","title":"Response","text":"<p>Success (200 OK):</p> Field Type Description <code>columns</code> string[] List of column names in the result. <code>rows</code> any[][] Array of rows, where each row is an array of values corresponding to <code>columns</code>. <code>execution_time_ms</code> number Time taken to execute the query in milliseconds. <p>Example Response:</p> <pre><code>{\n  \"columns\": [\"n.name\", \"n.age\"],\n  \"rows\": [\n    [\"Alice\", 32],\n    [\"Bob\", 45]\n  ],\n  \"execution_time_ms\": 12\n}\n</code></pre> <p>Error (400 Bad Request):</p> <pre><code>{\n  \"error\": \"Parse error: Unexpected token at line 1...\"\n}\n</code></pre>"},{"location":"reference/rest-api/#metrics","title":"Metrics","text":"<p>Retrieve Prometheus-compatible metrics for monitoring database health and performance.</p> <p>Endpoint: <code>GET /api/v1/metrics</code></p> <p>Response (200 OK): Text-based Prometheus format.</p> <pre><code># HELP uni_query_duration_seconds Query execution duration\n# TYPE uni_query_duration_seconds histogram\nuni_query_duration_seconds_bucket{le=\"0.005\"} 12\n...\n</code></pre> <p>(Note: Metrics availability depends on feature flags and server configuration.)</p>"},{"location":"reference/rest-api/#data-types","title":"Data Types","text":"<p>JSON values in the response map to Uni's internal types as follows:</p> Uni Type JSON Representation <code>String</code> String <code>Integer</code> Number <code>Float</code> Number <code>Boolean</code> Boolean <code>Null</code> <code>null</code> <code>Vector</code> Array of numbers <code>[0.1, 0.2, ...]</code> <code>Node</code> Object <code>{\"_id\": \"...\", \"_label\": \"...\", \"properties\": {...}}</code> <code>Edge</code> Object <code>{\"_id\": \"...\", \"_type\": \"...\", \"_src\": \"...\", \"_dst\": \"...\", \"properties\": {...}}</code> <code>Path</code> Object <code>{\"nodes\": [...], \"edges\": [...]}</code>"},{"location":"reference/rest-api/#errors","title":"Errors","text":"<p>The API uses standard HTTP status codes:</p> <ul> <li><code>200 OK</code>: Query executed successfully.</li> <li><code>400 Bad Request</code>: Invalid JSON, parse error, or runtime error during query execution.</li> <li><code>404 Not Found</code>: Endpoint not found.</li> <li><code>500 Internal Server Error</code>: Unexpected server-side failure.</li> </ul>"},{"location":"reference/rust-api/","title":"Rust API Reference","text":"<p>Uni provides a comprehensive Rust API for embedding the graph database directly into your application. This reference covers all public APIs.</p>"},{"location":"reference/rust-api/#quick-start","title":"Quick Start","text":"<pre><code>use uni::prelude::*;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Open or create database\n    let db = Uni::open(\"./my-graph\")\n        .schema_file(\"schema.json\")\n        .build()\n        .await?;\n\n    // Run a query\n    let results = db.query(\"MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN p.title LIMIT 10\").await?;\n\n    for row in &amp;results {\n        let title: String = row.get(\"p.title\")?;\n        println!(\"{}\", title);\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"reference/rust-api/#module-uni","title":"Module: <code>uni</code>","text":"<p>The main entry point for the database.</p>"},{"location":"reference/rust-api/#uni","title":"Uni","text":"<pre><code>/// Main database instance\npub struct Uni {\n    // Internal state\n}\n\nimpl Uni {\n    /// Open or create a database at the given path\n    pub fn open(path: impl AsRef&lt;Path&gt;) -&gt; UniBuilder;\n\n    /// Create an in-memory database\n    pub fn in_memory() -&gt; UniBuilder;\n\n    /// Get current configuration\n    pub fn config(&amp;self) -&gt; &amp;UniConfig;\n\n    /// Get current schema\n    pub fn current_schema(&amp;self) -&gt; Schema;\n\n    /// Flush uncommitted changes to storage\n    pub async fn flush(&amp;self) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#unibuilder","title":"UniBuilder","text":"<pre><code>/// Fluent builder for database instances\npub struct UniBuilder {\n    // Internal state\n}\n\nimpl UniBuilder {\n    /// Set schema from JSON file\n    pub fn schema_file(self, path: impl AsRef&lt;Path&gt;) -&gt; Self;\n\n    /// Set configuration\n    pub fn config(self, config: UniConfig) -&gt; Self;\n\n    /// Set cache size in bytes\n    pub fn cache_size(self, bytes: usize) -&gt; Self;\n\n    /// Set parallelism (worker threads)\n    pub fn parallelism(self, n: usize) -&gt; Self;\n\n    /// Build the database instance (async)\n    pub async fn build(self) -&gt; Result&lt;Uni&gt;;\n\n    /// Build the database instance (blocking)\n    pub fn build_sync(self) -&gt; Result&lt;Uni&gt;;\n}\n\n// Example\nlet db = Uni::open(\"./data\")\n    .schema_file(\"schema.json\")\n    .cache_size(2 * 1024 * 1024 * 1024)  // 2 GB\n    .parallelism(8)\n    .build()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#queries","title":"Queries","text":""},{"location":"reference/rust-api/#basic-queries","title":"Basic Queries","text":"<pre><code>impl Uni {\n    /// Execute a Cypher query\n    pub async fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n\n    /// Execute a query with parameters\n    pub fn query_with(&amp;self, cypher: &amp;str) -&gt; QueryBuilder&lt;'_&gt;;\n\n    /// Execute a mutation (CREATE, SET, DELETE, MERGE)\n    pub async fn execute(&amp;self, cypher: &amp;str) -&gt; Result&lt;ExecuteResult&gt;;\n}\n\n// Simple query\nlet results = db.query(\"MATCH (p:Paper) RETURN p.title, p.year\").await?;\n\n// Query with parameters\nlet results = db.query_with(\"MATCH (p:Paper) WHERE p.year &gt; $year RETURN p\")\n    .param(\"year\", 2020)\n    .fetch_all()\n    .await?;\n\n// Mutation\nlet result = db.execute(\"CREATE (p:Paper {title: 'New Paper', year: 2024})\").await?;\nprintln!(\"Created {} nodes\", result.affected_rows);\n</code></pre>"},{"location":"reference/rust-api/#querybuilder","title":"QueryBuilder","text":"<pre><code>/// Builder for parameterized queries\npub struct QueryBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; QueryBuilder&lt;'a&gt; {\n    /// Add a parameter\n    pub fn param&lt;V: Into&lt;Value&gt;&gt;(self, name: &amp;str, value: V) -&gt; Self;\n\n    /// Add multiple parameters\n    pub fn params(self, params: HashMap&lt;String, Value&gt;) -&gt; Self;\n\n    /// Execute and fetch all results\n    pub async fn fetch_all(self) -&gt; Result&lt;QueryResult&gt;;\n}\n\n// Example with multiple parameters\nlet results = db.query_with(\n    \"MATCH (a:Author)-[:AUTHORED]-&gt;(p:Paper)\n     WHERE a.name = $name AND p.year &gt;= $min_year\n     RETURN p.title, p.year\"\n)\n    .param(\"name\", \"Jane Smith\")\n    .param(\"min_year\", 2020)\n    .fetch_all()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#sessions","title":"Sessions","text":"<p>Sessions provide scoped context for multi-tenant and security-aware queries.</p>"},{"location":"reference/rust-api/#sessionbuilder","title":"SessionBuilder","text":"<pre><code>impl Uni {\n    /// Create a session builder with scoped variables\n    pub fn session(&amp;self) -&gt; SessionBuilder&lt;'_&gt;;\n}\n\n/// Builder for creating query sessions\npub struct SessionBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; SessionBuilder&lt;'a&gt; {\n    /// Set a session variable\n    pub fn set&lt;K: Into&lt;String&gt;, V: Into&lt;Value&gt;&gt;(self, key: K, value: V) -&gt; Self;\n\n    /// Build the session (variables become immutable)\n    pub fn build(self) -&gt; Session&lt;'a&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#session","title":"Session","text":"<pre><code>/// A query session with scoped variables\npub struct Session&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; Session&lt;'a&gt; {\n    /// Execute a query with session variables available\n    pub async fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n\n    /// Execute a query with additional parameters\n    pub fn query_with(&amp;self, cypher: &amp;str) -&gt; SessionQueryBuilder&lt;'a, '_&gt;;\n\n    /// Execute a mutation\n    pub async fn execute(&amp;self, cypher: &amp;str) -&gt; Result&lt;ExecuteResult&gt;;\n\n    /// Get a session variable value\n    pub fn get(&amp;self, key: &amp;str) -&gt; Option&lt;&amp;Value&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#session-example","title":"Session Example","text":"<pre><code>// Create session with tenant context\nlet session = db.session()\n    .set(\"tenant_id\", \"acme-corp\")\n    .set(\"user_id\", \"user-123\")\n    .set(\"granted_tags\", vec![\"public\", \"team:eng\"])\n    .build();\n\n// All queries automatically have access to $session.*\nlet results = session.query(\n    \"MATCH (d:Document)\n     WHERE d.tenant_id = $session.tenant_id\n     RETURN d.title\"\n).await?;\n\n// Query with additional parameters\nlet results = session.query_with(\n    \"MATCH (d:Document)\n     WHERE d.tenant_id = $session.tenant_id\n       AND d.status = $status\n     RETURN d\"\n)\n    .param(\"status\", \"published\")\n    .fetch_all()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#bulk-loading","title":"Bulk Loading","text":"<p>High-performance data loading with deferred indexing.</p>"},{"location":"reference/rust-api/#bulkwriter","title":"BulkWriter","text":"<pre><code>impl Uni {\n    /// Create a bulk writer builder\n    pub fn bulk_writer(&amp;self) -&gt; BulkWriterBuilder&lt;'_&gt;;\n}\n\n/// Builder for bulk write operations\npub struct BulkWriterBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; BulkWriterBuilder&lt;'a&gt; {\n    /// Defer vector index updates until commit\n    pub fn defer_vector_indexes(self, defer: bool) -&gt; Self;\n\n    /// Defer scalar index updates until commit\n    pub fn defer_scalar_indexes(self, defer: bool) -&gt; Self;\n\n    /// Set batch size for flushing\n    pub fn batch_size(self, size: usize) -&gt; Self;\n\n    /// Build indexes asynchronously after commit\n    pub fn async_indexes(self, async_build: bool) -&gt; Self;\n\n    /// Set progress callback\n    pub fn on_progress&lt;F: Fn(BulkProgress) + Send + 'static&gt;(self, f: F) -&gt; Self;\n\n    /// Build the bulk writer\n    pub fn build(self) -&gt; Result&lt;BulkWriter&lt;'a&gt;&gt;;\n}\n\n/// Bulk writer for high-performance data loading\npub struct BulkWriter&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; BulkWriter&lt;'a&gt; {\n    /// Insert vertices in bulk\n    pub async fn insert_vertices(\n        &amp;mut self,\n        label: &amp;str,\n        vertices: Vec&lt;HashMap&lt;String, Value&gt;&gt;,\n    ) -&gt; Result&lt;Vec&lt;Vid&gt;&gt;;\n\n    /// Insert edges in bulk\n    pub async fn insert_edges(\n        &amp;mut self,\n        edge_type: &amp;str,\n        edges: Vec&lt;EdgeData&gt;,\n    ) -&gt; Result&lt;Vec&lt;Eid&gt;&gt;;\n\n    /// Commit all pending data and rebuild indexes\n    pub async fn commit(self) -&gt; Result&lt;BulkStats&gt;;\n\n    /// Abort bulk operation, discarding uncommitted data\n    pub async fn abort(self) -&gt; Result&lt;()&gt;;\n}\n\n/// Bulk loading progress information\n#[derive(Debug, Clone)]\npub struct BulkProgress {\n    pub phase: BulkPhase,\n    pub rows_processed: usize,\n    pub total_rows: Option&lt;usize&gt;,\n    pub current_label: Option&lt;String&gt;,\n    pub elapsed: Duration,\n}\n\n/// Bulk loading phase\n#[derive(Debug, Clone)]\npub enum BulkPhase {\n    Inserting,\n    RebuildingVectorIndex { label: String, property: String },\n    RebuildingScalarIndex { label: String, property: String },\n    UpdatingAdjacency,\n    Finalizing,\n}\n\n/// Bulk loading statistics\n#[derive(Debug, Clone, Default)]\npub struct BulkStats {\n    pub vertices_inserted: usize,\n    pub edges_inserted: usize,\n    pub indexes_rebuilt: usize,\n    pub duration: Duration,\n    pub index_build_duration: Duration,\n}\n</code></pre>"},{"location":"reference/rust-api/#bulkwriter-example","title":"BulkWriter Example","text":"<pre><code>// Create bulk writer with deferred indexing\nlet mut bulk = db.bulk_writer()\n    .defer_vector_indexes(true)\n    .defer_scalar_indexes(true)\n    .batch_size(50_000)\n    .on_progress(|p| println!(\"{:?}: {} rows\", p.phase, p.rows_processed))\n    .build()?;\n\n// Insert 100K vertices\nlet vertices: Vec&lt;HashMap&lt;String, Value&gt;&gt; = (0..100_000)\n    .map(|i| {\n        hashmap! {\n            \"name\" =&gt; format!(\"item-{}\", i).into(),\n            \"embedding\" =&gt; random_vector(128).into(),\n        }\n    })\n    .collect();\n\nlet vids = bulk.insert_vertices(\"Item\", vertices).await?;\nassert_eq!(vids.len(), 100_000);\n\n// Commit and rebuild indexes\nlet stats = bulk.commit().await?;\nprintln!(\"Loaded {} vertices, rebuilt {} indexes in {:?}\",\n    stats.vertices_inserted, stats.indexes_rebuilt, stats.duration);\n</code></pre>"},{"location":"reference/rust-api/#snapshots","title":"Snapshots","text":"<p>Read-only access to historical database states.</p>"},{"location":"reference/rust-api/#snapshot-management","title":"Snapshot Management","text":"<pre><code>impl Uni {\n    /// List all available snapshots\n    pub async fn list_snapshots(&amp;self) -&gt; Result&lt;Vec&lt;SnapshotInfo&gt;&gt;;\n\n    /// Open a read-only view at a specific snapshot\n    pub async fn at_snapshot(&amp;self, snapshot_id: &amp;str) -&gt; Result&lt;Uni&gt;;\n\n    /// Restore database to a snapshot state\n    pub async fn restore_snapshot(&amp;self, snapshot_id: &amp;str) -&gt; Result&lt;()&gt;;\n}\n\n/// Snapshot metadata\n#[derive(Debug, Clone)]\npub struct SnapshotInfo {\n    pub id: String,\n    pub name: Option&lt;String&gt;,\n    pub created_at: DateTime&lt;Utc&gt;,\n    pub version: u64,\n}\n</code></pre>"},{"location":"reference/rust-api/#snapshot-example","title":"Snapshot Example","text":"<pre><code>// List available snapshots\nlet snapshots = db.list_snapshots().await?;\nfor snap in &amp;snapshots {\n    println!(\"{}: {} ({})\", snap.id, snap.name.as_deref().unwrap_or(\"-\"), snap.created_at);\n}\n\n// Open a read-only view at a specific snapshot\nlet historical = db.at_snapshot(&amp;snapshots[0].id).await?;\n\n// Query historical data\nlet old_results = historical.query(\"MATCH (n) RETURN count(n) AS c\").await?;\nprintln!(\"Count at snapshot: {}\", old_results[0].get::&lt;i64&gt;(\"c\")?);\n\n// Writes fail on snapshot readers\nlet result = historical.execute(\"CREATE (n:Test)\").await;\nassert!(result.is_err()); // WriteOnReadOnly error\n</code></pre>"},{"location":"reference/rust-api/#snapshot-procedures","title":"Snapshot Procedures","text":"<p>Snapshots can also be managed via Cypher:</p> <pre><code>// Create a named snapshot\nCALL db.snapshot.create('before_migration')\nYIELD id, name, created\n\n// List snapshots\nCALL db.snapshot.list()\nYIELD id, name, created, size\n\n// Restore to a snapshot\nCALL db.snapshot.restore('before_migration')\n</code></pre>"},{"location":"reference/rust-api/#transactions","title":"Transactions","text":"<pre><code>impl Uni {\n    /// Begin an explicit transaction\n    pub async fn begin(&amp;self) -&gt; Result&lt;Transaction&lt;'_&gt;&gt;;\n\n    /// Run a closure within a transaction\n    pub async fn transaction&lt;F, Fut, T&gt;(&amp;self, f: F) -&gt; Result&lt;T&gt;\n    where\n        F: FnOnce(Transaction&lt;'_&gt;) -&gt; Fut,\n        Fut: Future&lt;Output = Result&lt;T&gt;&gt;;\n}\n\n/// Active transaction handle\npub struct Transaction&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; Transaction&lt;'a&gt; {\n    /// Execute a query within the transaction\n    pub async fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n\n    /// Execute a mutation within the transaction\n    pub async fn execute(&amp;self, cypher: &amp;str) -&gt; Result&lt;ExecuteResult&gt;;\n\n    /// Commit the transaction\n    pub async fn commit(self) -&gt; Result&lt;()&gt;;\n\n    /// Rollback the transaction\n    pub async fn rollback(self) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#transaction-examples","title":"Transaction Examples","text":"<pre><code>// Explicit transaction\nlet tx = db.begin().await?;\ntx.execute(\"CREATE (p:Paper {title: 'Paper 1'})\").await?;\ntx.execute(\"CREATE (p:Paper {title: 'Paper 2'})\").await?;\ntx.commit().await?;\n\n// Closure-based transaction (auto-commit on success, rollback on error)\ndb.transaction(|tx| async move {\n    tx.execute(\"CREATE (a:Author {name: 'Alice'})\").await?;\n    tx.execute(\"CREATE (a:Author {name: 'Bob'})\").await?;\n    Ok(())\n}).await?;\n\n// Transaction with rollback\nlet tx = db.begin().await?;\ntx.execute(\"DELETE (p:Paper) WHERE p.year &lt; 2000\").await?;\n// Changed our mind\ntx.rollback().await?;\n</code></pre>"},{"location":"reference/rust-api/#query-results","title":"Query Results","text":""},{"location":"reference/rust-api/#queryresult","title":"QueryResult","text":"<pre><code>/// Collection of result rows\npub struct QueryResult {\n    // Internal state\n}\n\nimpl QueryResult {\n    /// Get column names\n    pub fn columns(&amp;self) -&gt; &amp;[String];\n\n    /// Get number of rows\n    pub fn len(&amp;self) -&gt; usize;\n\n    /// Check if empty\n    pub fn is_empty(&amp;self) -&gt; bool;\n\n    /// Get rows as slice\n    pub fn rows(&amp;self) -&gt; &amp;[Row];\n\n    /// Consume into owned rows\n    pub fn into_rows(self) -&gt; Vec&lt;Row&gt;;\n\n    /// Iterate over rows\n    pub fn iter(&amp;self) -&gt; impl Iterator&lt;Item = &amp;Row&gt;;\n}\n\n// Implements IntoIterator\nfor row in results {\n    // ...\n}\n\n// Or by reference\nfor row in &amp;results {\n    // ...\n}\n</code></pre>"},{"location":"reference/rust-api/#row","title":"Row","text":"<pre><code>/// Single result row\npub struct Row {\n    // Internal state\n}\n\nimpl Row {\n    /// Get typed value by column name\n    pub fn get&lt;T: FromValue&gt;(&amp;self, column: &amp;str) -&gt; Result&lt;T&gt;;\n\n    /// Get typed value by index\n    pub fn get_idx&lt;T: FromValue&gt;(&amp;self, index: usize) -&gt; Result&lt;T&gt;;\n\n    /// Try to get value (returns None if missing or wrong type)\n    pub fn try_get&lt;T: FromValue&gt;(&amp;self, column: &amp;str) -&gt; Option&lt;T&gt;;\n\n    /// Get raw Value by column name\n    pub fn value(&amp;self, column: &amp;str) -&gt; Option&lt;&amp;Value&gt;;\n\n    /// Convert to HashMap\n    pub fn as_map(&amp;self) -&gt; HashMap&lt;&amp;str, &amp;Value&gt;;\n\n    /// Convert to JSON\n    pub fn to_json(&amp;self) -&gt; serde_json::Value;\n}\n\n// Index access\nimpl Index&lt;usize&gt; for Row {\n    type Output = Value;\n    fn index(&amp;self, index: usize) -&gt; &amp;Value;\n}\n\n// Example\nfor row in &amp;results {\n    let title: String = row.get(\"p.title\")?;\n    let year: i32 = row.get(\"p.year\")?;\n    let citations: Option&lt;i64&gt; = row.try_get(\"p.citations\");\n    println!(\"{} ({}) - {:?} citations\", title, year, citations);\n}\n</code></pre>"},{"location":"reference/rust-api/#node","title":"Node","text":"<pre><code>/// Graph node returned from queries\npub struct Node {\n    // Internal state\n}\n\nimpl Node {\n    /// Get vertex ID\n    pub fn id(&amp;self) -&gt; Vid;\n\n    /// Get label name\n    pub fn label(&amp;self) -&gt; &amp;str;\n\n    /// Get all properties\n    pub fn properties(&amp;self) -&gt; &amp;HashMap&lt;String, Value&gt;;\n\n    /// Get typed property value\n    pub fn get&lt;T: FromValue&gt;(&amp;self, property: &amp;str) -&gt; Result&lt;T&gt;;\n\n    /// Try to get property (returns None if missing)\n    pub fn try_get&lt;T: FromValue&gt;(&amp;self, property: &amp;str) -&gt; Option&lt;T&gt;;\n}\n\n// Example: Query returns nodes\nlet results = db.query(\"MATCH (p:Paper) RETURN p\").await?;\nfor row in &amp;results {\n    let node: Node = row.get(\"p\")?;\n    println!(\"Label: {}, ID: {}\", node.label(), node.id());\n    println!(\"Title: {}\", node.get::&lt;String&gt;(\"title\")?);\n}\n</code></pre>"},{"location":"reference/rust-api/#edge","title":"Edge","text":"<pre><code>/// Graph edge returned from queries\npub struct Edge {\n    // Internal state\n}\n\nimpl Edge {\n    /// Get edge ID\n    pub fn id(&amp;self) -&gt; Eid;\n\n    /// Get edge type name\n    pub fn edge_type(&amp;self) -&gt; &amp;str;\n\n    /// Get source vertex ID\n    pub fn src(&amp;self) -&gt; Vid;\n\n    /// Get destination vertex ID\n    pub fn dst(&amp;self) -&gt; Vid;\n\n    /// Get all properties\n    pub fn properties(&amp;self) -&gt; &amp;HashMap&lt;String, Value&gt;;\n\n    /// Get typed property value\n    pub fn get&lt;T: FromValue&gt;(&amp;self, property: &amp;str) -&gt; Result&lt;T&gt;;\n}\n\n// Example\nlet results = db.query(\"MATCH (a:Author)-[r:AUTHORED]-&gt;(p:Paper) RETURN r\").await?;\nfor row in &amp;results {\n    let edge: Edge = row.get(\"r\")?;\n    println!(\"Type: {}, From: {} To: {}\", edge.edge_type(), edge.src(), edge.dst());\n}\n</code></pre>"},{"location":"reference/rust-api/#path","title":"Path","text":"<pre><code>/// Graph path (sequence of nodes and edges)\npub struct Path {\n    // Internal state\n}\n\nimpl Path {\n    /// Get all nodes in the path\n    pub fn nodes(&amp;self) -&gt; &amp;[Node];\n\n    /// Get all edges in the path\n    pub fn edges(&amp;self) -&gt; &amp;[Edge];\n\n    /// Get path length (number of edges)\n    pub fn len(&amp;self) -&gt; usize;\n\n    /// Check if path is empty\n    pub fn is_empty(&amp;self) -&gt; bool;\n\n    /// Get start node\n    pub fn start(&amp;self) -&gt; &amp;Node;\n\n    /// Get end node\n    pub fn end(&amp;self) -&gt; &amp;Node;\n}\n\n// Example: Variable-length path query\nlet results = db.query(\n    \"MATCH path = (a:Paper)-[:CITES*1..3]-&gt;(b:Paper)\n     WHERE a.title = 'Attention Is All You Need'\n     RETURN path\"\n).await?;\n\nfor row in &amp;results {\n    let path: Path = row.get(\"path\")?;\n    println!(\"Path length: {} hops\", path.len());\n    println!(\"Start: {}\", path.start().get::&lt;String&gt;(\"title\")?);\n    println!(\"End: {}\", path.end().get::&lt;String&gt;(\"title\")?);\n}\n</code></pre>"},{"location":"reference/rust-api/#value","title":"Value","text":"<pre><code>/// Dynamic value type for properties and results\n#[derive(Clone, Debug, PartialEq)]\npub enum Value {\n    Null,\n    Bool(bool),\n    Int(i64),\n    Float(f64),\n    String(String),\n    Bytes(Vec&lt;u8&gt;),\n    List(Vec&lt;Value&gt;),\n    Map(HashMap&lt;String, Value&gt;),\n    Node(Node),\n    Edge(Edge),\n    Path(Path),\n    Vector(Vec&lt;f32&gt;),\n}\n\nimpl Value {\n    // Type checking\n    pub fn is_null(&amp;self) -&gt; bool;\n    pub fn is_bool(&amp;self) -&gt; bool;\n    pub fn is_int(&amp;self) -&gt; bool;\n    pub fn is_float(&amp;self) -&gt; bool;\n    pub fn is_string(&amp;self) -&gt; bool;\n    pub fn is_list(&amp;self) -&gt; bool;\n    pub fn is_map(&amp;self) -&gt; bool;\n    pub fn is_node(&amp;self) -&gt; bool;\n    pub fn is_edge(&amp;self) -&gt; bool;\n    pub fn is_path(&amp;self) -&gt; bool;\n    pub fn is_vector(&amp;self) -&gt; bool;\n\n    // Accessors (return None if wrong type)\n    pub fn as_bool(&amp;self) -&gt; Option&lt;bool&gt;;\n    pub fn as_i64(&amp;self) -&gt; Option&lt;i64&gt;;\n    pub fn as_f64(&amp;self) -&gt; Option&lt;f64&gt;;\n    pub fn as_str(&amp;self) -&gt; Option&lt;&amp;str&gt;;\n    pub fn as_bytes(&amp;self) -&gt; Option&lt;&amp;[u8]&gt;;\n    pub fn as_list(&amp;self) -&gt; Option&lt;&amp;[Value]&gt;;\n    pub fn as_map(&amp;self) -&gt; Option&lt;&amp;HashMap&lt;String, Value&gt;&gt;;\n    pub fn as_node(&amp;self) -&gt; Option&lt;&amp;Node&gt;;\n    pub fn as_edge(&amp;self) -&gt; Option&lt;&amp;Edge&gt;;\n    pub fn as_path(&amp;self) -&gt; Option&lt;&amp;Path&gt;;\n    pub fn as_vector(&amp;self) -&gt; Option&lt;&amp;[f32]&gt;;\n}\n\n// From implementations for common types\nimpl From&lt;bool&gt; for Value { ... }\nimpl From&lt;i32&gt; for Value { ... }\nimpl From&lt;i64&gt; for Value { ... }\nimpl From&lt;f64&gt; for Value { ... }\nimpl From&lt;String&gt; for Value { ... }\nimpl From&lt;&amp;str&gt; for Value { ... }\nimpl From&lt;Vec&lt;f32&gt;&gt; for Value { ... }\n</code></pre>"},{"location":"reference/rust-api/#fromvalue-trait","title":"FromValue Trait","text":"<pre><code>/// Trait for converting from Value\npub trait FromValue: Sized {\n    fn from_value(value: &amp;Value) -&gt; Result&lt;Self&gt;;\n}\n\n// Implemented for:\n// - String, &amp;str\n// - bool\n// - i32, i64, u32, u64\n// - f32, f64\n// - Vec&lt;T&gt; where T: FromValue\n// - Option&lt;T&gt; where T: FromValue\n// - Node, Edge, Path\n// - Vid, Eid\n// - Vec&lt;f32&gt; (vectors)\n</code></pre>"},{"location":"reference/rust-api/#schema-management","title":"Schema Management","text":""},{"location":"reference/rust-api/#schema-builder","title":"Schema Builder","text":"<pre><code>impl Uni {\n    /// Get schema builder for modifications\n    pub fn schema(&amp;self) -&gt; SchemaBuilder&lt;'_&gt;;\n\n    /// Load schema from file\n    pub async fn load_schema(&amp;self, path: impl AsRef&lt;Path&gt;) -&gt; Result&lt;()&gt;;\n\n    /// Save schema to file\n    pub async fn save_schema(&amp;self, path: impl AsRef&lt;Path&gt;) -&gt; Result&lt;()&gt;;\n}\n\n/// Fluent schema builder\npub struct SchemaBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; SchemaBuilder&lt;'a&gt; {\n    /// Add a new label (vertex type)\n    pub fn label(self, name: &amp;str) -&gt; LabelBuilder&lt;'a&gt;;\n\n    /// Add a new edge type\n    pub fn edge_type(\n        self,\n        name: &amp;str,\n        from_labels: &amp;[&amp;str],\n        to_labels: &amp;[&amp;str],\n    ) -&gt; EdgeTypeBuilder&lt;'a&gt;;\n\n    /// Apply all schema changes\n    pub async fn apply(self) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#labelbuilder","title":"LabelBuilder","text":"<pre><code>/// Builder for label definitions\npub struct LabelBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; LabelBuilder&lt;'a&gt; {\n    /// Mark as document collection (enables JSON storage)\n    pub fn document(self) -&gt; Self;\n\n    /// Add a required property\n    pub fn property(self, name: &amp;str, data_type: DataType) -&gt; Self;\n\n    /// Add a nullable property\n    pub fn property_nullable(self, name: &amp;str, data_type: DataType) -&gt; Self;\n\n    /// Add a vector property\n    pub fn vector(self, name: &amp;str, dimensions: usize) -&gt; Self;\n\n    /// Add an index on a property\n    pub fn index(self, property: &amp;str, index_type: IndexType) -&gt; Self;\n\n    /// Finish this label and return to SchemaBuilder\n    pub fn done(self) -&gt; SchemaBuilder&lt;'a&gt;;\n\n    /// Chain to another label\n    pub fn label(self, name: &amp;str) -&gt; LabelBuilder&lt;'a&gt;;\n\n    /// Chain to an edge type\n    pub fn edge_type(\n        self,\n        name: &amp;str,\n        from: &amp;[&amp;str],\n        to: &amp;[&amp;str],\n    ) -&gt; EdgeTypeBuilder&lt;'a&gt;;\n\n    /// Apply all schema changes\n    pub async fn apply(self) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#edgetypebuilder","title":"EdgeTypeBuilder","text":"<pre><code>/// Builder for edge type definitions\npub struct EdgeTypeBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; EdgeTypeBuilder&lt;'a&gt; {\n    /// Add a required property\n    pub fn property(self, name: &amp;str, data_type: DataType) -&gt; Self;\n\n    /// Add a nullable property\n    pub fn property_nullable(self, name: &amp;str, data_type: DataType) -&gt; Self;\n\n    /// Finish and return to SchemaBuilder\n    pub fn done(self) -&gt; SchemaBuilder&lt;'a&gt;;\n\n    /// Chain to a label\n    pub fn label(self, name: &amp;str) -&gt; LabelBuilder&lt;'a&gt;;\n\n    /// Chain to another edge type\n    pub fn edge_type(\n        self,\n        name: &amp;str,\n        from: &amp;[&amp;str],\n        to: &amp;[&amp;str],\n    ) -&gt; EdgeTypeBuilder&lt;'a&gt;;\n\n    /// Apply all schema changes\n    pub async fn apply(self) -&gt; Result&lt;()&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#schema-example","title":"Schema Example","text":"<pre><code>// Define schema using fluent API\ndb.schema()\n    .label(\"Paper\")\n        .property(\"title\", DataType::String)\n        .property(\"year\", DataType::Int32)\n        .property_nullable(\"abstract\", DataType::String)\n        .vector(\"embedding\", 768)\n        .index(\"year\", IndexType::Scalar(ScalarType::BTree))\n        .index(\"embedding\", IndexType::Vector(VectorIndexCfg {\n            algorithm: VectorAlgo::Hnsw { m: 16, ef_construction: 200 },\n            metric: VectorMetric::Cosine,\n        }))\n    .label(\"Author\")\n        .property(\"name\", DataType::String)\n        .property_nullable(\"email\", DataType::String)\n        .index(\"name\", IndexType::Scalar(ScalarType::Hash))\n    .edge_type(\"AUTHORED\", &amp;[\"Author\"], &amp;[\"Paper\"])\n        .property_nullable(\"position\", DataType::Int32)\n    .edge_type(\"CITES\", &amp;[\"Paper\"], &amp;[\"Paper\"])\n    .apply()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#schema-types","title":"Schema Types","text":"<pre><code>/// Property data type\n#[derive(Clone, Debug, PartialEq)]\npub enum DataType {\n    String,\n    Int32,\n    Int64,\n    Float32,\n    Float64,\n    Bool,\n    Timestamp,\n    Json,\n    Vector { dimensions: usize },\n    Crdt(CrdtType),\n}\n\n/// CRDT type variants\n#[derive(Clone, Debug, PartialEq)]\npub enum CrdtType {\n    GCounter,\n    GSet,\n    ORSet,\n    LWWRegister,\n    LWWMap,\n    Rga,\n}\n\n/// Index type configuration\n#[derive(Clone, Debug)]\npub enum IndexType {\n    Vector(VectorIndexCfg),\n    FullText,\n    Scalar(ScalarType),\n}\n\n/// Vector index configuration\n#[derive(Clone, Debug)]\npub struct VectorIndexCfg {\n    pub algorithm: VectorAlgo,\n    pub metric: VectorMetric,\n}\n\n/// Vector index algorithms\n#[derive(Clone, Debug)]\npub enum VectorAlgo {\n    /// HNSW index (fast, high recall)\n    Hnsw { m: u32, ef_construction: u32 },\n    /// IVF-PQ index (memory efficient)\n    IvfPq { partitions: u32, sub_vectors: u32 },\n    /// Flat index (exact, slow)\n    Flat,\n}\n\n/// Vector distance metrics\n#[derive(Clone, Copy, Debug)]\npub enum VectorMetric {\n    Cosine,\n    L2,\n    Dot,\n}\n\n/// Scalar index types\n#[derive(Clone, Copy, Debug)]\npub enum ScalarType {\n    BTree,   // Range queries\n    Hash,    // Equality queries\n    Bitmap,  // Low cardinality\n}\n</code></pre>"},{"location":"reference/rust-api/#vector-search","title":"Vector Search","text":""},{"location":"reference/rust-api/#basic-vector-search","title":"Basic Vector Search","text":"<pre><code>impl Uni {\n    /// Perform vector similarity search\n    pub async fn vector_search(\n        &amp;self,\n        label: &amp;str,\n        property: &amp;str,\n        query: Vec&lt;f32&gt;,\n        k: usize,\n    ) -&gt; Result&lt;Vec&lt;VectorMatch&gt;&gt;;\n\n    /// Vector search with options\n    pub fn vector_search_with(\n        &amp;self,\n        label: &amp;str,\n        property: &amp;str,\n        query: Vec&lt;f32&gt;,\n    ) -&gt; VectorSearchBuilder&lt;'_&gt;;\n}\n\n/// Vector search result\n#[derive(Clone, Debug)]\npub struct VectorMatch {\n    pub vid: Vid,\n    pub distance: f32,\n}\n</code></pre>"},{"location":"reference/rust-api/#vectorsearchbuilder","title":"VectorSearchBuilder","text":"<pre><code>/// Fluent builder for vector searches\npub struct VectorSearchBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; VectorSearchBuilder&lt;'a&gt; {\n    /// Set number of results to return\n    pub fn k(self, k: usize) -&gt; Self;\n\n    /// Set distance threshold (filter out results above this)\n    pub fn threshold(self, threshold: f32) -&gt; Self;\n\n    /// Add a filter predicate (Cypher WHERE syntax)\n    pub fn filter(self, filter: &amp;str) -&gt; Self;\n\n    /// Execute search and return matches\n    pub async fn search(self) -&gt; Result&lt;Vec&lt;VectorMatch&gt;&gt;;\n\n    /// Execute search and fetch full nodes\n    pub async fn fetch_nodes(self) -&gt; Result&lt;Vec&lt;(Node, f32)&gt;&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#vector-search-examples","title":"Vector Search Examples","text":"<pre><code>// Simple vector search\nlet query_embedding = embedding_service.embed(\"machine learning\")?;\nlet matches = db.vector_search(\"Paper\", \"embedding\", query_embedding, 10).await?;\n\nfor m in matches {\n    println!(\"VID: {}, Distance: {:.4}\", m.vid, m.distance);\n}\n\n// Vector search with filters and fetch nodes\nlet results = db.vector_search_with(\"Paper\", \"embedding\", query_embedding)\n    .k(20)\n    .threshold(0.5)\n    .filter(\"node.year &gt;= 2020\")\n    .fetch_nodes()\n    .await?;\n\nfor (node, distance) in results {\n    println!(\"{} ({:.4})\", node.get::&lt;String&gt;(\"title\")?, distance);\n}\n\n// Vector search via Cypher\nlet results = db.query_with(\n    \"CALL db.idx.vector.query('Paper', 'embedding', $vec, 10)\n     YIELD node, distance\n     WHERE node.year &gt;= 2020\n     RETURN node.title, distance\n     ORDER BY distance\"\n)\n    .param(\"vec\", query_embedding)\n    .fetch_all()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#graph-algorithms","title":"Graph Algorithms","text":""},{"location":"reference/rust-api/#algobuilder","title":"AlgoBuilder","text":"<pre><code>impl Uni {\n    /// Access algorithm builder\n    pub fn algo(&amp;self) -&gt; AlgoBuilder&lt;'_&gt;;\n}\n\n/// Builder for graph algorithms\npub struct AlgoBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; AlgoBuilder&lt;'a&gt; {\n    /// PageRank centrality algorithm\n    pub fn pagerank(self) -&gt; PageRankBuilder&lt;'a&gt;;\n\n    /// Weakly Connected Components\n    pub fn wcc(self) -&gt; WccBuilder&lt;'a&gt;;\n}\n</code></pre>"},{"location":"reference/rust-api/#pagerank","title":"PageRank","text":"<pre><code>/// PageRank algorithm builder\npub struct PageRankBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; PageRankBuilder&lt;'a&gt; {\n    /// Filter to specific labels\n    pub fn labels(self, labels: &amp;[&amp;str]) -&gt; Self;\n\n    /// Filter to specific edge types\n    pub fn edge_types(self, types: &amp;[&amp;str]) -&gt; Self;\n\n    /// Set damping factor (default: 0.85)\n    pub fn damping(self, d: f64) -&gt; Self;\n\n    /// Set maximum iterations (default: 20)\n    pub fn max_iterations(self, n: usize) -&gt; Self;\n\n    /// Set convergence tolerance (default: 1e-6)\n    pub fn tolerance(self, tol: f64) -&gt; Self;\n\n    /// Run the algorithm\n    pub async fn run(self) -&gt; Result&lt;Vec&lt;(Vid, f64)&gt;&gt;;\n}\n\n// Example\nlet rankings = db.algo()\n    .pagerank()\n    .labels(&amp;[\"Paper\"])\n    .edge_types(&amp;[\"CITES\"])\n    .damping(0.85)\n    .max_iterations(50)\n    .run()\n    .await?;\n\nfor (vid, score) in rankings.iter().take(10) {\n    println!(\"VID: {}, PageRank: {:.6}\", vid, score);\n}\n</code></pre>"},{"location":"reference/rust-api/#weakly-connected-components","title":"Weakly Connected Components","text":"<pre><code>/// WCC algorithm builder\npub struct WccBuilder&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; WccBuilder&lt;'a&gt; {\n    /// Filter to specific labels\n    pub fn labels(self, labels: &amp;[&amp;str]) -&gt; Self;\n\n    /// Filter to specific edge types\n    pub fn edge_types(self, types: &amp;[&amp;str]) -&gt; Self;\n\n    /// Run the algorithm\n    pub async fn run(self) -&gt; Result&lt;Vec&lt;(Vid, i64)&gt;&gt;;\n}\n\n// Example: Find connected components\nlet components = db.algo()\n    .wcc()\n    .labels(&amp;[\"Paper\", \"Author\"])\n    .edge_types(&amp;[\"AUTHORED\", \"CITES\"])\n    .run()\n    .await?;\n\n// Count component sizes\nlet mut component_sizes: HashMap&lt;i64, usize&gt; = HashMap::new();\nfor (_, component_id) in &amp;components {\n    *component_sizes.entry(*component_id).or_default() += 1;\n}\nprintln!(\"Found {} components\", component_sizes.len());\n</code></pre>"},{"location":"reference/rust-api/#algorithms-via-cypher","title":"Algorithms via Cypher","text":"<pre><code>// PageRank via Cypher CALL\nlet results = db.query(\n    \"CALL algo.pageRank('Paper', 'CITES', {damping: 0.85, iterations: 20})\n     YIELD nodeId, score\n     RETURN nodeId, score\n     ORDER BY score DESC\n     LIMIT 10\"\n).await?;\n\n// Shortest path\nlet results = db.query(\n    \"CALL algo.shortestPath($startVid, $endVid, 'CITES')\n     YIELD path, distance\n     RETURN path, distance\"\n)\n    .param(\"startVid\", start_vid.as_u64() as i64)\n    .param(\"endVid\", end_vid.as_u64() as i64)\n    .fetch_all()\n    .await?;\n\n// Louvain community detection\nlet results = db.query(\n    \"CALL algo.louvain('Paper', 'CITES')\n     YIELD nodeId, communityId\n     RETURN communityId, COUNT(*) AS size\n     ORDER BY size DESC\"\n).await?;\n</code></pre>"},{"location":"reference/rust-api/#core-types","title":"Core Types","text":""},{"location":"reference/rust-api/#vid-vertex-id","title":"Vid (Vertex ID)","text":"<pre><code>/// 64-bit vertex identifier\n/// Encoding: label_id (16 bits) | local_offset (48 bits)\n#[derive(Clone, Copy, Hash, Eq, PartialEq, Ord, PartialOrd)]\npub struct Vid(u64);\n\nimpl Vid {\n    /// Create from label ID and offset\n    pub fn new(label_id: u16, local_offset: u64) -&gt; Self;\n\n    /// Extract label ID (upper 16 bits)\n    pub fn label_id(&amp;self) -&gt; u16;\n\n    /// Extract local offset (lower 48 bits)\n    pub fn local_offset(&amp;self) -&gt; u64;\n\n    /// Get raw u64 value\n    pub fn as_u64(&amp;self) -&gt; u64;\n}\n\nimpl From&lt;u64&gt; for Vid { ... }\nimpl Display for Vid { ... }  // Formats as \"0x{:016x}\"\n\n// Example\nlet vid = Vid::new(1, 12345);\nassert_eq!(vid.label_id(), 1);\nassert_eq!(vid.local_offset(), 12345);\n</code></pre>"},{"location":"reference/rust-api/#eid-edge-id","title":"Eid (Edge ID)","text":"<pre><code>/// 64-bit edge identifier\n/// Encoding: type_id (16 bits) | local_offset (48 bits)\n#[derive(Clone, Copy, Hash, Eq, PartialEq, Ord, PartialOrd)]\npub struct Eid(u64);\n\nimpl Eid {\n    /// Create from edge type ID and offset\n    pub fn new(type_id: u16, local_offset: u64) -&gt; Self;\n\n    /// Extract edge type ID\n    pub fn type_id(&amp;self) -&gt; u16;\n\n    /// Extract local offset\n    pub fn local_offset(&amp;self) -&gt; u64;\n\n    /// Get raw u64 value\n    pub fn as_u64(&amp;self) -&gt; u64;\n}\n\nimpl From&lt;u64&gt; for Eid { ... }\nimpl Display for Eid { ... }\n</code></pre>"},{"location":"reference/rust-api/#uniid","title":"UniId","text":"<pre><code>/// Content-addressed identifier (SHA3-256 hash)\n/// Used for provenance tracking and distributed sync\n#[derive(Clone, Hash, Eq, PartialEq)]\npub struct UniId([u8; 32]);\n\nimpl UniId {\n    /// Create from raw bytes\n    pub fn from_bytes(bytes: [u8; 32]) -&gt; Self;\n\n    /// Compute from content\n    pub fn compute(content: &amp;[u8]) -&gt; Self;\n\n    /// Get as hex string\n    pub fn to_hex(&amp;self) -&gt; String;\n\n    /// Parse from hex string\n    pub fn from_hex(s: &amp;str) -&gt; Result&lt;Self&gt;;\n\n    /// Get raw bytes\n    pub fn as_bytes(&amp;self) -&gt; &amp;[u8; 32];\n}\n</code></pre>"},{"location":"reference/rust-api/#blocking-api-unisync","title":"Blocking API (UniSync)","text":"<p>For applications that cannot use async/await.</p> <pre><code>/// Blocking wrapper for Uni\npub struct UniSync {\n    // Internal state\n}\n\nimpl UniSync {\n    /// Open database (blocking)\n    pub fn open(path: impl AsRef&lt;Path&gt;) -&gt; Result&lt;Self&gt;;\n\n    /// Create in-memory database (blocking)\n    pub fn in_memory() -&gt; Result&lt;Self&gt;;\n\n    /// Execute query (blocking)\n    pub fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n\n    /// Execute mutation (blocking)\n    pub fn execute(&amp;self, cypher: &amp;str) -&gt; Result&lt;ExecuteResult&gt;;\n\n    /// Query with parameters\n    pub fn query_with(&amp;self, cypher: &amp;str) -&gt; QueryBuilderSync&lt;'_&gt;;\n\n    /// Get current schema\n    pub fn schema_meta(&amp;self) -&gt; Schema;\n\n    /// Get schema builder\n    pub fn schema(&amp;self) -&gt; SchemaBuilderSync&lt;'_&gt;;\n\n    /// Begin transaction (blocking)\n    pub fn begin(&amp;self) -&gt; Result&lt;TransactionSync&lt;'_&gt;&gt;;\n}\n\n/// Blocking transaction\npub struct TransactionSync&lt;'a&gt; {\n    // Internal state\n}\n\nimpl&lt;'a&gt; TransactionSync&lt;'a&gt; {\n    pub fn query(&amp;self, cypher: &amp;str) -&gt; Result&lt;QueryResult&gt;;\n    pub fn execute(&amp;self, cypher: &amp;str) -&gt; Result&lt;ExecuteResult&gt;;\n    pub fn commit(self) -&gt; Result&lt;()&gt;;\n    pub fn rollback(self) -&gt; Result&lt;()&gt;;\n}\n\n// Example\nlet db = UniSync::open(\"./data\")?;\nlet results = db.query(\"MATCH (p:Paper) RETURN p.title LIMIT 10\")?;\nfor row in &amp;results {\n    println!(\"{}\", row.get::&lt;String&gt;(\"p.title\")?);\n}\n</code></pre>"},{"location":"reference/rust-api/#configuration","title":"Configuration","text":"<pre><code>/// Database configuration\n#[derive(Clone, Debug)]\npub struct UniConfig {\n    /// Cache size in bytes (default: 1 GB)\n    pub cache_size: usize,\n\n    /// Worker thread count (default: available cores)\n    pub parallelism: usize,\n\n    /// Batch size for vectorized execution (default: 1024)\n    pub batch_size: usize,\n\n    /// Maximum frontier size for traversals (default: 1M)\n    pub max_frontier_size: usize,\n\n    /// Auto-flush after this many mutations (default: 10K)\n    pub auto_flush_threshold: usize,\n\n    /// Enable write-ahead log (default: true)\n    pub wal_enabled: bool,\n}\n\nimpl Default for UniConfig {\n    fn default() -&gt; Self {\n        Self {\n            cache_size: 1024 * 1024 * 1024,  // 1 GB\n            parallelism: num_cpus::get(),\n            batch_size: 1024,\n            max_frontier_size: 1_000_000,\n            auto_flush_threshold: 10_000,\n            wal_enabled: true,\n        }\n    }\n}\n\n// Example\nlet config = UniConfig {\n    cache_size: 4 * 1024 * 1024 * 1024,  // 4 GB\n    parallelism: 16,\n    ..Default::default()\n};\n\nlet db = Uni::open(\"./data\")\n    .config(config)\n    .build()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#error-handling","title":"Error Handling","text":"<pre><code>/// Main error type\n#[derive(Debug, thiserror::Error)]\npub enum UniError {\n    #[error(\"Database not found: {path}\")]\n    NotFound { path: PathBuf },\n\n    #[error(\"Schema error: {message}\")]\n    Schema { message: String },\n\n    #[error(\"Parse error: {message}\")]\n    Parse {\n        message: String,\n        position: Option&lt;usize&gt;,\n        line: Option&lt;usize&gt;,\n        column: Option&lt;usize&gt;,\n        context: Option&lt;String&gt;,\n    },\n\n    #[error(\"Query error: {message}\")]\n    Query {\n        message: String,\n        query: Option&lt;String&gt;,\n    },\n\n    #[error(\"Transaction error: {message}\")]\n    Transaction { message: String },\n\n    #[error(\"Transaction conflict: {message}\")]\n    TransactionConflict { message: String },\n\n    #[error(\"Database is locked by another process\")]\n    DatabaseLocked,\n\n    #[error(\"Query timeout after {timeout_ms}ms\")]\n    Timeout { timeout_ms: u64 },\n\n    #[error(\"Type error: expected {expected}, got {actual}\")]\n    Type { expected: String, actual: String },\n\n    #[error(\"Constraint violation: {message}\")]\n    Constraint { message: String },\n\n    #[error(\"Storage error: {message}\")]\n    Storage {\n        message: String,\n        source: Option&lt;Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;,\n    },\n\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"Internal error: {0}\")]\n    Internal(#[from] anyhow::Error),\n}\n\n/// Result type alias\npub type Result&lt;T&gt; = std::result::Result&lt;T, UniError&gt;;\n\n// Error handling example\nmatch db.query(\"INVALID QUERY\").await {\n    Ok(results) =&gt; { /* ... */ }\n    Err(UniError::Parse { message, line, column, .. }) =&gt; {\n        eprintln!(\"Parse error at {}:{}: {}\", line.unwrap_or(0), column.unwrap_or(0), message);\n    }\n    Err(UniError::Query { message, query }) =&gt; {\n        eprintln!(\"Query failed: {}\", message);\n    }\n    Err(e) =&gt; {\n        eprintln!(\"Error: {}\", e);\n    }\n}\n</code></pre>"},{"location":"reference/rust-api/#prelude","title":"Prelude","text":"<p>Convenient re-exports for common usage.</p> <pre><code>pub use crate::{\n    Uni, UniBuilder, UniSync, UniConfig, UniError, Result,\n    Transaction, QueryBuilder,\n};\npub use crate::query::{\n    QueryResult, Row, Node, Edge, Path, Value, FromValue, ExecuteResult,\n};\npub use crate::core::{Vid, Eid, UniId};\npub use crate::schema::{\n    Schema, DataType, CrdtType, IndexType, VectorIndexCfg,\n    VectorAlgo, VectorMetric, ScalarType,\n};\npub use crate::vector::VectorMatch;\n</code></pre>"},{"location":"reference/rust-api/#complete-example","title":"Complete Example","text":"<pre><code>use uni::prelude::*;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create database with schema\n    let db = Uni::open(\"./academic-graph\")\n        .cache_size(2 * 1024 * 1024 * 1024)\n        .build()\n        .await?;\n\n    // Define schema\n    db.schema()\n        .label(\"Paper\")\n            .property(\"title\", DataType::String)\n            .property(\"year\", DataType::Int32)\n            .vector(\"embedding\", 768)\n            .index(\"year\", IndexType::Scalar(ScalarType::BTree))\n        .label(\"Author\")\n            .property(\"name\", DataType::String)\n        .edge_type(\"AUTHORED\", &amp;[\"Author\"], &amp;[\"Paper\"])\n        .edge_type(\"CITES\", &amp;[\"Paper\"], &amp;[\"Paper\"])\n        .apply()\n        .await?;\n\n    // Insert data in a transaction\n    db.transaction(|tx| async move {\n        tx.execute(\"CREATE (a:Author {name: 'Alice'})\").await?;\n        tx.execute(\"CREATE (p:Paper {title: 'Graph Databases', year: 2024})\").await?;\n        tx.execute(\n            \"MATCH (a:Author {name: 'Alice'}), (p:Paper {title: 'Graph Databases'})\n             CREATE (a)-[:AUTHORED]-&gt;(p)\"\n        ).await?;\n        Ok(())\n    }).await?;\n\n    // Query with parameters\n    let results = db.query_with(\n        \"MATCH (a:Author)-[:AUTHORED]-&gt;(p:Paper)\n         WHERE p.year &gt;= $min_year\n         RETURN a.name AS author, p.title AS paper, p.year AS year\n         ORDER BY p.year DESC\"\n    )\n        .param(\"min_year\", 2020)\n        .fetch_all()\n        .await?;\n\n    println!(\"Found {} results:\", results.len());\n    for row in &amp;results {\n        println!(\n            \"  {} wrote '{}' ({})\",\n            row.get::&lt;String&gt;(\"author\")?,\n            row.get::&lt;String&gt;(\"paper\")?,\n            row.get::&lt;i32&gt;(\"year\")?\n        );\n    }\n\n    // Run PageRank on citation network\n    let rankings = db.algo()\n        .pagerank()\n        .labels(&amp;[\"Paper\"])\n        .edge_types(&amp;[\"CITES\"])\n        .run()\n        .await?;\n\n    println!(\"\\nTop 5 papers by PageRank:\");\n    for (vid, score) in rankings.iter().take(5) {\n        let result = db.query_with(\"MATCH (p:Paper) WHERE id(p) = $vid RETURN p.title\")\n            .param(\"vid\", vid.as_u64() as i64)\n            .fetch_all()\n            .await?;\n        if let Some(row) = result.rows().first() {\n            println!(\"  {:.6}: {}\", score, row.get::&lt;String&gt;(\"p.title\")?);\n        }\n    }\n\n    Ok(())\n}\n</code></pre>"},{"location":"reference/rust-api/#api-gaps-workarounds","title":"API Gaps &amp; Workarounds","text":"<p>The following features exist internally but have limited or no exposure through the public Rust API. This section documents what's available and workarounds where applicable.</p>"},{"location":"reference/rust-api/#feature-availability-summary","title":"Feature Availability Summary","text":"Feature Rust API Cypher Notes Basic CRUD \u2705 \u2705 <code>query()</code>, <code>execute()</code> Parameterized queries \u2705 \u2705 <code>query_with().param()</code> Transactions \u2705 \u2705 <code>begin()</code>, <code>transaction()</code> Schema definition \u2705 \u2705 <code>schema()</code> builder Vector search \u2705 \u2705 <code>vector_search()</code> + <code>db.idx.vector.query()</code> PageRank / WCC \u2705 \u2705 <code>algo().pagerank()</code> Session variables \u2705 \u2705 <code>session().set().build()</code> + <code>$session.*</code> Bulk loading \u2705 \u2014 <code>bulk_writer()</code> with deferred indexing Snapshots \u2705 \u2705 <code>at_snapshot()</code>, <code>list_snapshots()</code>, <code>db.snapshot.*</code> Temporal queries \u2014 \u2705 <code>uni.validAt()</code>, <code>VALID_AT</code> macro Schema DDL procedures \u2014 \u2705 <code>db.createLabel()</code>, <code>db.createIndex()</code> Schema introspection \u2705 \u2705 <code>db.labels()</code>, <code>db.indexes()</code>, <code>db.constraints()</code> EXPLAIN/PROFILE \u2705 \u2705 <code>explain()</code>, <code>profile()</code> with index usage Import/Export \u274c \u2705 Use <code>COPY</code> (see below) Embedding generation \u274c \u2705 Auto on CREATE with schema config Other algorithms \u274c \u2705 Use <code>CALL algo.*</code> CRDT operations \u274c \u2705 Schema type + Cypher S3/GCS storage \u274c \u2014 Filesystem assumptions in metadata ops Compaction control \u274c \u274c Automatic only"},{"location":"reference/rust-api/#batch-ingestion","title":"Batch Ingestion","text":"<p>No direct <code>put_batch()</code> method exists. Use Cypher <code>UNWIND</code> for batch operations:</p> <pre><code>// Batch insert via UNWIND\nlet papers = vec![\n    json!({\"title\": \"Paper 1\", \"year\": 2024}),\n    json!({\"title\": \"Paper 2\", \"year\": 2023}),\n    json!({\"title\": \"Paper 3\", \"year\": 2024}),\n];\n\ndb.query_with(\n    \"UNWIND $papers AS p\n     CREATE (n:Paper {title: p.title, year: p.year})\"\n)\n    .param(\"papers\", papers)\n    .fetch_all()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#importexport","title":"Import/Export","text":"<p>No direct import/export methods. Use Cypher <code>COPY</code>:</p> <pre><code>// Import from CSV\ndb.execute(\"COPY Paper FROM 'papers.csv'\").await?;\n\n// Export to Parquet\ndb.execute(\"COPY Paper TO 'papers.parquet' WITH {format: 'parquet'}\").await?;\n\n// Export to CSV\ndb.execute(\"COPY Paper TO 'papers.csv' WITH {format: 'csv'}\").await?;\n</code></pre>"},{"location":"reference/rust-api/#graph-algorithms_1","title":"Graph Algorithms","text":"<p>Only PageRank and WCC have dedicated builder APIs. Other algorithms are accessible via Cypher:</p> <pre><code>// Louvain community detection\nlet results = db.query(\n    \"CALL algo.louvain('Paper', 'CITES')\n     YIELD nodeId, communityId\n     RETURN communityId, COUNT(*) AS size\n     ORDER BY size DESC\"\n).await?;\n\n// Shortest path\nlet results = db.query_with(\n    \"CALL algo.shortestPath($start, $end, 'CITES')\n     YIELD path, distance\n     RETURN path, distance\"\n)\n    .param(\"start\", start_vid)\n    .param(\"end\", end_vid)\n    .fetch_all()\n    .await?;\n\n// Label propagation\nlet results = db.query(\n    \"CALL algo.labelPropagation('Paper', 'CITES')\n     YIELD nodeId, communityId\n     RETURN communityId, COUNT(*) AS size\"\n).await?;\n</code></pre>"},{"location":"reference/rust-api/#embedding-generation","title":"Embedding Generation","text":"<p>Embeddings are auto-generated on CREATE when configured in schema. No direct embedding API:</p> <pre><code>// Schema with embedding config (embeddings auto-generated on insert)\ndb.schema()\n    .label(\"Paper\")\n        .property(\"title\", DataType::String)\n        .property(\"abstract\", DataType::String)\n        .vector(\"embedding\", 384)  // Dimensions match model\n    .apply()\n    .await?;\n\n// Embedding generated automatically from configured source properties\ndb.execute(\"CREATE (p:Paper {title: 'ML Paper', abstract: 'Deep learning...'})\").await?;\n\n// Query embeddings via vector search\nlet results = db.query(\n    \"CALL db.idx.vector.query('Paper', 'embedding', $query_vec, 10)\n     YIELD node, distance\n     RETURN node.title, distance\"\n)\n    .param(\"query_vec\", query_embedding)\n    .fetch_all()\n    .await?;\n</code></pre>"},{"location":"reference/rust-api/#crdt-types","title":"CRDT Types","text":"<p>CRDTs can be defined in schema but manipulated only via Cypher:</p> <pre><code>// Define CRDT property\ndb.schema()\n    .label(\"Counter\")\n        .property(\"value\", DataType::Crdt(CrdtType::GCounter))\n    .apply()\n    .await?;\n\n// Increment counter via Cypher\ndb.execute(\"MATCH (c:Counter {id: 'visits'}) SET c.value = crdt.increment(c.value, 1)\").await?;\n\n// Read counter\nlet results = db.query(\"MATCH (c:Counter {id: 'visits'}) RETURN crdt.value(c.value) AS count\").await?;\n</code></pre>"},{"location":"reference/rust-api/#storage-backend","title":"Storage Backend","text":"<p>Currently only local filesystem paths are supported. While Lance (the underlying storage) supports S3/GCS/Azure natively, Uni's metadata operations (schema, snapshots, WAL, ID allocation) use <code>std::fs</code> directly:</p> <pre><code>// Local storage (supported)\nlet db = Uni::open(\"./my-graph\").build().await?;\n\n// S3/GCS/Azure (NOT SUPPORTED)\n// Blocked by filesystem assumptions in:\n// - SchemaManager (fs::read_to_string, fs::write)\n// - SnapshotManager (fs::create_dir_all, fs::write)\n// - WriteAheadLog (File::open)\n// - IdAllocator (fs::rename for atomic writes)\n</code></pre> <p>Supporting object stores would require abstracting these operations to use <code>object_store</code> crate throughout.</p>"},{"location":"reference/rust-api/#full-text-search","title":"Full-Text Search","text":"<p>FTS indexes can be created but querying is not yet implemented:</p> <pre><code>// Create FTS index (works)\ndb.execute(\"CREATE FULLTEXT INDEX bio_fts FOR (p:Person) ON EACH [p.bio]\").await?;\n\n// FTS query (NOT YET IMPLEMENTED)\n// CONTAINS, STARTS WITH, ENDS WITH not supported in parser\n// No db.idx.fts.query() procedure exists\n</code></pre>"},{"location":"reference/rust-api/#whats-not-accessible","title":"What's NOT Accessible","text":"<p>These internal features have no public access path:</p> <ul> <li>Compaction control: No <code>compact()</code> method; runs automatically</li> <li>Snapshot management: Internal only; no create/restore API</li> <li>WAL management: Only <code>wal_enabled</code> config flag; no rotation/recovery API</li> <li>ID allocation: Internal <code>IdAllocator</code>; no public ID control</li> <li>Subgraph extraction: Internal <code>load_subgraph_cached()</code>; no public method</li> <li>Property lazy-loading: Internal <code>PropertyManager</code>; transparent to users</li> </ul>"},{"location":"reference/rust-api/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Reference \u2014 All configuration options</li> <li>Cypher Querying \u2014 Query language guide</li> <li>Vector Search \u2014 Embedding search patterns</li> <li>Troubleshooting \u2014 Common issues and solutions</li> </ul>"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":"<p>This guide covers common issues, error messages, and their solutions when working with Uni.</p>"},{"location":"reference/troubleshooting/#quick-diagnostics","title":"Quick Diagnostics","text":"<pre><code># Check storage health\nuni stats --path ./storage\n\n# Validate schema\nuni schema validate --path ./storage\n\n# Check for corruption\nuni check --path ./storage\n\n# View recent logs\nRUST_LOG=uni=debug uni query \"RETURN 1\" --path ./storage 2&gt;&amp;1 | tail -50\n</code></pre>"},{"location":"reference/troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"reference/troubleshooting/#installation-problems","title":"Installation Problems","text":""},{"location":"reference/troubleshooting/#rust-version-incompatible","title":"Rust Version Incompatible","text":"<p>Symptom: <pre><code>error: package `uni v0.1.0` cannot be built because it requires rustc 1.75 or newer\n</code></pre></p> <p>Solution: <pre><code># Update Rust\nrustup update stable\n\n# Verify version\nrustc --version  # Should be 1.75+\n</code></pre></p>"},{"location":"reference/troubleshooting/#missing-system-dependencies","title":"Missing System Dependencies","text":"<p>Symptom: <pre><code>error: failed to run custom build command for `openssl-sys`\n</code></pre></p> <p>Solution: <pre><code># Ubuntu/Debian\nsudo apt install pkg-config libssl-dev\n\n# macOS\nbrew install openssl\nexport OPENSSL_DIR=$(brew --prefix openssl)\n\n# Fedora\nsudo dnf install openssl-devel\n</code></pre></p>"},{"location":"reference/troubleshooting/#build-fails-with-simd-errors","title":"Build Fails with SIMD Errors","text":"<p>Symptom: <pre><code>error: unknown feature 'avx2'\n</code></pre></p> <p>Solution: <pre><code># Build without SIMD optimizations\ncargo build --release --no-default-features\n\n# Or specify target CPU\nRUSTFLAGS=\"-C target-cpu=native\" cargo build --release\n</code></pre></p>"},{"location":"reference/troubleshooting/#storage-issues","title":"Storage Issues","text":""},{"location":"reference/troubleshooting/#cannot-open-storage","title":"Cannot Open Storage","text":"<p>Symptom: <pre><code>Error: Failed to open storage at ./storage: No such file or directory\n</code></pre></p> <p>Solution: <pre><code># Check path exists\nls -la ./storage\n\n# Initialize new storage\nuni import my-data --papers data.jsonl --citations edges.jsonl --output ./storage\n\n# Or create programmatically\nlet storage = StorageManager::new(\"./storage\", schema);\n</code></pre></p>"},{"location":"reference/troubleshooting/#corrupted-storage","title":"Corrupted Storage","text":"<p>Symptom: <pre><code>Error: Invalid manifest at version 42: CRC mismatch\n</code></pre></p> <p>Solution: <pre><code># Check integrity\nuni check --path ./storage --verbose\n\n# Repair if possible\nuni repair --path ./storage\n\n# Rollback to previous version\nuni rollback --path ./storage --version 41\n\n# Last resort: re-import\nuni import my-data --papers data.jsonl --output ./storage --force\n</code></pre></p>"},{"location":"reference/troubleshooting/#out-of-disk-space","title":"Out of Disk Space","text":"<p>Symptom: <pre><code>Error: Failed to write to storage: No space left on device\n</code></pre></p> <p>Solution: <pre><code># Check disk usage\ndf -h ./storage\n\n# Compact storage (removes old versions)\nuni compact --path ./storage --level l2\n\n# Clean old WAL segments\nuni wal clean --path ./storage --keep-count 2\n\n# Increase disk or move storage\nuni migrate --from ./storage --to /larger-disk/storage\n</code></pre></p>"},{"location":"reference/troubleshooting/#lock-file-issues","title":"Lock File Issues","text":"<p>Symptom: <pre><code>Error: Storage is locked by another process\n</code></pre></p> <p>Solution: <pre><code># Check for running processes\nlsof ./storage/.lock\n\n# Force unlock (only if no other process is actually using it!)\nrm ./storage/.lock\n\n# In code, ensure proper cleanup\ndrop(storage);  // Explicit drop releases lock\n</code></pre></p>"},{"location":"reference/troubleshooting/#query-issues","title":"Query Issues","text":""},{"location":"reference/troubleshooting/#parse-errors","title":"Parse Errors","text":"<p>Symptom: <pre><code>Error: Parse error at line 1, column 15: unexpected token\n</code></pre></p> <p>Common Causes:</p> <ol> <li> <p>Missing quotes around strings: <pre><code>// Wrong\nWHERE p.title = My Paper\n\n// Correct\nWHERE p.title = 'My Paper'\n</code></pre></p> </li> <li> <p>Wrong comparison operator: <pre><code>// Wrong (SQL style)\nWHERE p.year == 2023\n\n// Correct (Cypher style)\nWHERE p.year = 2023\n</code></pre></p> </li> <li> <p>Missing relationship direction: <pre><code>// Wrong\nMATCH (a)-[r]-(b)  // Ambiguous in some contexts\n\n// Better (explicit direction)\nMATCH (a)-[r]-&gt;(b)\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#semantic-errors","title":"Semantic Errors","text":"<p>Symptom: <pre><code>Error: Unknown label 'Paper'\n</code></pre></p> <p>Solution: <pre><code># List available labels\nuni schema show --path ./storage\n\n# Check spelling/case\n# Labels are case-sensitive: Paper != paper\n</code></pre></p> <p>Symptom: <pre><code>Error: Unknown property 'year' for label 'Paper'\n</code></pre></p> <p>Solution: <pre><code># List properties for label\nuni schema show --path ./storage --label Paper\n\n# Add property to schema if needed\nuni schema update --path ./storage --add-property Paper.year:Int32\n</code></pre></p>"},{"location":"reference/troubleshooting/#query-timeout","title":"Query Timeout","text":"<p>Symptom: <pre><code>Error: Query timeout after 300 seconds\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Add LIMIT: <pre><code>MATCH (p:Paper)-[:CITES]-&gt;(cited)\nRETURN p.title, cited.title\nLIMIT 1000  -- Add limit\n</code></pre></p> </li> <li> <p>Add filters: <pre><code>MATCH (p:Paper)-[:CITES]-&gt;(cited)\nWHERE p.year &gt; 2020  -- Filter early\nRETURN p.title, cited.title\n</code></pre></p> </li> <li> <p>Increase timeout: <pre><code>let config = ExecutorConfig {\n    timeout: Duration::from_secs(600),  // 10 minutes\n    ..Default::default()\n};\n</code></pre></p> </li> <li> <p>Check query plan: <pre><code>uni query \"EXPLAIN MATCH (p:Paper)...\" --path ./storage\n# Look for missing indexes\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#out-of-memory","title":"Out of Memory","text":"<p>Symptom: <pre><code>Error: Query execution failed: Out of memory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Reduce result size: <pre><code>MATCH (p:Paper)\nRETURN p.title  -- Only needed columns\nLIMIT 10000     -- Reasonable limit\n</code></pre></p> </li> <li> <p>Stream results: <pre><code>let stream = executor.execute_stream(query).await?;\nwhile let Some(row) = stream.next().await {\n    // Process one row at a time\n}\n</code></pre></p> </li> <li> <p>Increase memory limit: <pre><code>let config = ExecutorConfig {\n    memory_limit: 8 * 1024 * 1024 * 1024,  // 8 GB\n    ..Default::default()\n};\n</code></pre></p> </li> <li> <p>Reduce batch size: <pre><code>let config = ExecutorConfig {\n    batch_size: 1024,  // Smaller batches\n    morsel_size: 1024,\n    ..Default::default()\n};\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#index-issues","title":"Index Issues","text":""},{"location":"reference/troubleshooting/#vector-search-returns-poor-results","title":"Vector Search Returns Poor Results","text":"<p>Symptom: Results are not semantically similar to the query.</p> <p>Causes and Solutions:</p> <ol> <li> <p>Wrong embedding model: <pre><code>// Ensure same model for indexing and querying\nlet service = FastEmbedService::new(FastEmbedModel::BGEBaseENV15)?;\n// Use the same model everywhere!\n</code></pre></p> </li> <li> <p>Dimension mismatch: <pre><code># Check schema dimensions\nuni schema show --path ./storage --label Paper\n# Embedding: Vector[768]\n\n# Ensure query vector matches\nassert_eq!(query_vec.len(), 768);\n</code></pre></p> </li> <li> <p>Low ef_search: <pre><code>-- Increase search depth\nCALL db.idx.vector.query('Paper', 'embedding', $vec, 10, {ef_search: 200})\n</code></pre></p> </li> <li> <p>Wrong distance metric: <pre><code># Check index metric\nuni index show --path ./storage --name paper_embeddings\n# Metric: cosine\n\n# Rebuild with correct metric if needed\nuni index rebuild --path ./storage --name paper_embeddings --metric l2\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#index-not-being-used","title":"Index Not Being Used","text":"<p>Symptom: Query is slow despite having an index.</p> <p>Diagnosis: <pre><code>uni query \"EXPLAIN MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN p\" --path ./storage\n</code></pre></p> <p>Common Causes:</p> <ol> <li> <p>Function on indexed column: <pre><code>// Index NOT used (function applied to column)\nWHERE LOWER(p.venue) = 'neurips'\n\n// Index used\nWHERE p.venue = 'NeurIPS'\n</code></pre></p> </li> <li> <p>OR conditions: <pre><code>// May not use index efficiently\nWHERE p.year &gt; 2020 OR p.venue = 'NeurIPS'\n\n// Better: split into UNION (if supported)\n</code></pre></p> </li> <li> <p>Leading wildcard: <pre><code>// Cannot use index\nWHERE p.title CONTAINS 'attention'\n\n// Can use full-text index (if available)\n</code></pre></p> </li> <li> <p>Low selectivity: <pre><code>// If 80% of data matches, full scan may be faster\nWHERE p.year &gt; 2000\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#index-build-fails","title":"Index Build Fails","text":"<p>Symptom: <pre><code>Error: Failed to build vector index: out of memory\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Reduce batch size: <pre><code>uni index create --path ./storage --batch-size 10000 ...\n</code></pre></p> </li> <li> <p>Use IVF_PQ instead of HNSW: <pre><code>CREATE VECTOR INDEX paper_embeddings\nFOR (p:Paper) ON p.embedding\nOPTIONS { index_type: 'ivf_pq' }  -- Less memory\n</code></pre></p> </li> <li> <p>Build incrementally: <pre><code># Build in chunks\nuni index create --path ./storage --incremental ...\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#import-issues","title":"Import Issues","text":""},{"location":"reference/troubleshooting/#schema-inference-fails","title":"Schema Inference Fails","text":"<p>Symptom: <pre><code>Error: Cannot infer type for property 'year': mixed types\n</code></pre></p> <p>Solution: <pre><code># Provide explicit schema\nuni import my-data --schema schema.json ...\n\n# Or fix source data to have consistent types\n</code></pre></p>"},{"location":"reference/troubleshooting/#duplicate-ids","title":"Duplicate IDs","text":"<p>Symptom: <pre><code>Warning: Duplicate external ID 'paper_123', keeping latest\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Deduplicate source data: <pre><code>sort -u -t',' -k1,1 papers.jsonl &gt; papers_dedup.jsonl\n</code></pre></p> </li> <li> <p>Use merge mode: <pre><code>uni import my-data --mode merge ...  # Merge duplicates\n</code></pre></p> </li> <li> <p>Use strict mode to fail: <pre><code>uni import my-data --on-duplicate error ...\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#embedding-dimension-mismatch","title":"Embedding Dimension Mismatch","text":"<p>Symptom: <pre><code>Error: Vector dimension mismatch: expected 768, got 384\n</code></pre></p> <p>Solution: <pre><code># Check schema\nuni schema show --path ./storage --label Paper\n\n# Re-embed with correct model or update schema\nuni schema update --path ./storage --property Paper.embedding:Vector[384]\n# Note: This requires re-importing data\n</code></pre></p>"},{"location":"reference/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"reference/troubleshooting/#slow-traversals","title":"Slow Traversals","text":"<p>Symptom: Graph traversals take &gt;100ms.</p> <p>Diagnosis: <pre><code>uni query \"PROFILE MATCH (p:Paper)-[:CITES]-&gt;(c) RETURN COUNT(c)\" --path ./storage\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Warm the adjacency cache: <pre><code>storage.adjacency_cache().warm(&amp;frequently_accessed_vids).await?;\n</code></pre></p> </li> <li> <p>Increase cache size: <pre><code>let config = StorageConfig {\n    adjacency_cache_size: 5_000_000,\n    ..Default::default()\n};\n</code></pre></p> </li> <li> <p>Add LIMIT to multi-hop: <pre><code>MATCH (p:Paper)-[:CITES*1..3]-&gt;(end)\nRETURN DISTINCT end\nLIMIT 1000\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#high-memory-usage","title":"High Memory Usage","text":"<p>Symptom: Process using more memory than expected.</p> <p>Diagnosis: <pre><code>let stats = storage.memory_stats();\nprintln!(\"Adjacency cache: {} MB\", stats.adjacency_cache_mb);\nprintln!(\"Property cache: {} MB\", stats.property_cache_mb);\nprintln!(\"L0 buffer: {} MB\", stats.l0_buffer_mb);\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Reduce cache sizes: <pre><code>let config = StorageConfig {\n    adjacency_cache_size: 500_000,\n    property_cache_size: 50_000,\n    ..Default::default()\n};\n</code></pre></p> </li> <li> <p>Flush L0 more frequently: <pre><code>let config = StorageConfig {\n    max_l0_size: 32 * 1024 * 1024,  // 32 MB\n    max_mutations_before_flush: 5_000,\n    ..Default::default()\n};\n</code></pre></p> </li> <li> <p>Use streaming queries: <pre><code>let stream = executor.execute_stream(query).await?;\n// Process results without loading all into memory\n</code></pre></p> </li> </ol>"},{"location":"reference/troubleshooting/#error-reference","title":"Error Reference","text":""},{"location":"reference/troubleshooting/#storage-errors","title":"Storage Errors","text":"Error Cause Solution <code>StorageLocked</code> Another process holds lock Wait or force unlock <code>CorruptedManifest</code> Invalid manifest file Rollback or repair <code>WalCorrupted</code> WAL corruption detected Truncate WAL, may lose recent writes <code>DiskFull</code> No space available Free space or compact <code>VersionNotFound</code> Requested version doesn't exist Use valid version number"},{"location":"reference/troubleshooting/#query-errors","title":"Query Errors","text":"Error Cause Solution <code>ParseError</code> Invalid Cypher syntax Fix query syntax <code>UnknownLabel</code> Label not in schema Check schema or fix query <code>UnknownProperty</code> Property not in schema Check schema or fix query <code>TypeMismatch</code> Incompatible types Fix query or data types <code>Timeout</code> Query exceeded time limit Optimize query or increase timeout <code>OutOfMemory</code> Memory limit exceeded Reduce result size or increase limit"},{"location":"reference/troubleshooting/#index-errors","title":"Index Errors","text":"Error Cause Solution <code>IndexNotFound</code> Index doesn't exist Create index first <code>IndexBuildFailed</code> Build process failed Check logs, retry with smaller batch <code>DimensionMismatch</code> Vector size doesn't match Use correct embedding dimensions <code>MetricMismatch</code> Distance metric incompatible Use matching metric"},{"location":"reference/troubleshooting/#debugging-tips","title":"Debugging Tips","text":""},{"location":"reference/troubleshooting/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<pre><code># All Uni logs at debug level\nRUST_LOG=uni=debug uni query \"...\" --path ./storage\n\n# Specific module\nRUST_LOG=uni::storage=trace,uni::query=debug uni query \"...\"\n\n# Include Lance logs\nRUST_LOG=uni=debug,lance=info uni query \"...\"\n</code></pre>"},{"location":"reference/troubleshooting/#query-profiling","title":"Query Profiling","text":"<pre><code># Get execution profile\nuni query \"PROFILE MATCH (p:Paper) WHERE p.year &gt; 2020 RETURN COUNT(p)\" --path ./storage\n\n# Output shows:\n# - Time per operator\n# - Rows processed\n# - Index usage\n# - Memory usage\n</code></pre>"},{"location":"reference/troubleshooting/#storage-inspection","title":"Storage Inspection","text":"<pre><code># List all datasets\nls -la ./storage/vertices/\nls -la ./storage/edges/\nls -la ./storage/adjacency/\n\n# Check Lance dataset info\nuni inspect --path ./storage/vertices/Paper\n\n# View manifest\ncat ./storage/manifest.json | jq .\n</code></pre>"},{"location":"reference/troubleshooting/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Run with memory tracking\nRUST_LOG=uni=debug UNI_TRACK_MEMORY=1 uni query \"...\"\n\n# Use heaptrack (Linux)\nheaptrack uni query \"...\"\nheaptrack_gui heaptrack.uni.*.gz\n</code></pre>"},{"location":"reference/troubleshooting/#getting-help","title":"Getting Help","text":""},{"location":"reference/troubleshooting/#resources","title":"Resources","text":"<ul> <li>Documentation: https://uni.dev/docs</li> <li>GitHub Issues: https://github.com/dragonscale/uni/issues</li> <li>Discussions: https://github.com/dragonscale/uni/discussions</li> </ul>"},{"location":"reference/troubleshooting/#reporting-bugs","title":"Reporting Bugs","text":"<p>When reporting issues, include:</p> <ol> <li>Uni version: <code>uni --version</code></li> <li>Rust version: <code>rustc --version</code></li> <li>OS and version</li> <li>Minimal reproduction steps</li> <li>Error messages (full output)</li> <li>Query plan (if query-related): <code>EXPLAIN ...</code></li> <li>Storage stats: <code>uni stats --path ./storage</code></li> </ol>"},{"location":"reference/troubleshooting/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Reference \u2014 All configuration options</li> <li>Performance Tuning \u2014 Optimization strategies</li> <li>Glossary \u2014 Terminology reference</li> </ul>"},{"location":"use-cases/","title":"Use Cases","text":"<p>Explore common architectures and solutions built with Uni.</p>   ### [RAG &amp; Knowledge Graphs](rag-knowledge-graph.md) Combine vector retrieval with graph traversal for smarter AI context.     ### [Real-Time Fraud Detection](fraud-detection.md) High-velocity ingestion and low-latency pattern matching to stop fraud.     ### [Recommendation Engines](recommendation-engine.md) Hybrid vector/graph scoring for personalized product and content discovery.     ### [Supply Chain &amp; BOM](supply-chain.md) Recursive analysis and document storage for complex component hierarchies."},{"location":"use-cases/#common-themes","title":"Common Themes","text":"<p>Uni excels in scenarios that require:</p> <ol> <li>Multiple Data Models: You need Graph for relationships and Vector for similarity.</li> <li>Low Latency: You need to traverse deep relationships faster than a relational JOIN.</li> <li>Simplified Stack: You want to avoid maintaining a separate vector DB and graph DB.</li> <li>High Ingest: You need to handle real-time write streams without locking readers.</li> </ol>"},{"location":"use-cases/fraud-detection/","title":"Real-Time Fraud Detection","text":"<p>Fraud detection requires analyzing complex relationships (graph) and patterns in real-time, often while ingesting high volumes of transaction data. Uni's single-writer architecture with L0 memory buffering makes it ideal for high-velocity ingest combined with instant \"read-your-writes\" queries.</p>"},{"location":"use-cases/fraud-detection/#why-uni-for-fraud-detection","title":"Why Uni for Fraud Detection?","text":"Challenge Traditional Approach Uni Approach Ingest Rate Graph DBs struggle with high write loads; Relational DBs can't do hops. L0 Buffer: Writes hit memory first (WAL-backed), amortized flush to disk. Freshness \"Eventual consistency\" or ETL lag (minutes/hours). Snapshot Isolation: Readers see writes immediately (if configured). Deep Links Detecting \"Payment Rings\" requires 3+ hops. SQL joins choke. CSR Cache: O(1) adjacency lookups make multi-hop checks fast."},{"location":"use-cases/fraud-detection/#scenario-payment-ring-detection","title":"Scenario: Payment Ring Detection","text":"<p>We want to detect a circular payment pattern: <code>User A -&gt; User B -&gt; User C -&gt; User A</code> happening within a short time window.</p>"},{"location":"use-cases/fraud-detection/#1-schema-definition","title":"1. Schema Definition","text":"<p>We model <code>Users</code>, <code>Devices</code>, and <code>IPs</code> as nodes to detect shared infrastructure usage. <code>Transactions</code> are edges with timestamps.</p> <p><code>schema.json</code> <pre><code>{\n  \"labels\": {\n    \"User\": { \"id\": 1 },\n    \"Device\": { \"id\": 2 },\n    \"IP\": { \"id\": 3 }\n  },\n  \"edge_types\": {\n    \"SENT_MONEY\": { \"id\": 1, \"src_labels\": [\"User\"], \"dst_labels\": [\"User\"] },\n    \"USED_DEVICE\": { \"id\": 2, \"src_labels\": [\"User\"], \"dst_labels\": [\"Device\"] },\n    \"USED_IP\": { \"id\": 3, \"src_labels\": [\"User\"], \"dst_labels\": [\"IP\"] }\n  },\n  \"properties\": {\n    \"SENT_MONEY\": {\n      \"amount\": { \"type\": \"Float64\", \"nullable\": false },\n      \"ts\": { \"type\": \"Int64\", \"nullable\": false }\n    },\n    \"User\": {\n      \"risk_score\": { \"type\": \"Float32\", \"nullable\": true }\n    }\n  },\n  \"indexes\": []\n}\n</code></pre></p>"},{"location":"use-cases/fraud-detection/#2-configuration","title":"2. Configuration","text":"<p>For high write throughput, we tune the WAL and L0 Buffer.</p> <p><code>uni.toml</code> <pre><code>[storage]\n# Allow large in-memory buffer before flushing to Lance\nmax_l0_size_mb = 512\nmax_mutations_before_flush = 100000\n\n[storage.wal]\n# \"Periodic\" is faster than \"Sync\", still safe enough for most fraud cases\nsync_mode = \"periodic\"\nsync_interval_ms = 50\n</code></pre></p>"},{"location":"use-cases/fraud-detection/#3-streaming-ingestion","title":"3. Streaming Ingestion","text":"<p>Use the HTTP API or Rust bindings to ingest transactions as they happen.</p> <pre><code>// Rust API Example\nlet writer = db.writer();\nlet mut tx_props = std::collections::HashMap::new();\ntx_props.insert(\"amount\".to_string(), json!(5000.00));\ntx_props.insert(\"ts\".to_string(), json!(current_time));\n\n// Allocate edge ID and insert\n// This hits the L0 memory buffer - &lt;1ms latency\n// insert_edge(src, dst, type_id, eid, props)\nwriter.insert_edge(user_a, user_b, sent_money_type, eid, tx_props).await?;\n</code></pre>"},{"location":"use-cases/fraud-detection/#4-real-time-detection-query","title":"4. Real-time Detection Query","text":"<p>Run this query synchronously when a transaction is attempted. It checks for a cycle of length 3-4 involving the sender.</p> <pre><code>// Check for cycles starting from User A\nMATCH (a:User)-[t1:SENT_MONEY]-&gt;(b:User)-[t2:SENT_MONEY]-&gt;(c:User)-[t3:SENT_MONEY]-&gt;(a)\n\n// Filter recent transactions only (e.g., last 1 hour)\nWHERE t1.ts &gt; $threshold AND t2.ts &gt; $threshold AND t3.ts &gt; $threshold\n\n// Return the cycle details\nRETURN a.id, b.id, c.id, t1.amount, t2.amount, t3.amount\n</code></pre>"},{"location":"use-cases/fraud-detection/#5-identity-resolution-query","title":"5. Identity Resolution Query","text":"<p>Check if the sender shares an IP or Device with known fraudsters.</p> <pre><code>MATCH (sender:User)-[:USED_DEVICE]-&gt;(shared_resource)&lt;-[:USED_DEVICE]-(other:User)\nWHERE other.risk_score &gt; 0.8\nRETURN count(other) as suspicious_links\n</code></pre>"},{"location":"use-cases/fraud-detection/#key-advantages","title":"Key Advantages","text":"<ul> <li>Ingest Speed: Uni's L0 buffer acts like a Write-Optimized Store (WOS), handling spikes in transaction volume without blocking readers.</li> <li>Latency: Checking a 3-hop cycle takes milliseconds due to the in-memory CSR cache.</li> <li>Data Locality: The graph structure and properties are co-located; no need to query a Redis cache for \"risk scores\" separately.</li> </ul>"},{"location":"use-cases/rag-knowledge-graph/","title":"RAG &amp; Knowledge Graphs","text":"<p>Uni is uniquely positioned for Retrieval-Augmented Generation (RAG) by combining vector search (for semantic retrieval) and knowledge graphs (for structured reasoning) in a single, embedded engine.</p>"},{"location":"use-cases/rag-knowledge-graph/#why-uni-for-rag","title":"Why Uni for RAG?","text":"Challenge Traditional Approach Uni Approach Latency Vector DB query + Graph DB query + App logic merge (~50-100ms) Single execution plan, local memory access (~5ms) Complexity Maintaining sync between Pinecone/Weaviate and Neo4j One schema, one storage engine, one transaction log Context \"Dumb\" retrieval of chunks based only on similarity GraphRAG: Retrieve chunks + related entities + relationships"},{"location":"use-cases/rag-knowledge-graph/#scenario-technical-support-bot","title":"Scenario: Technical Support Bot","text":"<p>We want to build a support bot that answers questions about a software product. It needs to: 1. Find documentation chunks semantically similar to the user's query. 2. Traverse to related API methods, known issues, and version history. 3. Return a rich context window to the LLM.</p>"},{"location":"use-cases/rag-knowledge-graph/#1-schema-definition","title":"1. Schema Definition","text":"<p>We model <code>Documents</code> (chunked text) and <code>Entities</code> (API endpoints, Error codes) linked together.</p> <p><code>schema.json</code> <pre><code>{\n  \"labels\": {\n    \"Chunk\": {\n      \"id\": 1,\n      \"is_document\": false\n    },\n    \"Entity\": {\n      \"id\": 2,\n      \"is_document\": false\n    }\n  },\n  \"edge_types\": {\n    \"MENTIONS\": { \"id\": 1, \"src_labels\": [\"Chunk\"], \"dst_labels\": [\"Entity\"] },\n    \"RELATED_TO\": { \"id\": 2, \"src_labels\": [\"Entity\"], \"dst_labels\": [\"Entity\"] },\n    \"NEXT_CHUNK\": { \"id\": 3, \"src_labels\": [\"Chunk\"], \"dst_labels\": [\"Chunk\"] }\n  },\n  \"properties\": {\n    \"Chunk\": {\n      \"text\": { \"type\": \"String\", \"nullable\": false },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 768 }\n    },\n    \"Entity\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"type\": { \"type\": \"String\", \"nullable\": true } // \"function\", \"class\", \"error\"\n    }\n  },\n  \"indexes\": [\n    {\n      \"type\": \"Vector\",\n      \"name\": \"chunk_embeddings\",\n      \"label\": \"Chunk\",\n      \"property\": \"embedding\",\n      \"index_type\": { \"Hnsw\": { \"m\": 32, \"ef_construction\": 200 } },\n      \"metric\": \"Cosine\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"use-cases/rag-knowledge-graph/#2-configuration","title":"2. Configuration","text":"<p>For RAG, we prioritize read latency. We ensure the Adjacency Cache is large enough to hold the relationship graph, and the Vector Index fits in memory/cache.</p> <p><code>uni.toml</code> <pre><code>[storage]\npath = \"./rag_data\"\n# Cache topology for fast Entity expansion\nadjacency_cache_size = 500000 \n\n[index.vector.defaults]\n# Tune for high recall\nm = 32\nef_search = 100\n</code></pre></p>"},{"location":"use-cases/rag-knowledge-graph/#3-data-ingestion","title":"3. Data Ingestion","text":"<p>Embed your documents (using OpenAI/Cohere/FastEmbed) and extract entities (using LLM or NER) before inserting.</p> <pre><code># Example JSONL structure for import\n# chunks.jsonl\n# {\"id\": \"c1\", \"text\": \"Function verify() checks signatures.\", \"embedding\": [...]} \n# entities.jsonl\n# {\"id\": \"e1\", \"name\": \"verify\", \"type\": \"function\"}\n# relations.jsonl\n# {\"src\": \"c1\", \"dst\": \"e1\", \"type\": \"MENTIONS\"}\n\nuni import support-bot \\\n  --papers chunks.jsonl \\\n  --citations relations.jsonl \\\n  --schema schema.json\n</code></pre>"},{"location":"use-cases/rag-knowledge-graph/#4-querying-graphrag","title":"4. Querying (GraphRAG)","text":"<p>This single query performs the entire retrieval pipeline:</p> <ol> <li>Vector Search: Finds the top 5 relevant text chunks.</li> <li>Graph Expansion: Finds entities mentioned in those chunks.</li> <li>2nd Hop: Finds other chunks that mention those entities (expanding context).</li> </ol> <pre><code>// 1. Vector Search for relevant chunks\nCALL db.idx.vector.query('Chunk', 'embedding', $user_query_vector, 5)\nYIELD node AS primary_chunk, distance\n\n// 2. Find connected Entities (e.g., \"verify function\")\nMATCH (primary_chunk)-[:MENTIONS]-&gt;(topic:Entity)\n\n// 3. Find other chunks mentioning these topics (Context Expansion)\nMATCH (related_chunk:Chunk)-[:MENTIONS]-&gt;(topic)\nWHERE related_chunk.id &lt;&gt; primary_chunk.id\n\n// 4. Return unique relevant text blocks\nRETURN DISTINCT \n    primary_chunk.text AS main_answer,\n    topic.name AS related_concept,\n    related_chunk.text AS additional_context,\n    distance\nORDER BY distance ASC\nLIMIT 10\n</code></pre>"},{"location":"use-cases/rag-knowledge-graph/#key-advantages","title":"Key Advantages","text":"<ul> <li>Speed: No network round-trip between Vector DB and Graph DB. The join happens in-memory via the adjacency cache.</li> <li>Simplicity: Just one Docker container (or embedded binary) to manage.</li> <li>Precision: We filter vector noise using graph structure (only chunks related to specific entities).</li> </ul>"},{"location":"use-cases/recommendation-engine/","title":"Recommendation Engines","text":"<p>Modern recommendation systems are hybrids: they use collaborative filtering (graph-based: \"users like you bought...\") and content-based filtering (vector-based: \"products similar to this...\"). Uni handles both in a single query engine.</p>"},{"location":"use-cases/recommendation-engine/#why-uni-for-recsys","title":"Why Uni for RecSys?","text":"Challenge Traditional Approach Uni Approach Cold Start Graph algorithms fail for new items (no edges). Vector Search: Find items similar to user's interest description. Diversity Vector search returns near-duplicates. Graph Expansion: Boost score if item is in a cluster \"liked\" by friends. Real-time Pre-compute recommendations batch (stale). On-demand: Generate candidates at query time using live history."},{"location":"use-cases/recommendation-engine/#scenario-e-commerce-personalization","title":"Scenario: E-Commerce Personalization","text":"<p>We want to recommend products to a user based on: 1.  Semantic Match: Products matching their search query (Vector). 2.  Social Proof: Products purchased by other users who bought the same items as the target user (Graph).</p>"},{"location":"use-cases/recommendation-engine/#1-schema-definition","title":"1. Schema Definition","text":"<p><code>schema.json</code> <pre><code>{\n  \"labels\": {\n    \"User\": { \"id\": 1 },\n    \"Product\": { \"id\": 2 },\n    \"Category\": { \"id\": 3 }\n  },\n  \"edge_types\": {\n    \"VIEWED\": { \"id\": 1, \"src_labels\": [\"User\"], \"dst_labels\": [\"Product\"] },\n    \"PURCHASED\": { \"id\": 2, \"src_labels\": [\"User\"], \"dst_labels\": [\"Product\"] },\n    \"IN_CATEGORY\": { \"id\": 3, \"src_labels\": [\"Product\"], \"dst_labels\": [\"Category\"] }\n  },\n  \"properties\": {\n    \"Product\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"price\": { \"type\": \"Float64\", \"nullable\": false },\n      \"embedding\": { \"type\": \"Vector\", \"dimensions\": 384 } // Image + Text embedding\n    }\n  },\n  \"indexes\": [\n    {\n      \"type\": \"Vector\",\n      \"name\": \"product_embedding\",\n      \"label\": \"Product\",\n      \"property\": \"embedding\",\n      \"index_type\": { \"IvfPq\": { \"num_partitions\": 1024, \"num_sub_vectors\": 16 } },\n      \"metric\": \"Cosine\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"use-cases/recommendation-engine/#2-configuration","title":"2. Configuration","text":"<p>We use IVF_PQ for the vector index to reduce memory usage, allowing us to keep a larger portion of the graph in the Adjacency Cache.</p> <p><code>uni.toml</code> <pre><code>[storage]\nadjacency_cache_size = 2000000 # Cache large parts of user-product graph\n\n[executor]\n# Parallelize scoring across many candidate products\nworker_threads = 16 \n</code></pre></p>"},{"location":"use-cases/recommendation-engine/#3-hybrid-query","title":"3. Hybrid Query","text":"<p>This query performs a \"Vector-to-Graph\" re-ranking pipeline.</p> <ol> <li>Candidate Generation: Find 50 products semantically similar to the user's current search (e.g., \"running shoes\").</li> <li>Scoring:<ul> <li>Base score = Vector similarity.</li> <li>Boost = Count of purchases by similar users (Collaborative Filtering signal).</li> </ul> </li> </ol> <pre><code>// 1. Generate Candidates (Content-Based)\nCALL db.idx.vector.query('Product', 'embedding', $search_embedding, 50)\nYIELD node AS product, distance\n\n// 2. Calculate Social Score (Collaborative)\n// Find users who bought this product\nMATCH (other_user:User)-[:PURCHASED]-&gt;(product)\n\n// (Optional) Ensure 'other_user' has some overlap with current user\n// MATCH (current_user)-[:PURCHASED]-&gt;(:Product)&lt;-[:PURCHASED]-(other_user) ...\n\n// 3. Aggregate and Re-rank\nRETURN \n    product.name, \n    product.price,\n    distance AS semantic_score,\n    COUNT(other_user) AS popularity_score,\n    // Final score: similarity weighted by log of popularity\n    (1.0 - distance) + LOG(1 + COUNT(other_user)) * 0.5 AS final_score\nORDER BY final_score DESC\nLIMIT 10\n</code></pre>"},{"location":"use-cases/recommendation-engine/#key-advantages","title":"Key Advantages","text":"<ul> <li>No ETL: You don't need to export data to Spark to run collaborative filtering. It happens in the DB.</li> <li>Vector-Native: Unlike Lucene-based search engines, the vector index is part of the query planner, allowing seamless joining with graph data.</li> <li>Flexibility: You can tweak the weighting formula (<code>0.5</code> in the example) instantly without retraining models.</li> </ul>"},{"location":"use-cases/supply-chain/","title":"Supply Chain &amp; BOM Analysis","text":"<p>Supply chains are deeply nested graphs (Part A -&gt; Part B -&gt; Part C). Uni's specialized support for recursive traversals and document storage makes it an excellent fit for Bill of Materials (BOM) management and impact analysis.</p>"},{"location":"use-cases/supply-chain/#why-uni-for-supply-chain","title":"Why Uni for Supply Chain?","text":"Challenge Traditional Approach Uni Approach Recursive Depth SQL <code>WITH RECURSIVE</code> is slow and hard to optimize. Vectorized Recursion: <code>MATCH (n)-[:PART_OF*]-&gt;(m)</code> is optimized for deep paths. Variable Data Parts have widely varying specs (resistors vs. CPUs). Relational schemas explode. Document Mode: Store distinct part specs as JSON in the same <code>Part</code> table. Analytics Hard to aggregage cost/weight up the tree. Aggregation Pushdown: Fast summation over traversal paths."},{"location":"use-cases/supply-chain/#scenario-product-impact-analysis","title":"Scenario: Product Impact Analysis","text":"<p>A supplier notifies you that \"Part X\" has a defect. You need to find: 1.  All finished products that contain Part X (recursively). 2.  The total revenue at risk.</p>"},{"location":"use-cases/supply-chain/#1-schema-definition","title":"1. Schema Definition","text":"<p>We enable Document Mode for <code>Part</code> to store varied technical specifications.</p> <p><code>schema.json</code> <pre><code>{\n  \"labels\": {\n    \"Part\": {\n      \"id\": 1,\n      \"is_document\": true // Allows storing arbitrary JSON in _doc\n    },\n    \"Supplier\": { \"id\": 2 },\n    \"Product\": { \"id\": 3 }\n  },\n  \"edge_types\": {\n    \"ASSEMBLED_FROM\": { \"id\": 1, \"src_labels\": [\"Part\", \"Product\"], \"dst_labels\": [\"Part\"] },\n    \"SUPPLIED_BY\": { \"id\": 2, \"src_labels\": [\"Part\"], \"dst_labels\": [\"Supplier\"] }\n  },\n  \"properties\": {\n    \"Part\": {\n      \"sku\": { \"type\": \"String\", \"nullable\": false },\n      \"cost\": { \"type\": \"Float64\", \"nullable\": false }\n    },\n    \"Product\": {\n      \"name\": { \"type\": \"String\", \"nullable\": false },\n      \"price\": { \"type\": \"Float64\", \"nullable\": false }\n    }\n  },\n  \"indexes\": [\n    {\n      \"type\": \"Scalar\",\n      \"name\": \"part_sku\",\n      \"label\": \"Part\",\n      \"properties\": [\"sku\"],\n      \"index_type\": \"Hash\"\n    },\n    {\n      \"type\": \"Scalar\",\n      \"name\": \"json_spec_voltage\",\n      \"label\": \"Part\",\n      \"properties\": [\"$.specs.voltage\"], // JSON Path Indexing (Planned feature)\n      \"index_type\": \"BTree\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"use-cases/supply-chain/#2-ingestion-with-documents","title":"2. Ingestion (With Documents)","text":"<p>When inserting parts, we put fixed fields in properties and variable fields in <code>_doc</code>.</p> <pre><code>// Rust Example\nwriter.insert_vertex(vid, json!({\n    \"sku\": \"RES-10K\",\n    \"cost\": 0.05,\n    \"_doc\": {\n        \"type\": \"resistor\",\n        \"specs\": { \"resistance\": \"10k\", \"tolerance\": \"5%\" },\n        \"compliance\": [\"RoHS\"]\n    }\n})).await?;\n</code></pre>"},{"location":"use-cases/supply-chain/#3-query-bom-explosion","title":"3. Query: BOM Explosion","text":"<p>Find all products affected by the defective part.</p> <pre><code>// Start at the defective part\nMATCH (defective:Part {sku: 'RES-10K'})\n\n// Traverse UP the assembly tree (incoming ASSEMBLED_FROM edges)\n// Variable length path: *1..20 levels deep\nMATCH (product:Product)-[:ASSEMBLED_FROM*1..20]-&gt;(defective)\n\n// Return unique affected products and their price\nRETURN DISTINCT \n    product.name, \n    product.price\nORDER BY product.price DESC\n</code></pre>"},{"location":"use-cases/supply-chain/#4-query-cost-rollup","title":"4. Query: Cost Rollup","text":"<p>Calculate the total cost of a product by summing the cost of all its constituent parts.</p> <pre><code>MATCH (p:Product {name: 'Smartphone X'})\nMATCH (p)-[:ASSEMBLED_FROM*]-&gt;(part:Part)\nRETURN p.name, SUM(part.cost) AS total_bom_cost\n</code></pre>"},{"location":"use-cases/supply-chain/#key-advantages","title":"Key Advantages","text":"<ul> <li>Deep Traversal Speed: Uni's adjacency cache ensures that each hop is a simple memory lookup, not a disk seek. BOM explosions that take seconds in SQL take milliseconds in Uni.</li> <li>Schema Flexibility: You can store resistors, capacitors, screens, and batteries in the same <code>Part</code> dataset without a sparse column mess.</li> <li>Vector Potential: You could even add embeddings to parts (e.g., image of the component) to find visual duplicates in your inventory.</li> </ul>"}]}